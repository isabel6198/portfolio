[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Menu principal",
    "section": "",
    "text": "R√©alis√©e par Gloria Isabel PALACIO BARCO\nContact par mail :\ngloria.palacio-barco@etu.univ-nantes.fr\nisabel6198@hotmail.com"
  },
  {
    "objectID": "posts/post-without-code/Projets.html",
    "href": "posts/post-without-code/Projets.html",
    "title": "ECAP Master1",
    "section": "",
    "text": "Pr√©sentation des differents projets (sans code)"
  },
  {
    "objectID": "posts/post-without-code/Projets.html#series-temporelles-univariees",
    "href": "posts/post-without-code/Projets.html#series-temporelles-univariees",
    "title": "ECAP Master1",
    "section": "SeÃÅries temporelles univarieÃÅes",
    "text": "SeÃÅries temporelles univarieÃÅes\n\nEtude des seÃÅries temporelles de l‚Äôindice de prix aÃÄ la consommation (IPC), le prix du peÃÅtrole et la variation des tempeÃÅratures en France, aÃÄ l‚Äôaide de la meÃÅthodologie ARIMA\nUne analyse des tendances et des fluctuations de 2010 jusqu‚ÄôaÃÄ 2022\nPar : Gloria Isabel PALACIO\nDate : F√©vrier 2024"
  },
  {
    "objectID": "posts/post-without-code/Projets.html#√©valuation-des-actifs-financiers",
    "href": "posts/post-without-code/Projets.html#√©valuation-des-actifs-financiers",
    "title": "ECAP Master1",
    "section": "√âvaluation des actifs financiers",
    "text": "√âvaluation des actifs financiers\n\nEtude de fonds d‚Äôinvestissement social responsable sur l‚ÄôanneÃÅe 2023\nPar : Marie KERHOAS & Gloria Isabel PALACIO\nDate : Mars 2024"
  },
  {
    "objectID": "posts/post-without-code/Projets.html#analyse-de-donn√©es-et-descriptive",
    "href": "posts/post-without-code/Projets.html#analyse-de-donn√©es-et-descriptive",
    "title": "ECAP Master1",
    "section": "Analyse de donn√©es et descriptive",
    "text": "Analyse de donn√©es et descriptive\n\nAnalyse de l‚Äôattractivite touristique des d√©partements en France m√©tropolitaine 2022\nPar : Marie KERHOAS & Gloria Isabel PALACIO\nDate : Mars 2024"
  },
  {
    "objectID": "posts/post-with-code/econometrie_lineaire/econometrie.html",
    "href": "posts/post-with-code/econometrie_lineaire/econometrie.html",
    "title": "√âconom√©trie lin√©aire avanc√©e",
    "section": "",
    "text": "(sur un eÃÅchantillon de 98 personnes en 2023)\nR√©sum√©\nL‚Äôobjectif de notre √©tude est d‚Äôidentifier les facteurs influen√ßant la consommation num√©rique hebdomadaire chez les adultes Fran√ßais, √† partir de 18 ans, √† l‚Äô√©chelle nationale. Nous avons fait appel √† la m√©thode des moindres carr√©s (MCO) qui nous a permis d‚Äôobtenir un mod√®le fiable validant toutes les conditions requises pour son application. Pour ce faire, nous avons opt√© pour l‚Äôutilisation d‚Äôun jeu de donn√©es se rapprochant le plus possible de la r√©alit√©. Par cons√©quent, nous avons directement interrog√© la population √† l‚Äôaide d‚Äôun questionnaire se basant sur la mod√©lisation faite au pr√©alable √† partir de la litt√©rature. Nous avons obtenu un √©chantillon non repr√©sentatif de 98 individus d√ª √† un ratio femmes/hommes √©lev√©.\nLe mod√®le nous a donn√© d‚Äôune part des r√©sultats attendus. En effet, les personnes ayant une vie sociale importante ou ne travaillant pas toute la journ√©e sur un √©cran ont une consommation num√©rique hebdomadaire moindre par rapport aux casaniers et √† ceux exer√ßant un m√©tier pour lequel l‚Äô√©cran est le seul outil de travail. Puis, d‚Äôautre part, des r√©sultats inattendus. En effet, une personne poss√©dant un nombre d‚Äôappareils moindre a une consommation plus importante que celle ayant plus d‚Äôappareils, ou encore les personnes n‚Äôayant pas la fibre passent plus de temps sur les √©crans que ceux ayant la fibre.\n\n\n\n\nVous avez la possibilit√© de t√©l√©charger le document ici :) üì• T√©l√©charger le fichier PDF"
  },
  {
    "objectID": "posts/post-with-code/econometrie_lineaire/econometrie.html#analyse-du-temps-decran-chez-les-francais-de-plus-de-18-ans",
    "href": "posts/post-with-code/econometrie_lineaire/econometrie.html#analyse-du-temps-decran-chez-les-francais-de-plus-de-18-ans",
    "title": "√âconom√©trie lin√©aire avanc√©e",
    "section": "",
    "text": "(sur un eÃÅchantillon de 98 personnes en 2023)\nR√©sum√©\nL‚Äôobjectif de notre √©tude est d‚Äôidentifier les facteurs influen√ßant la consommation num√©rique hebdomadaire chez les adultes Fran√ßais, √† partir de 18 ans, √† l‚Äô√©chelle nationale. Nous avons fait appel √† la m√©thode des moindres carr√©s (MCO) qui nous a permis d‚Äôobtenir un mod√®le fiable validant toutes les conditions requises pour son application. Pour ce faire, nous avons opt√© pour l‚Äôutilisation d‚Äôun jeu de donn√©es se rapprochant le plus possible de la r√©alit√©. Par cons√©quent, nous avons directement interrog√© la population √† l‚Äôaide d‚Äôun questionnaire se basant sur la mod√©lisation faite au pr√©alable √† partir de la litt√©rature. Nous avons obtenu un √©chantillon non repr√©sentatif de 98 individus d√ª √† un ratio femmes/hommes √©lev√©.\nLe mod√®le nous a donn√© d‚Äôune part des r√©sultats attendus. En effet, les personnes ayant une vie sociale importante ou ne travaillant pas toute la journ√©e sur un √©cran ont une consommation num√©rique hebdomadaire moindre par rapport aux casaniers et √† ceux exer√ßant un m√©tier pour lequel l‚Äô√©cran est le seul outil de travail. Puis, d‚Äôautre part, des r√©sultats inattendus. En effet, une personne poss√©dant un nombre d‚Äôappareils moindre a une consommation plus importante que celle ayant plus d‚Äôappareils, ou encore les personnes n‚Äôayant pas la fibre passent plus de temps sur les √©crans que ceux ayant la fibre.\n\n\n\n\nVous avez la possibilit√© de t√©l√©charger le document ici :) üì• T√©l√©charger le fichier PDF"
  },
  {
    "objectID": "posts/post-with-code/econometrie_lineaire/econometrie.html#pr√©paration-des-donn√©es",
    "href": "posts/post-with-code/econometrie_lineaire/econometrie.html#pr√©paration-des-donn√©es",
    "title": "√âconom√©trie lin√©aire avanc√©e",
    "section": "Pr√©paration des donn√©es",
    "text": "Pr√©paration des donn√©es\n\nLibrairies\n\n\nsuppressPackageStartupMessages({\nlibrary(readxl)\nlibrary(writexl)\nlibrary(outliers)\nlibrary(dplyr)\nlibrary(VIM)\nlibrary(car)\nlibrary(MASS)\nlibrary(ggplot2)\nlibrary(EnvStats)\nlibrary(pander)\nlibrary(corrplot)\nlibrary(PerformanceAnalytics)\nlibrary(tidyverse)\nlibrary(questionr)\nlibrary(leaps)\nlibrary(stats)\nlibrary(lmtest)\nlibrary(AER)\nlibrary(here)\n})  \n\n\nVecteur de couleur\n\n\ncouleurs_genre &lt;- c(\"#9DBBA4\", \"#395948\")\ncouleurs &lt;- c(\"#9DBBA4\", \"#395948\")"
  },
  {
    "objectID": "posts/post-with-code/econometrie_lineaire/econometrie.html#pr√©paration-et-visualisation-des-donn√©es",
    "href": "posts/post-with-code/econometrie_lineaire/econometrie.html#pr√©paration-et-visualisation-des-donn√©es",
    "title": "√âconom√©trie lin√©aire avanc√©e",
    "section": "Pr√©paration et visualisation des donn√©es",
    "text": "Pr√©paration et visualisation des donn√©es\n\nT√©l√©chargement et visualisation du fichier, √† l‚Äôaide de la librairie ‚Äúreadxl‚Äù\nSupprimer la colonne ‚Äúhorodateur‚Äù qui est inutile\n\n\necran &lt;- read_excel(here(\"data\", \"BDD_propre.xlsx\"))\n\n\nhead(ecran)\n\n# A tibble: 6 √ó 21\n  Horodateur          A quelle cat√©gorie d‚Äô√¢ge apparten‚Ä¶¬π A quel genre vous id‚Ä¶¬≤\n  &lt;dttm&gt;              &lt;chr&gt;                               &lt;chr&gt;                 \n1 2023-11-30 16:40:29 25 - 49 ans                         Femme                 \n2 2023-11-30 16:54:37 50- 69 ans                          Femme                 \n3 2023-12-01 08:30:35 50- 69 ans                          Femme                 \n4 2023-12-02 14:14:23 50- 69 ans                          Homme                 \n5 2023-12-07 10:21:15 25 - 49 ans                         Femme                 \n6 2023-12-07 11:30:43 70 ans et plus                      Femme                 \n# ‚Ñπ abbreviated names: ¬π‚Äã`A quelle cat√©gorie d‚Äô√¢ge appartenez-vous ?`,\n#   ¬≤‚Äã`A quel genre vous identifiez-vous ?`\n# ‚Ñπ 18 more variables:\n#   `Quelle est votre cat√©gorie socioprofessionnelle ?` &lt;chr&gt;,\n#   `O√π habitez-vous ?` &lt;chr&gt;,\n#   `Avec combien de personnes vivez-vous dans votre logement principal ? (Par exemple si vous √™tes en couple r√©pondez 1)` &lt;dbl&gt;,\n#   `Quel est votre revenu fiscal apr√®s imp√¥t du foyer auquel vous √™tes rattach√© (par an) ? \\r\\nSi vous d√©pendez de vos parents mettez celui de vos parents.` &lt;chr&gt;, ‚Ä¶\n\necran &lt;- ecran[,-1]\n\n\nRenommer les colonnes\n\ncolnames(ecran) &lt;- c(\"age\", \"genre\", \"csp\", \"lieu_de_vie\", \"nb_personnes\", \"revenu\", \"temps_ecran\", \"nb_appareils\", \"internet\", \"fibre\", \"forfait_tel\", \"telephone_pro\", \"ecran_travail\", \"sommeil\", \"stress\", \"loisir\", \"vie_sociale\", \"ecran_jour\", \"reseaux_sociaux\", \"nb_abonnements\")\n\n\n\nMettre en num√©rique les variables\n\nstr(ecran)\n\ntibble [98 √ó 20] (S3: tbl_df/tbl/data.frame)\n $ age            : chr [1:98] \"25 - 49 ans\" \"50- 69 ans\" \"50- 69 ans\" \"50- 69 ans\" ...\n $ genre          : chr [1:98] \"Femme\" \"Femme\" \"Femme\" \"Homme\" ...\n $ csp            : chr [1:98] \"Cadres et professions intellectuelles sup√©rieures\" \"Professions interm√©diaires\" \"Cadres et professions intellectuelles sup√©rieures\" \"Cadres et professions intellectuelles sup√©rieures\" ...\n $ lieu_de_vie    : chr [1:98] \"Ville\" \"Campagne\" \"P√©riurbaine/ Banlieue\" \"Ville\" ...\n $ nb_personnes   : num [1:98] 1 2 2 1 5 0 1 3 1 3 ...\n $ revenu         : chr [1:98] \"30 000 - 40 000\" \"40 000 - 50 000\" \"70 000 - 80 000\" \"70 000 - 80 000\" ...\n $ temps_ecran    : num [1:98] 35 35 30 60 64 28 28 35 25 21 ...\n $ nb_appareils   : chr [1:98] \"3\" \"5\" \"4\" \"4\" ...\n $ internet       : chr [1:98] \"Oui, avec la fibre\" \"Oui, avec la fibre\" \"Oui, avec la fibre\" \"Oui, avec la fibre\" ...\n $ fibre          : chr [1:98] \"Oui\" \"Oui\" \"Oui\" \"Oui\" ...\n $ forfait_tel    : chr [1:98] \"10 et 15 ‚Ç¨\" \"10 et 15 ‚Ç¨\" \"15 et 20 ‚Ç¨\" \"0\" ...\n $ telephone_pro  : chr [1:98] \"Oui\" \"Non\" \"Oui\" \"Oui\" ...\n $ ecran_travail  : chr [1:98] \"Toute la journ√©e\" \"Fr√©quemment (Plus de la moiti√© du temps)\" \"Fr√©quemment (Plus de la moiti√© du temps)\" \"Toute la journ√©e\" ...\n $ sommeil        : chr [1:98] \"5h ‚Äì 7h\" \"7h et 9h\" \"7h et 9h\" \"5h ‚Äì 7h\" ...\n $ stress         : chr [1:98] \"Parfois\" \"Parfois\" \"Rarement\" \"Fr√©quemment\" ...\n $ loisir         : num [1:98] 3 10 1 6 12 2 6 21 30 20 ...\n $ vie_sociale    : num [1:98] 14 15 2 8 8 7 10 20 80 10 ...\n $ ecran_jour     : chr [1:98] \"Le soir\" \"L‚Äôapr√®s midi\" \"Le matin\" \"Le soir\" ...\n $ reseaux_sociaux: chr [1:98] \"5\" \"2\" \"1\" \"0\" ...\n $ nb_abonnements : chr [1:98] \"0\" \"1\" \"3\" \"0\" ...\n\necran$loisir &lt;- as.numeric(ecran$loisir)\necran$vie_sociale &lt;- as.numeric(ecran$vie_sociale)\nstr(ecran)\n\ntibble [98 √ó 20] (S3: tbl_df/tbl/data.frame)\n $ age            : chr [1:98] \"25 - 49 ans\" \"50- 69 ans\" \"50- 69 ans\" \"50- 69 ans\" ...\n $ genre          : chr [1:98] \"Femme\" \"Femme\" \"Femme\" \"Homme\" ...\n $ csp            : chr [1:98] \"Cadres et professions intellectuelles sup√©rieures\" \"Professions interm√©diaires\" \"Cadres et professions intellectuelles sup√©rieures\" \"Cadres et professions intellectuelles sup√©rieures\" ...\n $ lieu_de_vie    : chr [1:98] \"Ville\" \"Campagne\" \"P√©riurbaine/ Banlieue\" \"Ville\" ...\n $ nb_personnes   : num [1:98] 1 2 2 1 5 0 1 3 1 3 ...\n $ revenu         : chr [1:98] \"30 000 - 40 000\" \"40 000 - 50 000\" \"70 000 - 80 000\" \"70 000 - 80 000\" ...\n $ temps_ecran    : num [1:98] 35 35 30 60 64 28 28 35 25 21 ...\n $ nb_appareils   : chr [1:98] \"3\" \"5\" \"4\" \"4\" ...\n $ internet       : chr [1:98] \"Oui, avec la fibre\" \"Oui, avec la fibre\" \"Oui, avec la fibre\" \"Oui, avec la fibre\" ...\n $ fibre          : chr [1:98] \"Oui\" \"Oui\" \"Oui\" \"Oui\" ...\n $ forfait_tel    : chr [1:98] \"10 et 15 ‚Ç¨\" \"10 et 15 ‚Ç¨\" \"15 et 20 ‚Ç¨\" \"0\" ...\n $ telephone_pro  : chr [1:98] \"Oui\" \"Non\" \"Oui\" \"Oui\" ...\n $ ecran_travail  : chr [1:98] \"Toute la journ√©e\" \"Fr√©quemment (Plus de la moiti√© du temps)\" \"Fr√©quemment (Plus de la moiti√© du temps)\" \"Toute la journ√©e\" ...\n $ sommeil        : chr [1:98] \"5h ‚Äì 7h\" \"7h et 9h\" \"7h et 9h\" \"5h ‚Äì 7h\" ...\n $ stress         : chr [1:98] \"Parfois\" \"Parfois\" \"Rarement\" \"Fr√©quemment\" ...\n $ loisir         : num [1:98] 3 10 1 6 12 2 6 21 30 20 ...\n $ vie_sociale    : num [1:98] 14 15 2 8 8 7 10 20 80 10 ...\n $ ecran_jour     : chr [1:98] \"Le soir\" \"L‚Äôapr√®s midi\" \"Le matin\" \"Le soir\" ...\n $ reseaux_sociaux: chr [1:98] \"5\" \"2\" \"1\" \"0\" ...\n $ nb_abonnements : chr [1:98] \"0\" \"1\" \"3\" \"0\" ...\n\nsummary(ecran)\n\n     age               genre               csp            lieu_de_vie       \n Length:98          Length:98          Length:98          Length:98         \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n                                                                            \n  nb_personnes      revenu           temps_ecran    nb_appareils      \n Min.   :0.000   Length:98          Min.   : 4.50   Length:98         \n 1st Qu.:1.000   Class :character   1st Qu.:26.25   Class :character  \n Median :1.000   Mode  :character   Median :35.00   Mode  :character  \n Mean   :1.622                      Mean   :35.76                     \n 3rd Qu.:3.000                      3rd Qu.:42.00                     \n Max.   :5.000                      Max.   :85.00                     \n                                                                      \n   internet            fibre           forfait_tel        telephone_pro     \n Length:98          Length:98          Length:98          Length:98         \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n                                                                            \n ecran_travail        sommeil             stress              loisir      \n Length:98          Length:98          Length:98          Min.   :  0.00  \n Class :character   Class :character   Class :character   1st Qu.:  4.00  \n Mode  :character   Mode  :character   Mode  :character   Median : 10.00  \n                                                          Mean   : 12.52  \n                                                          3rd Qu.: 15.00  \n                                                          Max.   :100.00  \n                                                          NA's   :7       \n  vie_sociale     ecran_jour        reseaux_sociaux    nb_abonnements    \n Min.   : 0.00   Length:98          Length:98          Length:98         \n 1st Qu.: 5.00   Class :character   Class :character   Class :character  \n Median :12.00   Mode  :character   Mode  :character   Mode  :character  \n Mean   :16.36                                                           \n 3rd Qu.:21.00                                                           \n Max.   :80.00                                                           \n NA's   :13                                                              \n\n\n\n\nMettre en facteurs les variables\n\necran$age &lt;- as.factor(ecran$age)\necran$genre &lt;- as.factor(ecran$genre)\necran$csp &lt;- as.factor(ecran$csp)\necran$lieu_de_vie &lt;- as.factor(ecran$lieu_de_vie)\necran$revenu &lt;- as.factor(ecran$revenu)\necran$nb_appareils &lt;- as.factor(ecran$nb_appareils)\necran$internet &lt;- as.factor(ecran$internet)\necran$fibre &lt;- as.factor(ecran$fibre)\necran$forfait_tel &lt;- as.factor(ecran$forfait_tel)\necran$telephone_pro &lt;- as.factor(ecran$telephone_pro)\necran$ecran_travail &lt;- as.factor(ecran$ecran_travail)\necran$sommeil &lt;- as.factor(ecran$sommeil)\necran$stress &lt;- as.factor(ecran$stress)\necran$ecran_jour &lt;- as.factor(ecran$ecran_jour)\necran$reseaux_sociaux &lt;- as.factor(ecran$reseaux_sociaux)\necran$nb_abonnements &lt;- as.factor(ecran$nb_abonnements)\n\nR√©sum√© des toutes les variables\n\nstr(ecran)\n\ntibble [98 √ó 20] (S3: tbl_df/tbl/data.frame)\n $ age            : Factor w/ 4 levels \"18 - 24 ans\",..: 2 3 3 3 2 4 2 2 3 2 ...\n $ genre          : Factor w/ 2 levels \"Femme\",\"Homme\": 1 1 1 2 1 1 1 2 1 2 ...\n $ csp            : Factor w/ 8 levels \"Agriculteurs exploitants\",..: 4 7 4 4 5 8 5 5 5 5 ...\n $ lieu_de_vie    : Factor w/ 3 levels \"Campagne\",\"P√©riurbaine/ Banlieue\",..: 3 1 2 3 1 1 1 2 1 2 ...\n $ nb_personnes   : num [1:98] 1 2 2 1 5 0 1 3 1 3 ...\n $ revenu         : Factor w/ 9 levels \"&lt; 10 000\",\"10 000 - 20 000\",..: 4 5 8 8 7 2 3 5 4 5 ...\n $ temps_ecran    : num [1:98] 35 35 30 60 64 28 28 35 25 21 ...\n $ nb_appareils   : Factor w/ 11 levels \"1\",\"10\",\"2\",\"3\",..: 4 6 5 5 8 4 4 5 9 7 ...\n $ internet       : Factor w/ 4 levels \"Non\",\"Oui, avec l‚ÄôADSL\",..: 3 3 3 3 2 2 3 3 3 3 ...\n $ fibre          : Factor w/ 2 levels \"Non\",\"Oui\": 2 2 2 2 1 2 2 2 2 2 ...\n $ forfait_tel    : Factor w/ 9 levels \"0\",\"10 et 15 ‚Ç¨\",..: 2 2 3 1 3 8 4 3 3 5 ...\n $ telephone_pro  : Factor w/ 2 levels \"Non\",\"Oui\": 2 1 2 2 1 1 1 2 1 2 ...\n $ ecran_travail  : Factor w/ 5 levels \"Fr√©quemment (Plus de la moiti√© du temps)\",..: 5 1 1 5 5 2 3 3 3 4 ...\n $ sommeil        : Factor w/ 4 levels \"3h ‚Äì 5h\",\"5h ‚Äì 7h\",..: 2 3 3 2 3 3 2 3 3 3 ...\n $ stress         : Factor w/ 5 levels \"Fr√©quemment\",..: 3 3 4 1 1 4 1 4 2 4 ...\n $ loisir         : num [1:98] 3 10 1 6 12 2 6 21 30 20 ...\n $ vie_sociale    : num [1:98] 14 15 2 8 8 7 10 20 80 10 ...\n $ ecran_jour     : Factor w/ 7 levels \"L‚Äôapr√®s midi\",..: 7 1 3 7 1 7 1 7 1 1 ...\n $ reseaux_sociaux: Factor w/ 11 levels \"0\",\"1\",\"2\",\"3\",..: 6 3 2 1 1 1 2 4 3 3 ...\n $ nb_abonnements : Factor w/ 9 levels \"0\",\"1\",\"10\",\"2\",..: 1 2 5 1 2 2 1 2 2 2 ...\n\nsummary(ecran)\n\n             age       genre   \n 18 - 24 ans   :47   Femme:72  \n 25 - 49 ans   :38   Homme:26  \n 50- 69 ans    :10             \n 70 ans et plus: 3             \n                               \n                               \n                               \n                                                                                         csp    \n Employ√©s                                                                                  :34  \n Autres personnes sans activit√© professionnelle (par exemple les ch√¥meurs ou les √©tudiants):31  \n Cadres et professions intellectuelles sup√©rieures                                         :17  \n Professions interm√©diaires                                                                : 6  \n Retrait√©s                                                                                 : 4  \n Ouvriers                                                                                  : 3  \n (Other)                                                                                   : 3  \n                lieu_de_vie  nb_personnes               revenu  \n Campagne             :36   Min.   :0.000   40 000 - 50 000:21  \n P√©riurbaine/ Banlieue:11   1st Qu.:1.000   20 000 - 30 000:18  \n Ville                :51   Median :1.000   10 000 - 20 000:17  \n                            Mean   :1.622   30 000 - 40 000:12  \n                            3rd Qu.:3.000   &lt; 10 000       :11  \n                            Max.   :5.000   (Other)        :10  \n                                            NA's           : 9  \n  temps_ecran     nb_appareils                         internet   fibre   \n Min.   : 4.50   3      :40    Non                         : 1   Non : 5  \n 1st Qu.:26.25   4      :19    Oui, avec l‚ÄôADSL            :17   Oui :84  \n Median :35.00   2      :14    Oui, avec la fibre          :71   NA's: 9  \n Mean   :35.76   5      :10    Oui, avec une autre solution: 9            \n 3rd Qu.:42.00   6      : 5                                               \n Max.   :85.00   7      : 3                                               \n                 (Other): 7                                               \n          forfait_tel telephone_pro\n 15 et 20 ‚Ç¨     :35   Non:33       \n 10 et 15 ‚Ç¨     :20   Oui:65       \n Plus de 35‚Ç¨    :12                \n 20 et 25 ‚Ç¨     :11                \n Entre 5 et 10 ‚Ç¨: 6                \n 30 et 35 ‚Ç¨     : 5                \n (Other)        : 9                \n                                        ecran_travail       sommeil  \n Fr√©quemment (Plus de la moiti√© du temps)      :26    3h ‚Äì 5h   : 9  \n Jamais                                        : 4    5h ‚Äì 7h   :32  \n Parfois (Entre un quart et la moiti√© du temps):17    7h et 9h  :54  \n Rarement                                      :11    Plus de 9h: 3  \n Toute la journ√©e                              :37                   \n NA's                                          : 3                   \n                                                                     \n         stress       loisir        vie_sociale   \n Fr√©quemment:26   Min.   :  0.00   Min.   : 0.00  \n Jamais     : 2   1st Qu.:  4.00   1st Qu.: 5.00  \n Parfois    :39   Median : 10.00   Median :12.00  \n Rarement   :15   Mean   : 12.52   Mean   :16.36  \n Toujours   :16   3rd Qu.: 15.00   3rd Qu.:21.00  \n                  Max.   :100.00   Max.   :80.00  \n                  NA's   :7        NA's   :13     \n                           ecran_jour reseaux_sociaux nb_abonnements\n L‚Äôapr√®s midi                   : 9   3      :24      1      :34    \n L‚Äôapr√®s midi, Le soir          :11   2      :14      2      :22    \n Le matin                       : 5   4      :12      0      :17    \n Le matin, L‚Äôapr√®s midi         : 7   5      :12      3      :12    \n Le matin, L‚Äôapr√®s midi, Le soir: 7   6      : 9      4      : 8    \n Le matin, Le soir              : 3   1      : 8      5      : 2    \n Le soir                        :56   (Other):19      (Other): 3    \n\n\n\n\nValeurs manquantes - visualisation\n\nsum(is.na(ecran))\n\n[1] 41\n\nlapply(ecran, function(x) which(is.na(x)))\n\n$age\ninteger(0)\n\n$genre\ninteger(0)\n\n$csp\ninteger(0)\n\n$lieu_de_vie\ninteger(0)\n\n$nb_personnes\ninteger(0)\n\n$revenu\n[1] 22 24 26 33 44 45 54 84 88\n\n$temps_ecran\ninteger(0)\n\n$nb_appareils\ninteger(0)\n\n$internet\ninteger(0)\n\n$fibre\n[1] 19 25 37 49 50 70 73 80 82\n\n$forfait_tel\ninteger(0)\n\n$telephone_pro\ninteger(0)\n\n$ecran_travail\n[1] 42 60 88\n\n$sommeil\ninteger(0)\n\n$stress\ninteger(0)\n\n$loisir\n[1] 14 15 23 47 54 62 64\n\n$vie_sociale\n [1] 14 15 22 43 44 47 51 52 54 60 62 64 67\n\n$ecran_jour\ninteger(0)\n\n$reseaux_sociaux\ninteger(0)\n\n$nb_abonnements\ninteger(0)\n\n\nNous avons au total 41 valeurs manquantes\nR√©sum√© des variables num√©riques\n\nsummary(select_if(ecran, is.numeric))\n\n  nb_personnes    temps_ecran        loisir        vie_sociale   \n Min.   :0.000   Min.   : 4.50   Min.   :  0.00   Min.   : 0.00  \n 1st Qu.:1.000   1st Qu.:26.25   1st Qu.:  4.00   1st Qu.: 5.00  \n Median :1.000   Median :35.00   Median : 10.00   Median :12.00  \n Mean   :1.622   Mean   :35.76   Mean   : 12.52   Mean   :16.36  \n 3rd Qu.:3.000   3rd Qu.:42.00   3rd Qu.: 15.00   3rd Qu.:21.00  \n Max.   :5.000   Max.   :85.00   Max.   :100.00   Max.   :80.00  \n                                 NA's   :7        NA's   :13     \n\nsapply(select_if(ecran, is.numeric), sd)\n\nnb_personnes  temps_ecran       loisir  vie_sociale \n    1.350947    15.699702           NA           NA \n\n\n\n\nImputation des valeurs manquantes\nL‚Äôalgorithme des k-plus proches voisins utilisera le voisin le plus proche pour l‚Äôimputation\n\necran &lt;- kNN(ecran, dist_var = colnames(ecran), k = 1)\necran &lt;- ecran[, -c(21:40)]\n\n\n\nExportation de la base de donn√©es sous format excel\n\n# write_xlsx(x = ecran, path = \"data/BDD_sans_NA.xlsx\")"
  },
  {
    "objectID": "posts/post-with-code/econometrie_lineaire/econometrie.html#mettre-en-facteurs-les-variables-1",
    "href": "posts/post-with-code/econometrie_lineaire/econometrie.html#mettre-en-facteurs-les-variables-1",
    "title": "√âconom√©trie lin√©aire avanc√©e",
    "section": "Mettre en facteurs les variables",
    "text": "Mettre en facteurs les variables\n\nstr(ecran)\n\ntibble [98 √ó 20] (S3: tbl_df/tbl/data.frame)\n $ age            : chr [1:98] \"25 - 49 ans\" \"50- 69 ans\" \"50- 69 ans\" \"50- 69 ans\" ...\n $ genre          : chr [1:98] \"Femme\" \"Femme\" \"Femme\" \"Homme\" ...\n $ csp            : chr [1:98] \"Cadres et professions intellectuelles sup√©rieures\" \"Professions interm√©diaires\" \"Cadres et professions intellectuelles sup√©rieures\" \"Cadres et professions intellectuelles sup√©rieures\" ...\n $ lieu_de_vie    : chr [1:98] \"Ville\" \"Campagne\" \"P√©riurbaine/ Banlieue\" \"Ville\" ...\n $ nb_personnes   : num [1:98] 1 2 2 1 5 0 1 3 1 3 ...\n $ revenu         : chr [1:98] \"30 000 - 40 000\" \"40 000 - 50 000\" \"70 000 - 80 000\" \"70 000 - 80 000\" ...\n $ temps_ecran    : num [1:98] 35 35 30 60 64 28 28 35 25 21 ...\n $ nb_appareils   : chr [1:98] \"3\" \"5\" \"4\" \"4\" ...\n $ internet       : chr [1:98] \"Oui, avec la fibre\" \"Oui, avec la fibre\" \"Oui, avec la fibre\" \"Oui, avec la fibre\" ...\n $ fibre          : chr [1:98] \"Oui\" \"Oui\" \"Oui\" \"Oui\" ...\n $ forfait_tel    : chr [1:98] \"10 et 15 ‚Ç¨\" \"10 et 15 ‚Ç¨\" \"15 et 20 ‚Ç¨\" \"0\" ...\n $ telephone_pro  : chr [1:98] \"Oui\" \"Non\" \"Oui\" \"Oui\" ...\n $ ecran_travail  : chr [1:98] \"Toute la journ√©e\" \"Fr√©quemment (Plus de la moiti√© du temps)\" \"Fr√©quemment (Plus de la moiti√© du temps)\" \"Toute la journ√©e\" ...\n $ sommeil        : chr [1:98] \"5h ‚Äì 7h\" \"7h et 9h\" \"7h et 9h\" \"5h ‚Äì 7h\" ...\n $ stress         : chr [1:98] \"Parfois\" \"Parfois\" \"Rarement\" \"Fr√©quemment\" ...\n $ loisir         : num [1:98] 3 10 1 6 12 2 6 21 30 20 ...\n $ vie_sociale    : num [1:98] 14 15 2 8 8 7 10 20 80 10 ...\n $ ecran_jour     : chr [1:98] \"Le soir\" \"L‚Äôapr√®s midi\" \"Le matin\" \"Le soir\" ...\n $ reseaux_sociaux: chr [1:98] \"5\" \"2\" \"1\" \"0\" ...\n $ nb_abonnements : chr [1:98] \"0\" \"1\" \"3\" \"0\" ...\n\necran$age &lt;- as.factor(ecran$age)\necran$genre &lt;- as.factor(ecran$genre)\necran$csp &lt;- as.factor(ecran$csp)\necran$lieu_de_vie &lt;- as.factor(ecran$lieu_de_vie)\necran$revenu &lt;- as.factor(ecran$revenu)\necran$nb_appareils &lt;- as.factor(ecran$nb_appareils)\necran$internet &lt;- as.factor(ecran$internet)\necran$fibre &lt;- as.factor(ecran$fibre)\necran$forfait_tel &lt;- as.factor(ecran$forfait_tel)\necran$telephone_pro &lt;- as.factor(ecran$telephone_pro)\necran$ecran_travail &lt;- as.factor(ecran$ecran_travail)\necran$sommeil &lt;- as.factor(ecran$sommeil)\necran$stress &lt;- as.factor(ecran$stress)\necran$ecran_jour &lt;- as.factor(ecran$ecran_jour)\necran$reseaux_sociaux &lt;- as.factor(ecran$reseaux_sociaux)\necran$nb_abonnements &lt;- as.factor(ecran$nb_abonnements)\nstr(ecran)\n\ntibble [98 √ó 20] (S3: tbl_df/tbl/data.frame)\n $ age            : Factor w/ 4 levels \"18 - 24 ans\",..: 2 3 3 3 2 4 2 2 3 2 ...\n $ genre          : Factor w/ 2 levels \"Femme\",\"Homme\": 1 1 1 2 1 1 1 2 1 2 ...\n $ csp            : Factor w/ 8 levels \"Agriculteurs exploitants\",..: 4 7 4 4 5 8 5 5 5 5 ...\n $ lieu_de_vie    : Factor w/ 3 levels \"Campagne\",\"P√©riurbaine/ Banlieue\",..: 3 1 2 3 1 1 1 2 1 2 ...\n $ nb_personnes   : num [1:98] 1 2 2 1 5 0 1 3 1 3 ...\n $ revenu         : Factor w/ 9 levels \"&lt; 10 000\",\"10 000 - 20 000\",..: 4 5 8 8 7 2 3 5 4 5 ...\n $ temps_ecran    : num [1:98] 35 35 30 60 64 28 28 35 25 21 ...\n $ nb_appareils   : Factor w/ 11 levels \"1\",\"10\",\"2\",\"3\",..: 4 6 5 5 8 4 4 5 9 7 ...\n $ internet       : Factor w/ 4 levels \"Non\",\"Oui, avec l‚ÄôADSL\",..: 3 3 3 3 2 2 3 3 3 3 ...\n $ fibre          : Factor w/ 2 levels \"Non\",\"Oui\": 2 2 2 2 1 2 2 2 2 2 ...\n $ forfait_tel    : Factor w/ 9 levels \"0\",\"10 et 15 ‚Ç¨\",..: 2 2 3 1 3 8 4 3 3 5 ...\n $ telephone_pro  : Factor w/ 2 levels \"Non\",\"Oui\": 2 1 2 2 1 1 1 2 1 2 ...\n $ ecran_travail  : Factor w/ 5 levels \"Fr√©quemment (Plus de la moiti√© du temps)\",..: 5 1 1 5 5 2 3 3 3 4 ...\n $ sommeil        : Factor w/ 4 levels \"3h ‚Äì 5h\",\"5h ‚Äì 7h\",..: 2 3 3 2 3 3 2 3 3 3 ...\n $ stress         : Factor w/ 5 levels \"Fr√©quemment\",..: 3 3 4 1 1 4 1 4 2 4 ...\n $ loisir         : num [1:98] 3 10 1 6 12 2 6 21 30 20 ...\n $ vie_sociale    : num [1:98] 14 15 2 8 8 7 10 20 80 10 ...\n $ ecran_jour     : Factor w/ 7 levels \"L‚Äôapr√®s midi\",..: 7 1 3 7 1 7 1 7 1 1 ...\n $ reseaux_sociaux: Factor w/ 11 levels \"0\",\"1\",\"2\",\"3\",..: 6 3 2 1 1 1 2 4 3 3 ...\n $ nb_abonnements : Factor w/ 9 levels \"0\",\"1\",\"10\",\"2\",..: 1 2 5 1 2 2 1 2 2 2 ..."
  },
  {
    "objectID": "posts/post-with-code/econometrie_lineaire/econometrie.html#analyse-univari√©e-des-variables-quantitatives-1",
    "href": "posts/post-with-code/econometrie_lineaire/econometrie.html#analyse-univari√©e-des-variables-quantitatives-1",
    "title": "√âconom√©trie lin√©aire avanc√©e",
    "section": "Analyse univari√©e des variables quantitatives",
    "text": "Analyse univari√©e des variables quantitatives\n\nstr(ecran)\n\ntibble [95 √ó 20] (S3: tbl_df/tbl/data.frame)\n $ age            : Factor w/ 4 levels \"18 - 24 ans\",..: 2 3 3 3 2 4 2 2 2 2 ...\n $ genre          : Factor w/ 2 levels \"Femme\",\"Homme\": 1 1 1 2 1 1 1 2 2 1 ...\n $ csp            : Factor w/ 8 levels \"Agriculteurs exploitants\",..: 4 7 4 4 5 8 5 5 5 2 ...\n $ lieu_de_vie    : Factor w/ 3 levels \"Campagne\",\"P√©riurbaine/ Banlieue\",..: 3 1 2 3 1 1 1 2 2 3 ...\n $ nb_personnes   : num [1:95] 1 2 2 1 5 0 1 3 3 1 ...\n $ revenu         : Factor w/ 9 levels \"&lt; 10 000\",\"10 000 - 20 000\",..: 4 5 8 8 7 2 3 5 5 4 ...\n $ temps_ecran    : num [1:95] 35 35 30 60 64 28 28 35 21 60 ...\n $ nb_appareils   : Factor w/ 11 levels \"1\",\"10\",\"2\",\"3\",..: 4 6 5 5 8 4 4 5 7 5 ...\n $ internet       : Factor w/ 4 levels \"Non\",\"Oui, avec l‚ÄôADSL\",..: 3 3 3 3 2 2 3 3 3 3 ...\n $ fibre          : Factor w/ 2 levels \"Non\",\"Oui\": 2 2 2 2 1 2 2 2 2 2 ...\n $ forfait_tel    : Factor w/ 9 levels \"0\",\"10 et 15 ‚Ç¨\",..: 2 2 3 1 3 8 4 3 5 3 ...\n $ telephone_pro  : Factor w/ 2 levels \"Non\",\"Oui\": 2 1 2 2 1 1 1 2 2 2 ...\n $ ecran_travail  : Factor w/ 5 levels \"Fr√©quemment (Plus de la moiti√© du temps)\",..: 5 1 1 5 5 2 3 3 4 5 ...\n $ sommeil        : Factor w/ 4 levels \"3h ‚Äì 5h\",\"5h ‚Äì 7h\",..: 2 3 3 2 3 3 2 3 3 1 ...\n $ stress         : Factor w/ 5 levels \"Fr√©quemment\",..: 3 3 4 1 1 4 1 4 4 5 ...\n $ loisir         : num [1:95] 3 10 1 6 12 2 6 21 20 4 ...\n $ vie_sociale    : num [1:95] 14 15 2 8 8 7 10 20 10 14 ...\n $ ecran_jour     : Factor w/ 7 levels \"L‚Äôapr√®s midi\",..: 7 1 3 7 1 7 1 7 1 4 ...\n $ reseaux_sociaux: Factor w/ 11 levels \"0\",\"1\",\"2\",\"3\",..: 6 3 2 1 1 1 2 4 3 7 ...\n $ nb_abonnements : Factor w/ 9 levels \"0\",\"1\",\"10\",\"2\",..: 1 2 5 1 2 2 1 2 2 5 ...\n\nsummary(ecran)\n\n             age       genre   \n 18 - 24 ans   :45   Femme:70  \n 25 - 49 ans   :38   Homme:25  \n 50- 69 ans    : 9             \n 70 ans et plus: 3             \n                               \n                               \n                               \n                                                                                         csp    \n Employ√©s                                                                                  :33  \n Autres personnes sans activit√© professionnelle (par exemple les ch√¥meurs ou les √©tudiants):29  \n Cadres et professions intellectuelles sup√©rieures                                         :17  \n Professions interm√©diaires                                                                : 6  \n Retrait√©s                                                                                 : 4  \n Ouvriers                                                                                  : 3  \n (Other)                                                                                   : 3  \n                lieu_de_vie  nb_personnes               revenu  \n Campagne             :35   Min.   :0.000   40 000 - 50 000:26  \n P√©riurbaine/ Banlieue:11   1st Qu.:1.000   20 000 - 30 000:22  \n Ville                :49   Median :1.000   10 000 - 20 000:17  \n                            Mean   :1.663   &lt; 10 000       :11  \n                            3rd Qu.:3.000   30 000 - 40 000:10  \n                            Max.   :5.000   50 000 - 60 000: 3  \n                                            (Other)        : 6  \n  temps_ecran     nb_appareils                         internet  fibre   \n Min.   : 4.50   3      :39    Non                         : 1   Non: 6  \n 1st Qu.:26.50   4      :18    Oui, avec l‚ÄôADSL            :17   Oui:89  \n Median :35.00   2      :14    Oui, avec la fibre          :68           \n Mean   :35.88   5      :10    Oui, avec une autre solution: 9           \n 3rd Qu.:45.00   6      : 5                                              \n Max.   :85.00   7      : 3                                              \n                 (Other): 6                                              \n          forfait_tel telephone_pro\n 15 et 20 ‚Ç¨     :34   Non:32       \n 10 et 15 ‚Ç¨     :20   Oui:63       \n Plus de 35‚Ç¨    :11                \n 20 et 25 ‚Ç¨     :10                \n Entre 5 et 10 ‚Ç¨: 6                \n 30 et 35 ‚Ç¨     : 5                \n (Other)        : 9                \n                                        ecran_travail       sommeil  \n Fr√©quemment (Plus de la moiti√© du temps)      :25    3h ‚Äì 5h   : 9  \n Jamais                                        : 4    5h ‚Äì 7h   :32  \n Parfois (Entre un quart et la moiti√© du temps):16    7h et 9h  :51  \n Rarement                                      :12    Plus de 9h: 3  \n Toute la journ√©e                              :38                   \n                                                                     \n                                                                     \n         stress       loisir      vie_sociale   \n Fr√©quemment:26   Min.   : 0.0   Min.   : 0.00  \n Jamais     : 1   1st Qu.: 4.0   1st Qu.: 5.00  \n Parfois    :38   Median :10.0   Median :10.00  \n Rarement   :15   Mean   :11.3   Mean   :15.12  \n Toujours   :15   3rd Qu.:15.0   3rd Qu.:20.50  \n                  Max.   :42.0   Max.   :50.00  \n                                                \n                           ecran_jour reseaux_sociaux nb_abonnements\n L‚Äôapr√®s midi                   : 8   3      :24      1      :33    \n L‚Äôapr√®s midi, Le soir          :10   2      :13      2      :21    \n Le matin                       : 5   5      :12      0      :17    \n Le matin, L‚Äôapr√®s midi         : 7   4      :11      3      :12    \n Le matin, L‚Äôapr√®s midi, Le soir: 7   6      : 9      4      : 8    \n Le matin, Le soir              : 3   1      : 8      5      : 2    \n Le soir                        :55   (Other):18      (Other): 2    \n\nsummary(select_if(ecran, is.numeric))\n\n  nb_personnes    temps_ecran        loisir      vie_sociale   \n Min.   :0.000   Min.   : 4.50   Min.   : 0.0   Min.   : 0.00  \n 1st Qu.:1.000   1st Qu.:26.50   1st Qu.: 4.0   1st Qu.: 5.00  \n Median :1.000   Median :35.00   Median :10.0   Median :10.00  \n Mean   :1.663   Mean   :35.88   Mean   :11.3   Mean   :15.12  \n 3rd Qu.:3.000   3rd Qu.:45.00   3rd Qu.:15.0   3rd Qu.:20.50  \n Max.   :5.000   Max.   :85.00   Max.   :42.0   Max.   :50.00  \n\n\n\nHistogrammes\n\npar(mfrow = c(2,2))\nhist(ecran$nb_personnes, main= \"R√©partition du nombre de personnes dans le foyer\", xlab=\"personnes\",ylab = \"nombre d'individus\", col = \"blue4\")\nhist(ecran$temps_ecran, main= \"R√©partition du temps d'√©crans\", xlab=\"dur√©e\", ylab = \"nombre d'individus\", col = \"blue4\")\nhist(ecran$loisir, main= \"R√©partition du temps consacr√© aux loisirs\", xlab=\"dur√©e\", ylab = \"nombre d'individus\", col = \"blue4\")\nhist(ecran$vie_sociale, main= \"R√©partition du temps consacr√© √† la vie sociale\", xlab=\"dur√©e\",ylab = \"nombre d'individus\", col = \"blue4\")"
  },
  {
    "objectID": "posts/post-with-code/econometrie_lineaire/econometrie.html#analyse-bivari√©e-des-variables-quantitatives",
    "href": "posts/post-with-code/econometrie_lineaire/econometrie.html#analyse-bivari√©e-des-variables-quantitatives",
    "title": "√âconom√©trie lin√©aire avanc√©e",
    "section": "Analyse bivari√©e des variables quantitatives",
    "text": "Analyse bivari√©e des variables quantitatives\nNous observons √† l‚Äôaide de nuages de points le lien entre ‚Äútemps_ecran‚Äù (y) et les variables explicatives\n\npar(mfrow = c(2,2))\npurrr::map2(\n.x = c(\"nb_personnes\", \"loisir\", \"vie_sociale\"),\n.y = c(\"temps_ecran\", \"temps_ecran\", \"temps_ecran\"),\n.f = ~ ggplot(ecran) +\naes(x = get(.x), y = get(.y)) +\ngeom_point() +\nlabs(x = .x, y = .y) +\nggtitle(paste(\"Corr√©lation entre\", .x, \"et\", .y)) +\ntheme_classic() +\ntheme(plot.title = element_text(hjust = 0.5, size = 12, face=\"bold\"))\n)\n\n[[1]]\n\n\n\n\n\n\n\n\n\n\n[[2]]\n\n\n\n\n\n\n\n\n\n\n[[3]]\n\n\n\n\n\n\n\n\n\n\nCorrelation\nSous forme de matrice :\n\nmydata &lt;- ecran[,c(\"nb_personnes\",\"temps_ecran\",\"loisir\",\"vie_sociale\")]\ncorr_mat=cor(mydata,method=\"s\")\ncorr_mat\n\n             nb_personnes temps_ecran     loisir vie_sociale\nnb_personnes   1.00000000  0.04474111 -0.0634830  0.08655831\ntemps_ecran    0.04474111  1.00000000 -0.2013519 -0.07046714\nloisir        -0.06348300 -0.20135191  1.0000000  0.44449510\nvie_sociale    0.08655831 -0.07046714  0.4444951  1.00000000\n\ncorrplot(corr_mat, method = 'number',type=\"upper\", tl.srt=45)\n\n\n\n\n\n\n\ncorrplot(corr_mat,type=\"upper\")\n\n\n\n\n\n\n\n\nNous pouvons voir que la corr√©lation est tr√®s faible entre chaque variable explicative.De plus, la variable √† expliquer a une corr√©lation n√©gative avec les variables ‚Äúloisir‚Äù et ‚Äúvie_sociale‚Äù et positive avec la variable ‚Äúnb_personnes‚Äù.\n\nTest de normalit√© des variables numeriques :\n\n\nks.test(ecran$nb_personnes,\"pnorm\",mean(ecran$nb_personnes),sd(ecran$nb_personnes))\n\nWarning in ks.test.default(ecran$nb_personnes, \"pnorm\",\nmean(ecran$nb_personnes), : ties should not be present for the\nKolmogorov-Smirnov test\n\n\n\n    Asymptotic one-sample Kolmogorov-Smirnov test\n\ndata:  ecran$nb_personnes\nD = 0.24631, p-value = 1.972e-05\nalternative hypothesis: two-sided\n\nks.test(ecran$loisir,\"pnorm\",mean(ecran$loisir),sd(ecran$loisir))\n\nWarning in ks.test.default(ecran$loisir, \"pnorm\", mean(ecran$loisir),\nsd(ecran$loisir)): ties should not be present for the Kolmogorov-Smirnov test\n\n\n\n    Asymptotic one-sample Kolmogorov-Smirnov test\n\ndata:  ecran$loisir\nD = 0.15804, p-value = 0.01738\nalternative hypothesis: two-sided\n\nks.test(ecran$vie_sociale,\"pnorm\",mean(ecran$vie_sociale),sd(ecran$vie_sociale))\n\nWarning in ks.test.default(ecran$vie_sociale, \"pnorm\", mean(ecran$vie_sociale),\n: ties should not be present for the Kolmogorov-Smirnov test\n\n\n\n    Asymptotic one-sample Kolmogorov-Smirnov test\n\ndata:  ecran$vie_sociale\nD = 0.18785, p-value = 0.00245\nalternative hypothesis: two-sided\n\n\nLes variables ne suivent pas la loi normale , on va donc utiliser le coefficient de Spearman\nSous forme de tableau :\n\ncor(ecran[,c(\"nb_personnes\",\"temps_ecran\",\"loisir\",\"vie_sociale\")],\n    use=\"complete.obs\",method = c(\"spearman\"))\n\n             nb_personnes temps_ecran     loisir vie_sociale\nnb_personnes   1.00000000  0.04474111 -0.0634830  0.08655831\ntemps_ecran    0.04474111  1.00000000 -0.2013519 -0.07046714\nloisir        -0.06348300 -0.20135191  1.0000000  0.44449510\nvie_sociale    0.08655831 -0.07046714  0.4444951  1.00000000\n\n\nPour avoir un aper√ßu visuel, nous utilisons une matrice de corr√©lation compl√©t√©e par les nuages de points et les histogrammes.\n\n#chart.Correlation(mydata, histogram=TRUE, pch=19,method = c(\"spearman\"))\n\n\nConclusion : Pas de corr√©lation entre ces variables explicatives donc nous allons les conserver."
  },
  {
    "objectID": "posts/post-with-code/econometrie_lineaire/econometrie.html#variables-quali-en-binaire",
    "href": "posts/post-with-code/econometrie_lineaire/econometrie.html#variables-quali-en-binaire",
    "title": "√âconom√©trie lin√©aire avanc√©e",
    "section": "Variables quali en binaire",
    "text": "Variables quali en binaire\n\nR√©seaux sociaux\n\n\nsummary(ecran2$reseaux_sociaux)\n\n         0          1          2          3          4          5          6 \n         5          8         13         24         11         12          9 \n         7          8          9 Plus de 10 \n         6          3          0          4 \n\necran2 &lt;- ecran2 |&gt; \n  mutate(cat_reseau_0_2 = ifelse(reseaux_sociaux %in% c(\"0\",\"1\",\"2\"), 1, 0),\n         cat_reseau_3_5 = ifelse(reseaux_sociaux %in% c(\"3\",\"4\",\"5\"), 1, 0),\n         cat_reseau_6_sup6 = ifelse(reseaux_sociaux %in% c(\"6\",\"7\",\"8\",\"9\",\"Plus de 10\"), 1, 0))\n\n\nAge\n\n\necran2 &lt;- ecran2 |&gt; \n  mutate(cat_18_24 = ifelse(age == \"18 - 24 ans\", 1, 0),\n         cat_25_49 = ifelse(age == \"25 - 49 ans\", 1, 0),\n         cat_plus_50 = ifelse(age %in% c(\"50- 69 ans\",\"70 ans et plus\"), 1, 0))\n\n\nForfait t√©l√©phone\n\n\nsummary(ecran2$forfait_tel)\n\n              0      10 et 15 ‚Ç¨      15 et 20 ‚Ç¨      20 et 25 ‚Ç¨      25 et 30 ‚Ç¨ \n              2              20              34              10               3 \n     30 et 35 ‚Ç¨ Entre 5 et 10 ‚Ç¨   Moins  de 5 ‚Ç¨     Plus de 35‚Ç¨ \n              5               6               4              11 \n\necran2 &lt;- ecran2 |&gt; \n  mutate(tel_inf_15 = ifelse(forfait_tel %in% c(\"0\", \"Moins  de 5 ‚Ç¨\",\"Entre 5 et 10 ‚Ç¨\",\"10 et 15 ‚Ç¨\" ), 1, 0),\n         tel_15_25 = ifelse(forfait_tel %in% c(\"15 et 20 ‚Ç¨\",\"20 et 25 ‚Ç¨\"), 1, 0),\n         tel_sup_25 = ifelse(forfait_tel %in% c(\"25 et 30 ‚Ç¨\",\"30 et 35 ‚Ç¨\",\"Plus de 35‚Ç¨\"), 1, 0))\n\n\nNombre d‚Äôappareils\n\n\nsummary(ecran2$nb_appareils)\n\n         1         10          2          3          4          5          6 \n         1          2         14         39         18         10          5 \n         7          8          9 Plus de 10 \n         3          0          1          2 \n\necran2 &lt;- ecran2 |&gt; \n  mutate(appareils_1_2 = ifelse(nb_appareils %in% c(\"1\", \"2\"), 1, 0),\n         appareils_3_4 = ifelse(nb_appareils %in% c(\"3\", \"4\"), 1, 0),\n         appareils_plus_4 = ifelse(nb_appareils %in% c(\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\"Plus de 10\"), 1, 0))\n\n\nNombre d‚Äôabonnements\n\n\nsummary(ecran2$nb_abonnements)\n\n         0          1         10          2          3          4          5 \n        17         33          1         21         12          8          2 \n         7 Plus de 10 \n         0          1 \n\necran2 &lt;- ecran2 |&gt; \n  mutate(abo_0 = ifelse(nb_abonnements == \"0\", 1, 0),\n         abo_1 = ifelse(nb_abonnements == \"1\", 1, 0),\n         abo_2 = ifelse(nb_abonnements == \"2\", 1, 0),\n         abo_3_sup = ifelse(nb_abonnements %in% c(\"3\",\"4\",\"5\",\"6\",\"7\", \"8\",\"9\",\"10\",\"Plus de 10\"), 1, 0))\n\n\nGenre\n\n\nsummary(ecran2$genre)\n\nFemme Homme \n   70    25 \n\necran2 &lt;- ecran2 |&gt; \n  mutate(homme = ifelse(genre == \"Homme\", 1, 0),\n         femme = ifelse(genre == \"Femme\", 1, 0))\n\n\nLieu de vie\n\n\nsummary(ecran2$lieu_de_vie)\n\n             Campagne P√©riurbaine/ Banlieue                 Ville \n                   35                    11                    49 \n\necran2 &lt;- ecran2 |&gt; \n  mutate(pas_ville = ifelse(lieu_de_vie %in% c(\"Campagne\",\"P√©riurbaine/ Banlieue\"), 1, 0),\n         ville = ifelse(lieu_de_vie == \"Ville\", 1, 0))\n\n\nCSP\n\n\nsummary(ecran2$csp)\n\n                                                                  Agriculteurs exploitants \n                                                                                         1 \n                                                      Artisan/commer√ßant/Chef d‚Äôentreprise \n                                                                                         2 \nAutres personnes sans activit√© professionnelle (par exemple les ch√¥meurs ou les √©tudiants) \n                                                                                        29 \n                                         Cadres et professions intellectuelles sup√©rieures \n                                                                                        17 \n                                                                                  Employ√©s \n                                                                                        33 \n                                                                                  Ouvriers \n                                                                                         3 \n                                                                Professions interm√©diaires \n                                                                                         6 \n                                                                                 Retrait√©s \n                                                                                         4 \n\necran2 &lt;- ecran2 |&gt; \n  mutate(cat_Employes = ifelse(csp == \"Employ√©s\", 1, 0),\n         cat_sans_activite = ifelse(csp == \"Autres personnes sans activit√© professionnelle (par exemple les ch√¥meurs ou les √©tudiants)\", 1, 0),\n         cat_cadres = ifelse(csp == \"Cadres et professions intellectuelles sup√©rieures\", 1, 0),\n         cat_autres = ifelse(csp %in% c(\"Professions interm√©diaires\",\"Retrait√©s\", \"Ouvriers\", \"Artisan/commer√ßant/Chef d‚Äôentreprise\",\"Agriculteurs exploitants\"), 1, 0))\n\n\nEcran au travail\n\n\nsummary(ecran2$ecran_travail)\n\n      Fr√©quemment (Plus de la moiti√© du temps) \n                                            25 \n                                        Jamais \n                                             4 \nParfois (Entre un quart et la moiti√© du temps) \n                                            16 \n                                      Rarement \n                                            12 \n                              Toute la journ√©e \n                                            38 \n\necran2 &lt;- ecran2 |&gt; \n  mutate(ecran_travail_plein = ifelse(ecran_travail == \"Toute la journ√©e\", 1, 0),\n         ecran_travail_bcp = ifelse(ecran_travail == \"Fr√©quemment (Plus de la moiti√© du temps)\", 1, 0),\n         ecran_travail_peu = ifelse(ecran_travail %in% c(\"Parfois (Entre un quart et la moiti√© du temps)\",\"Rarement\",\"Jamais\"), 1, 0))\n\n\nInternet\n\n\nsummary(ecran2$internet)\n\n                         Non             Oui, avec l‚ÄôADSL \n                           1                           17 \n          Oui, avec la fibre Oui, avec une autre solution \n                          68                            9 \n\necran2 &lt;- ecran2 |&gt; \n  mutate(pas_internet = ifelse(internet == \"Non\", 1, 0),\n         internet_autre = ifelse(internet %in% c(\"Oui, avec l‚ÄôADSL\", \"Oui, avec une autre solution\"), 1, 0),\n         internet_fibre = ifelse(internet == \"Oui, avec la fibre\", 1, 0))\n\n\nSommeil\n\n\nsummary(ecran2$sommeil)\n\n   3h ‚Äì 5h    5h ‚Äì 7h   7h et 9h Plus de 9h \n         9         32         51          3 \n\necran2 &lt;- ecran2 |&gt; \n  mutate(nuit_inf_7 = ifelse(sommeil %in% c(\"3h ‚Äì 5h\", \"5h ‚Äì 7h\"), 1, 0),\n         nuit_5_7 = ifelse(sommeil %in% c(\"7h et 9h\",\"Plus de 9h\"), 1, 0))\n\n\nEcran jour\n\n\nsummary(ecran2$ecran_jour)\n\n                   L‚Äôapr√®s midi           L‚Äôapr√®s midi, Le soir \n                              8                              10 \n                       Le matin          Le matin, L‚Äôapr√®s midi \n                              5                               7 \nLe matin, L‚Äôapr√®s midi, Le soir               Le matin, Le soir \n                              7                               3 \n                        Le soir \n                             55 \n\necran2 &lt;- ecran2 |&gt; \n  mutate(jour_3 = ifelse(ecran_jour == \"Le matin, L‚Äôapr√®s midi, Le soir\", 1, 0),\n         jour_2 = ifelse(ecran_jour %in% c(\"L‚Äôapr√®s midi, Le soir\", \"Le matin, L‚Äôapr√®s midi\", \"Le matin, Le soir\"), 1, 0),\n         jour_1 = ifelse(ecran_jour %in% c(\"L‚Äôapr√®s midi\",\"Le matin\",\"Le soir\"), 1, 0))"
  },
  {
    "objectID": "posts/post-with-code/econometrie_lineaire/econometrie.html#variables-instruments",
    "href": "posts/post-with-code/econometrie_lineaire/econometrie.html#variables-instruments",
    "title": "√âconom√©trie lin√©aire avanc√©e",
    "section": "Variables instruments",
    "text": "Variables instruments\n\nRevenu\n\n\nsummary(ecran2$revenu)\n\n       &lt; 10 000 10 000 - 20 000 20 000 - 30 000 30 000 - 40 000 40 000 - 50 000 \n             11              17              22              10              26 \n50 000 - 60 000 60 000 - 70 000 70 000 - 80 000  80 000 et plus \n              3               2               3               1 \n\necran2 &lt;- ecran2 |&gt; \n  mutate(cat_inf_20000 = ifelse(revenu %in% c(\"&lt; 10 000\",\"10 000 - 20 000\"), 1, 0),\n         cat_20_40000 = ifelse(revenu %in% c(\"20 000 - 30 000\",\"30 000 - 40 000\"), 1, 0),\n         cat_sup_40000 = ifelse(revenu %in% c(\"40 000 - 50 000\",\"50 000 - 60 000\",\"60 000 - 70 000\", \"70 000 - 80 000\",\"80 000 et plus\"), 1, 0))\n\n\nFibre\n\n\nsummary(ecran2$fibre)\n\nNon Oui \n  6  89 \n\necran2 &lt;- ecran2 |&gt; \n  mutate(fibre_oui = ifelse(fibre == \"Oui\", 1, 0),\n         fibre_non = ifelse(fibre == \"Non\", 1, 0))\n\n\nT√©l√©phone pro\n\n\nsummary(ecran2$telephone_pro)\n\nNon Oui \n 32  63 \n\necran2 &lt;- ecran2 |&gt; \n  mutate(tel_pro_non = ifelse(telephone_pro == \"Non\", 1, 0),\n         tel_pro_oui = ifelse(telephone_pro == \"Oui\", 1, 0))\n\n\nStress\n\n\nsummary(ecran2$stress)\n\nFr√©quemment      Jamais     Parfois    Rarement    Toujours \n         26           1          38          15          15 \n\necran2 &lt;- ecran2 |&gt; \n  mutate(stress_toujours = ifelse(stress == \"Toujours\", 1, 0),\n         stress_bcp = ifelse(stress == \"Fr√©quemment\", 1, 0),\n         stress_peu = ifelse(stress %in% c(\"Parfois\", \"Rarement\",\"Jamais\"),1, 0))\n\n\nsummary(ecran2)\n\n             age       genre   \n 18 - 24 ans   :45   Femme:70  \n 25 - 49 ans   :38   Homme:25  \n 50- 69 ans    : 9             \n 70 ans et plus: 3             \n                               \n                               \n                               \n                                                                                         csp    \n Employ√©s                                                                                  :33  \n Autres personnes sans activit√© professionnelle (par exemple les ch√¥meurs ou les √©tudiants):29  \n Cadres et professions intellectuelles sup√©rieures                                         :17  \n Professions interm√©diaires                                                                : 6  \n Retrait√©s                                                                                 : 4  \n Ouvriers                                                                                  : 3  \n (Other)                                                                                   : 3  \n                lieu_de_vie  nb_personnes               revenu  \n Campagne             :35   Min.   :0.000   40 000 - 50 000:26  \n P√©riurbaine/ Banlieue:11   1st Qu.:1.000   20 000 - 30 000:22  \n Ville                :49   Median :1.000   10 000 - 20 000:17  \n                            Mean   :1.663   &lt; 10 000       :11  \n                            3rd Qu.:3.000   30 000 - 40 000:10  \n                            Max.   :5.000   50 000 - 60 000: 3  \n                                            (Other)        : 6  \n  temps_ecran     nb_appareils                         internet  fibre   \n Min.   : 4.50   3      :39    Non                         : 1   Non: 6  \n 1st Qu.:26.50   4      :18    Oui, avec l‚ÄôADSL            :17   Oui:89  \n Median :35.00   2      :14    Oui, avec la fibre          :68           \n Mean   :35.88   5      :10    Oui, avec une autre solution: 9           \n 3rd Qu.:45.00   6      : 5                                              \n Max.   :85.00   7      : 3                                              \n                 (Other): 6                                              \n          forfait_tel telephone_pro\n 15 et 20 ‚Ç¨     :34   Non:32       \n 10 et 15 ‚Ç¨     :20   Oui:63       \n Plus de 35‚Ç¨    :11                \n 20 et 25 ‚Ç¨     :10                \n Entre 5 et 10 ‚Ç¨: 6                \n 30 et 35 ‚Ç¨     : 5                \n (Other)        : 9                \n                                        ecran_travail       sommeil  \n Fr√©quemment (Plus de la moiti√© du temps)      :25    3h ‚Äì 5h   : 9  \n Jamais                                        : 4    5h ‚Äì 7h   :32  \n Parfois (Entre un quart et la moiti√© du temps):16    7h et 9h  :51  \n Rarement                                      :12    Plus de 9h: 3  \n Toute la journ√©e                              :38                   \n                                                                     \n                                                                     \n         stress       loisir      vie_sociale   \n Fr√©quemment:26   Min.   : 0.0   Min.   : 0.00  \n Jamais     : 1   1st Qu.: 4.0   1st Qu.: 5.00  \n Parfois    :38   Median :10.0   Median :10.00  \n Rarement   :15   Mean   :11.3   Mean   :15.12  \n Toujours   :15   3rd Qu.:15.0   3rd Qu.:20.50  \n                  Max.   :42.0   Max.   :50.00  \n                                                \n                           ecran_jour reseaux_sociaux nb_abonnements\n L‚Äôapr√®s midi                   : 8   3      :24      1      :33    \n L‚Äôapr√®s midi, Le soir          :10   2      :13      2      :21    \n Le matin                       : 5   5      :12      0      :17    \n Le matin, L‚Äôapr√®s midi         : 7   4      :11      3      :12    \n Le matin, L‚Äôapr√®s midi, Le soir: 7   6      : 9      4      : 8    \n Le matin, Le soir              : 3   1      : 8      5      : 2    \n Le soir                        :55   (Other):18      (Other): 2    \n cat_reseau_0_2   cat_reseau_3_5   cat_reseau_6_sup6   cat_18_24     \n Min.   :0.0000   Min.   :0.0000   Min.   :0.0000    Min.   :0.0000  \n 1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000    1st Qu.:0.0000  \n Median :0.0000   Median :0.0000   Median :0.0000    Median :0.0000  \n Mean   :0.2737   Mean   :0.4947   Mean   :0.2316    Mean   :0.4737  \n 3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:0.0000    3rd Qu.:1.0000  \n Max.   :1.0000   Max.   :1.0000   Max.   :1.0000    Max.   :1.0000  \n                                                                     \n   cat_25_49    cat_plus_50       tel_inf_15       tel_15_25        tel_sup_25 \n Min.   :0.0   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Min.   :0.0  \n 1st Qu.:0.0   1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0  \n Median :0.0   Median :0.0000   Median :0.0000   Median :0.0000   Median :0.0  \n Mean   :0.4   Mean   :0.1263   Mean   :0.3368   Mean   :0.4632   Mean   :0.2  \n 3rd Qu.:1.0   3rd Qu.:0.0000   3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:0.0  \n Max.   :1.0   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000   Max.   :1.0  \n                                                                               \n appareils_1_2    appareils_3_4 appareils_plus_4     abo_0       \n Min.   :0.0000   Min.   :0.0   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.0000   1st Qu.:0.0   1st Qu.:0.0000   1st Qu.:0.0000  \n Median :0.0000   Median :1.0   Median :0.0000   Median :0.0000  \n Mean   :0.1579   Mean   :0.6   Mean   :0.2421   Mean   :0.1789  \n 3rd Qu.:0.0000   3rd Qu.:1.0   3rd Qu.:0.0000   3rd Qu.:0.0000  \n Max.   :1.0000   Max.   :1.0   Max.   :1.0000   Max.   :1.0000  \n                                                                 \n     abo_1            abo_2          abo_3_sup          homme       \n Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000  \n Median :0.0000   Median :0.0000   Median :0.0000   Median :0.0000  \n Mean   :0.3474   Mean   :0.2211   Mean   :0.2526   Mean   :0.2632  \n 3rd Qu.:1.0000   3rd Qu.:0.0000   3rd Qu.:0.5000   3rd Qu.:1.0000  \n Max.   :1.0000   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000  \n                                                                    \n     femme          pas_ville          ville         cat_Employes   \n Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000  \n Median :1.0000   Median :0.0000   Median :1.0000   Median :0.0000  \n Mean   :0.7368   Mean   :0.4842   Mean   :0.5158   Mean   :0.3474  \n 3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:1.0000  \n Max.   :1.0000   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000  \n                                                                    \n cat_sans_activite   cat_cadres       cat_autres     ecran_travail_plein\n Min.   :0.0000    Min.   :0.0000   Min.   :0.0000   Min.   :0.0        \n 1st Qu.:0.0000    1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0        \n Median :0.0000    Median :0.0000   Median :0.0000   Median :0.0        \n Mean   :0.3053    Mean   :0.1789   Mean   :0.1684   Mean   :0.4        \n 3rd Qu.:1.0000    3rd Qu.:0.0000   3rd Qu.:0.0000   3rd Qu.:1.0        \n Max.   :1.0000    Max.   :1.0000   Max.   :1.0000   Max.   :1.0        \n                                                                        \n ecran_travail_bcp ecran_travail_peu  pas_internet     internet_autre  \n Min.   :0.0000    Min.   :0.0000    Min.   :0.00000   Min.   :0.0000  \n 1st Qu.:0.0000    1st Qu.:0.0000    1st Qu.:0.00000   1st Qu.:0.0000  \n Median :0.0000    Median :0.0000    Median :0.00000   Median :0.0000  \n Mean   :0.2632    Mean   :0.3368    Mean   :0.01053   Mean   :0.2737  \n 3rd Qu.:1.0000    3rd Qu.:1.0000    3rd Qu.:0.00000   3rd Qu.:1.0000  \n Max.   :1.0000    Max.   :1.0000    Max.   :1.00000   Max.   :1.0000  \n                                                                       \n internet_fibre     nuit_inf_7        nuit_5_7          jour_3       \n Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Min.   :0.00000  \n 1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.00000  \n Median :1.0000   Median :0.0000   Median :1.0000   Median :0.00000  \n Mean   :0.7158   Mean   :0.4316   Mean   :0.5684   Mean   :0.07368  \n 3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:0.00000  \n Max.   :1.0000   Max.   :1.0000   Max.   :1.0000   Max.   :1.00000  \n                                                                     \n     jour_2           jour_1       cat_inf_20000     cat_20_40000   \n Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000  \n Median :0.0000   Median :1.0000   Median :0.0000   Median :0.0000  \n Mean   :0.2105   Mean   :0.7158   Mean   :0.2947   Mean   :0.3368  \n 3rd Qu.:0.0000   3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:1.0000  \n Max.   :1.0000   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000  \n                                                                    \n cat_sup_40000      fibre_oui        fibre_non        tel_pro_non    \n Min.   :0.0000   Min.   :0.0000   Min.   :0.00000   Min.   :0.0000  \n 1st Qu.:0.0000   1st Qu.:1.0000   1st Qu.:0.00000   1st Qu.:0.0000  \n Median :0.0000   Median :1.0000   Median :0.00000   Median :0.0000  \n Mean   :0.3684   Mean   :0.9368   Mean   :0.06316   Mean   :0.3368  \n 3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:0.00000   3rd Qu.:1.0000  \n Max.   :1.0000   Max.   :1.0000   Max.   :1.00000   Max.   :1.0000  \n                                                                     \n  tel_pro_oui     stress_toujours    stress_bcp       stress_peu    \n Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000  \n Median :1.0000   Median :0.0000   Median :0.0000   Median :1.0000  \n Mean   :0.6632   Mean   :0.1579   Mean   :0.2737   Mean   :0.5684  \n 3rd Qu.:1.0000   3rd Qu.:0.0000   3rd Qu.:1.0000   3rd Qu.:1.0000  \n Max.   :1.0000   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000  \n                                                                    \n\nstr(ecran2)\n\ntibble [95 √ó 65] (S3: tbl_df/tbl/data.frame)\n $ age                : Factor w/ 4 levels \"18 - 24 ans\",..: 2 3 3 3 2 4 2 2 2 2 ...\n $ genre              : Factor w/ 2 levels \"Femme\",\"Homme\": 1 1 1 2 1 1 1 2 2 1 ...\n $ csp                : Factor w/ 8 levels \"Agriculteurs exploitants\",..: 4 7 4 4 5 8 5 5 5 2 ...\n $ lieu_de_vie        : Factor w/ 3 levels \"Campagne\",\"P√©riurbaine/ Banlieue\",..: 3 1 2 3 1 1 1 2 2 3 ...\n $ nb_personnes       : num [1:95] 1 2 2 1 5 0 1 3 3 1 ...\n $ revenu             : Factor w/ 9 levels \"&lt; 10 000\",\"10 000 - 20 000\",..: 4 5 8 8 7 2 3 5 5 4 ...\n $ temps_ecran        : num [1:95] 35 35 30 60 64 28 28 35 21 60 ...\n $ nb_appareils       : Factor w/ 11 levels \"1\",\"10\",\"2\",\"3\",..: 4 6 5 5 8 4 4 5 7 5 ...\n $ internet           : Factor w/ 4 levels \"Non\",\"Oui, avec l‚ÄôADSL\",..: 3 3 3 3 2 2 3 3 3 3 ...\n $ fibre              : Factor w/ 2 levels \"Non\",\"Oui\": 2 2 2 2 1 2 2 2 2 2 ...\n $ forfait_tel        : Factor w/ 9 levels \"0\",\"10 et 15 ‚Ç¨\",..: 2 2 3 1 3 8 4 3 5 3 ...\n $ telephone_pro      : Factor w/ 2 levels \"Non\",\"Oui\": 2 1 2 2 1 1 1 2 2 2 ...\n $ ecran_travail      : Factor w/ 5 levels \"Fr√©quemment (Plus de la moiti√© du temps)\",..: 5 1 1 5 5 2 3 3 4 5 ...\n $ sommeil            : Factor w/ 4 levels \"3h ‚Äì 5h\",\"5h ‚Äì 7h\",..: 2 3 3 2 3 3 2 3 3 1 ...\n $ stress             : Factor w/ 5 levels \"Fr√©quemment\",..: 3 3 4 1 1 4 1 4 4 5 ...\n $ loisir             : num [1:95] 3 10 1 6 12 2 6 21 20 4 ...\n $ vie_sociale        : num [1:95] 14 15 2 8 8 7 10 20 10 14 ...\n $ ecran_jour         : Factor w/ 7 levels \"L‚Äôapr√®s midi\",..: 7 1 3 7 1 7 1 7 1 4 ...\n $ reseaux_sociaux    : Factor w/ 11 levels \"0\",\"1\",\"2\",\"3\",..: 6 3 2 1 1 1 2 4 3 7 ...\n $ nb_abonnements     : Factor w/ 9 levels \"0\",\"1\",\"10\",\"2\",..: 1 2 5 1 2 2 1 2 2 5 ...\n $ cat_reseau_0_2     : num [1:95] 0 1 1 1 1 1 1 0 1 0 ...\n $ cat_reseau_3_5     : num [1:95] 1 0 0 0 0 0 0 1 0 0 ...\n $ cat_reseau_6_sup6  : num [1:95] 0 0 0 0 0 0 0 0 0 1 ...\n $ cat_18_24          : num [1:95] 0 0 0 0 0 0 0 0 0 0 ...\n $ cat_25_49          : num [1:95] 1 0 0 0 1 0 1 1 1 1 ...\n $ cat_plus_50        : num [1:95] 0 1 1 1 0 1 0 0 0 0 ...\n $ tel_inf_15         : num [1:95] 1 1 0 1 0 1 0 0 0 0 ...\n $ tel_15_25          : num [1:95] 0 0 1 0 1 0 1 1 0 1 ...\n $ tel_sup_25         : num [1:95] 0 0 0 0 0 0 0 0 1 0 ...\n $ appareils_1_2      : num [1:95] 0 0 0 0 0 0 0 0 0 0 ...\n $ appareils_3_4      : num [1:95] 1 0 1 1 0 1 1 1 0 1 ...\n $ appareils_plus_4   : num [1:95] 0 1 0 0 1 0 0 0 1 0 ...\n $ abo_0              : num [1:95] 1 0 0 1 0 0 1 0 0 0 ...\n $ abo_1              : num [1:95] 0 1 0 0 1 1 0 1 1 0 ...\n $ abo_2              : num [1:95] 0 0 0 0 0 0 0 0 0 0 ...\n $ abo_3_sup          : num [1:95] 0 0 1 0 0 0 0 0 0 1 ...\n $ homme              : num [1:95] 0 0 0 1 0 0 0 1 1 0 ...\n $ femme              : num [1:95] 1 1 1 0 1 1 1 0 0 1 ...\n $ pas_ville          : num [1:95] 0 1 1 0 1 1 1 1 1 0 ...\n $ ville              : num [1:95] 1 0 0 1 0 0 0 0 0 1 ...\n $ cat_Employes       : num [1:95] 0 0 0 0 1 0 1 1 1 0 ...\n $ cat_sans_activite  : num [1:95] 0 0 0 0 0 0 0 0 0 0 ...\n $ cat_cadres         : num [1:95] 1 0 1 1 0 0 0 0 0 0 ...\n $ cat_autres         : num [1:95] 0 1 0 0 0 1 0 0 0 1 ...\n $ ecran_travail_plein: num [1:95] 1 0 0 1 1 0 0 0 0 1 ...\n $ ecran_travail_bcp  : num [1:95] 0 1 1 0 0 0 0 0 0 0 ...\n $ ecran_travail_peu  : num [1:95] 0 0 0 0 0 1 1 1 1 0 ...\n $ pas_internet       : num [1:95] 0 0 0 0 0 0 0 0 0 0 ...\n $ internet_autre     : num [1:95] 0 0 0 0 1 1 0 0 0 0 ...\n $ internet_fibre     : num [1:95] 1 1 1 1 0 0 1 1 1 1 ...\n $ nuit_inf_7         : num [1:95] 1 0 0 1 0 0 1 0 0 1 ...\n $ nuit_5_7           : num [1:95] 0 1 1 0 1 1 0 1 1 0 ...\n $ jour_3             : num [1:95] 0 0 0 0 0 0 0 0 0 0 ...\n $ jour_2             : num [1:95] 0 0 0 0 0 0 0 0 0 1 ...\n $ jour_1             : num [1:95] 1 1 1 1 1 1 1 1 1 0 ...\n $ cat_inf_20000      : num [1:95] 0 0 0 0 0 1 0 0 0 0 ...\n $ cat_20_40000       : num [1:95] 1 0 0 0 0 0 1 0 0 1 ...\n $ cat_sup_40000      : num [1:95] 0 1 1 1 1 0 0 1 1 0 ...\n $ fibre_oui          : num [1:95] 1 1 1 1 0 1 1 1 1 1 ...\n $ fibre_non          : num [1:95] 0 0 0 0 1 0 0 0 0 0 ...\n $ tel_pro_non        : num [1:95] 0 1 0 0 1 1 1 0 0 0 ...\n $ tel_pro_oui        : num [1:95] 1 0 1 1 0 0 0 1 1 1 ...\n $ stress_toujours    : num [1:95] 0 0 0 0 0 0 0 0 0 1 ...\n $ stress_bcp         : num [1:95] 0 0 0 1 1 0 1 0 0 0 ...\n $ stress_peu         : num [1:95] 1 1 1 0 0 1 0 1 1 0 ..."
  },
  {
    "objectID": "posts/post-with-code/econometrie_lineaire/econometrie.html#r√©cup√©ration-de-donn√©es",
    "href": "posts/post-with-code/econometrie_lineaire/econometrie.html#r√©cup√©ration-de-donn√©es",
    "title": "√âconom√©trie lin√©aire avanc√©e",
    "section": "R√©cup√©ration de donn√©es",
    "text": "R√©cup√©ration de donn√©es\nUtilisation de la base de donn√©es √©cran sans les instruments et sans la r√©f√©rence\n\nload(here(\"data\", \"ecran_sans_instru_sansref.rda\"))\necran &lt;- ecran_sans_instru_sansref\ndim(ecran)\n\n[1] 95 26\n\n\n\nstr(ecran)\n\ntibble [95 √ó 26] (S3: tbl_df/tbl/data.frame)\n $ temps_ecran      : num [1:95] 35 35 30 60 64 28 28 35 21 60 ...\n $ loisir           : num [1:95] 3 10 1 6 12 2 6 21 20 4 ...\n $ vie_sociale      : num [1:95] 14 15 2 8 8 7 10 20 10 14 ...\n $ cat_reseau_0_2   : num [1:95] 0 1 1 1 1 1 1 0 1 0 ...\n $ cat_reseau_6_sup6: num [1:95] 0 0 0 0 0 0 0 0 0 1 ...\n $ cat_25_49        : num [1:95] 1 0 0 0 1 0 1 1 1 1 ...\n $ cat_plus_50      : num [1:95] 0 1 1 1 0 1 0 0 0 0 ...\n $ tel_inf_15       : num [1:95] 1 1 0 1 0 1 0 0 0 0 ...\n $ tel_sup_25       : num [1:95] 0 0 0 0 0 0 0 0 1 0 ...\n $ appareils_1_2    : num [1:95] 0 0 0 0 0 0 0 0 0 0 ...\n $ appareils_plus_4 : num [1:95] 0 1 0 0 1 0 0 0 1 0 ...\n $ abo_0            : num [1:95] 1 0 0 1 0 0 1 0 0 0 ...\n $ abo_2            : num [1:95] 0 0 0 0 0 0 0 0 0 0 ...\n $ abo_3_sup        : num [1:95] 0 0 1 0 0 0 0 0 0 1 ...\n $ homme            : num [1:95] 0 0 0 1 0 0 0 1 1 0 ...\n $ pas_ville        : num [1:95] 0 1 1 0 1 1 1 1 1 0 ...\n $ cat_sans_activite: num [1:95] 0 0 0 0 0 0 0 0 0 0 ...\n $ cat_cadres       : num [1:95] 1 0 1 1 0 0 0 0 0 0 ...\n $ cat_autres       : num [1:95] 0 1 0 0 0 1 0 0 0 1 ...\n $ ecran_travail_bcp: num [1:95] 0 1 1 0 0 0 0 0 0 0 ...\n $ ecran_travail_peu: num [1:95] 0 0 0 0 0 1 1 1 1 0 ...\n $ pas_internet     : num [1:95] 0 0 0 0 0 0 0 0 0 0 ...\n $ internet_autre   : num [1:95] 0 0 0 0 1 1 0 0 0 0 ...\n $ nuit_inf_7       : num [1:95] 1 0 0 1 0 0 1 0 0 1 ...\n $ jour_3           : num [1:95] 0 0 0 0 0 0 0 0 0 0 ...\n $ jour_2           : num [1:95] 0 0 0 0 0 0 0 0 0 1 ...\n\n\n\necran[4:26] &lt;- lapply(ecran[4:26], as.factor)\nstr(ecran)\n\ntibble [95 √ó 26] (S3: tbl_df/tbl/data.frame)\n $ temps_ecran      : num [1:95] 35 35 30 60 64 28 28 35 21 60 ...\n $ loisir           : num [1:95] 3 10 1 6 12 2 6 21 20 4 ...\n $ vie_sociale      : num [1:95] 14 15 2 8 8 7 10 20 10 14 ...\n $ cat_reseau_0_2   : Factor w/ 2 levels \"0\",\"1\": 1 2 2 2 2 2 2 1 2 1 ...\n $ cat_reseau_6_sup6: Factor w/ 2 levels \"0\",\"1\": 1 1 1 1 1 1 1 1 1 2 ...\n $ cat_25_49        : Factor w/ 2 levels \"0\",\"1\": 2 1 1 1 2 1 2 2 2 2 ...\n $ cat_plus_50      : Factor w/ 2 levels \"0\",\"1\": 1 2 2 2 1 2 1 1 1 1 ...\n $ tel_inf_15       : Factor w/ 2 levels \"0\",\"1\": 2 2 1 2 1 2 1 1 1 1 ...\n $ tel_sup_25       : Factor w/ 2 levels \"0\",\"1\": 1 1 1 1 1 1 1 1 2 1 ...\n $ appareils_1_2    : Factor w/ 2 levels \"0\",\"1\": 1 1 1 1 1 1 1 1 1 1 ...\n $ appareils_plus_4 : Factor w/ 2 levels \"0\",\"1\": 1 2 1 1 2 1 1 1 2 1 ...\n $ abo_0            : Factor w/ 2 levels \"0\",\"1\": 2 1 1 2 1 1 2 1 1 1 ...\n $ abo_2            : Factor w/ 2 levels \"0\",\"1\": 1 1 1 1 1 1 1 1 1 1 ...\n $ abo_3_sup        : Factor w/ 2 levels \"0\",\"1\": 1 1 2 1 1 1 1 1 1 2 ...\n $ homme            : Factor w/ 2 levels \"0\",\"1\": 1 1 1 2 1 1 1 2 2 1 ...\n $ pas_ville        : Factor w/ 2 levels \"0\",\"1\": 1 2 2 1 2 2 2 2 2 1 ...\n $ cat_sans_activite: Factor w/ 2 levels \"0\",\"1\": 1 1 1 1 1 1 1 1 1 1 ...\n $ cat_cadres       : Factor w/ 2 levels \"0\",\"1\": 2 1 2 2 1 1 1 1 1 1 ...\n $ cat_autres       : Factor w/ 2 levels \"0\",\"1\": 1 2 1 1 1 2 1 1 1 2 ...\n $ ecran_travail_bcp: Factor w/ 2 levels \"0\",\"1\": 1 2 2 1 1 1 1 1 1 1 ...\n $ ecran_travail_peu: Factor w/ 2 levels \"0\",\"1\": 1 1 1 1 1 2 2 2 2 1 ...\n $ pas_internet     : Factor w/ 2 levels \"0\",\"1\": 1 1 1 1 1 1 1 1 1 1 ...\n $ internet_autre   : Factor w/ 2 levels \"0\",\"1\": 1 1 1 1 2 2 1 1 1 1 ...\n $ nuit_inf_7       : Factor w/ 2 levels \"0\",\"1\": 2 1 1 2 1 1 2 1 1 2 ...\n $ jour_3           : Factor w/ 2 levels \"0\",\"1\": 1 1 1 1 1 1 1 1 1 1 ...\n $ jour_2           : Factor w/ 2 levels \"0\",\"1\": 1 1 1 1 1 1 1 1 1 2 ...\n\nsummary(ecran)\n\n  temps_ecran        loisir      vie_sociale    cat_reseau_0_2\n Min.   : 4.50   Min.   : 0.0   Min.   : 0.00   0:69          \n 1st Qu.:26.50   1st Qu.: 4.0   1st Qu.: 5.00   1:26          \n Median :35.00   Median :10.0   Median :10.00                 \n Mean   :35.88   Mean   :11.3   Mean   :15.12                 \n 3rd Qu.:45.00   3rd Qu.:15.0   3rd Qu.:20.50                 \n Max.   :85.00   Max.   :42.0   Max.   :50.00                 \n cat_reseau_6_sup6 cat_25_49 cat_plus_50 tel_inf_15 tel_sup_25 appareils_1_2\n 0:73              0:57      0:83        0:63       0:76       0:80         \n 1:22              1:38      1:12        1:32       1:19       1:15         \n                                                                            \n                                                                            \n                                                                            \n                                                                            \n appareils_plus_4 abo_0  abo_2  abo_3_sup homme  pas_ville cat_sans_activite\n 0:72             0:78   0:74   0:71      0:70   0:49      0:66             \n 1:23             1:17   1:21   1:24      1:25   1:46      1:29             \n                                                                            \n                                                                            \n                                                                            \n                                                                            \n cat_cadres cat_autres ecran_travail_bcp ecran_travail_peu pas_internet\n 0:78       0:79       0:70              0:63              0:94        \n 1:17       1:16       1:25              1:32              1: 1        \n                                                                       \n                                                                       \n                                                                       \n                                                                       \n internet_autre nuit_inf_7 jour_3 jour_2\n 0:69           0:54       0:88   0:75  \n 1:26           1:41       1: 7   1:20"
  },
  {
    "objectID": "posts/post-with-code/econometrie_lineaire/econometrie.html#hypoth√®ses-sous-jacentes-√†-la-m√©thode-des-moindres-carr√©s-ordinaires",
    "href": "posts/post-with-code/econometrie_lineaire/econometrie.html#hypoth√®ses-sous-jacentes-√†-la-m√©thode-des-moindres-carr√©s-ordinaires",
    "title": "√âconom√©trie lin√©aire avanc√©e",
    "section": "Hypoth√®ses sous-jacentes √† la m√©thode des Moindres Carr√©s Ordinaires",
    "text": "Hypoth√®ses sous-jacentes √† la m√©thode des Moindres Carr√©s Ordinaires\n\nMod√®le lin√©aire\nMod√®le avec toutes les variables, ne sera pas utilis√© dans notre analyse - voir m√©thode STEP\n\nmodele1 &lt;- lm(temps_ecran ~ loisir + vie_sociale + cat_reseau_0_2 + cat_reseau_6_sup6 + cat_25_49 + cat_plus_50 + tel_inf_15 + tel_sup_25 + appareils_1_2 + appareils_plus_4 + abo_0 + abo_2 + abo_3_sup + homme + pas_ville + cat_sans_activite + cat_cadres + cat_autres + ecran_travail_bcp + ecran_travail_peu + pas_internet + internet_autre + nuit_inf_7 + jour_3 + jour_2, data=ecran)\n\nsummary(modele1)\n\n\nCall:\nlm(formula = temps_ecran ~ loisir + vie_sociale + cat_reseau_0_2 + \n    cat_reseau_6_sup6 + cat_25_49 + cat_plus_50 + tel_inf_15 + \n    tel_sup_25 + appareils_1_2 + appareils_plus_4 + abo_0 + abo_2 + \n    abo_3_sup + homme + pas_ville + cat_sans_activite + cat_cadres + \n    cat_autres + ecran_travail_bcp + ecran_travail_peu + pas_internet + \n    internet_autre + nuit_inf_7 + jour_3 + jour_2, data = ecran)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-24.503  -8.912  -0.815   7.447  35.558 \n\nCoefficients:\n                   Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)         41.0805     7.1099   5.778 1.99e-07 ***\nloisir              -0.1057     0.2103  -0.503  0.61685    \nvie_sociale         -0.1800     0.1570  -1.147  0.25549    \ncat_reseau_0_21     -4.0312     5.0592  -0.797  0.42830    \ncat_reseau_6_sup61   9.5478     5.3309   1.791  0.07767 .  \ncat_25_491          -1.4514     5.2351  -0.277  0.78242    \ncat_plus_501        -4.1037     8.7089  -0.471  0.63898    \ntel_inf_151         -2.6226     4.0957  -0.640  0.52409    \ntel_sup_251         -7.9265     4.6422  -1.707  0.09223 .  \nappareils_1_21      11.5977     5.2763   2.198  0.03130 *  \nappareils_plus_41    3.1873     4.2642   0.747  0.45734    \nabo_01              -8.1979     5.0213  -1.633  0.10710    \nabo_21              -6.6294     5.0091  -1.323  0.19005    \nabo_3_sup1          -3.6215     4.4330  -0.817  0.41678    \nhomme1               6.1879     4.1251   1.500  0.13816    \npas_ville1           6.5266     3.7579   1.737  0.08689 .  \ncat_sans_activite1   2.1203     4.8246   0.439  0.66169    \ncat_cadres1          8.2460     5.8445   1.411  0.16277    \ncat_autres1          3.4039     5.7235   0.595  0.55397    \necran_travail_bcp1 -11.5269     4.6034  -2.504  0.01465 *  \necran_travail_peu1 -12.9224     4.7990  -2.693  0.00889 ** \npas_internet1       13.0349    16.3039   0.799  0.42675    \ninternet_autre1      6.6674     3.8631   1.726  0.08884 .  \nnuit_inf_71         -0.7751     3.6011  -0.215  0.83020    \njour_31             -1.0904     6.9154  -0.158  0.87518    \njour_21              3.6913     4.1450   0.891  0.37627    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 14.56 on 69 degrees of freedom\nMultiple R-squared:  0.3839,    Adjusted R-squared:  0.1607 \nF-statistic:  1.72 on 25 and 69 DF,  p-value: 0.04026\n\n\nR = 38.39% de la variance dans temps_ecran est expliqu√©e par le mod√®le. R- ajust√© : 16,07\nP-value associ√©e au test de Fisher &lt; 0,05 : H0 est refus√©e ==&gt; 0.040, le mod√®le, dans son ensemble, est statistiquement significatif, mais pas tr√®s fortement.\n\nplot(modele1)\n\nWarning: not plotting observations with leverage one:\n  70\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nD‚Äôapr√®s les graphiques, le mod√®le1\n\nNe suivent pas a priori une loi normale\nNe v√©rifie pas √† priori l‚Äôhypoth√®se d‚Äôhomosc√©dasticit√© car variance de la variable Mesure augmente √† droite\n\n\nTest de normalit√© de r√©sidus\nHypoth√®se H0 : les erreurs suivent une loi normale au seuil de risque de 5 %\n\nqqnorm(residuals(modele1))\n\n\n\n\n\n\n\nhist(residuals(modele1), breaks=30, main=\"Histogramme des R√©sidus\", xlab=\"R√©sidus\")\n\n\n\n\n\n\n\nresidus&lt;-residuals(modele1) \n\nshapiro.test(residus)\n\n\n    Shapiro-Wilk normality test\n\ndata:  residus\nW = 0.98024, p-value = 0.1614\n\nks.test(residus, \"pnorm\", mean = mean(residus), sd = sd(residus))\n\n\n    Exact one-sample Kolmogorov-Smirnov test\n\ndata:  residus\nD = 0.071371, p-value = 0.6913\nalternative hypothesis: two-sided\n\n\np-value = 0,16 : hypoth√®se de normalit√© des r√©sidus OK au seuil de risque de 5%\n\n\nTest d‚ÄôhomosceÃÅdasticiteÃÅ des reÃÅsidus\nH0 = homoscedasticit√©\n\nbptest(modele1)\n\n\n    studentized Breusch-Pagan test\n\ndata:  modele1\nBP = 12.07, df = 25, p-value = 0.986\n\n\np-value = 0.986 &gt; 0,05 On ne rejette pas l‚Äôhypoth√®se nulle (√† savoir l‚Äôhomosc√©dasticit√© des r√©sidus)\n\n\nTest de la lin√©arit√© de la forme fonctionnelle\n\nreset(modele1)\n\n\n    RESET test\n\ndata:  modele1\nRESET = 1.168, df1 = 2, df2 = 67, p-value = 0.3172\n\n\np-value = 0.3172\np_value&gt; 0,05 forme fonctionnelle lineÃÅaire du modeÃÄle speÃÅcifieÃÅ est accepteÃÅe au seuil de 5%\n\n\nAnalyse des observations influen√ßant l‚Äôestimation\n\nplot(cooks.distance(modele1),type=\"h\")\n\n\n\n\n\n\n\n# OU option avec le seuil \n\ncooks_d &lt;- cooks.distance(modele1)\n# Afficher le graphique des distances de Cook\nplot(cooks_d, type=\"h\", main=\"Distances de Cook\")\n\n\n\n\n\n\n\n\n\n\nV√©rification de la multicolin√©arit√© apr√®s estimation\n\nvif(modele1)\n\n           loisir       vie_sociale    cat_reseau_0_2 cat_reseau_6_sup6 \n         1.554233          1.759555          2.280368          2.266505 \n        cat_25_49       cat_plus_50        tel_inf_15        tel_sup_25 \n         2.947956          3.751426          1.679451          1.545372 \n    appareils_1_2  appareils_plus_4             abo_0             abo_2 \n         1.659030          1.495394          1.660307          1.936374 \n        abo_3_sup             homme         pas_ville cat_sans_activite \n         1.662921          1.478839          1.580720          2.212485 \n       cat_cadres        cat_autres ecran_travail_bcp ecran_travail_peu \n         2.249285          2.056297          1.841631          2.305654 \n     pas_internet    internet_autre        nuit_inf_7            jour_3 \n         1.240853          1.329520          1.425768          1.462933 \n           jour_2 \n         1.279849 \n\n\nPas de probleÃÄme de multicolineÃÅariteÃÅ entre les diffeÃÅrentes variables explicatives du modeÃÄle"
  },
  {
    "objectID": "posts/post-with-code/creation_package/index.html",
    "href": "posts/post-with-code/creation_package/index.html",
    "title": "Package olympicsWeather",
    "section": "",
    "text": "Le package olympicsWeather offre une solution simple et interactive pour acc√©der aux pr√©visions m√©t√©orologiques des sites olympiques. Utilisant des graphiques interactifs, il permet aux utilisateurs d‚Äôexplorer en profondeur les donn√©es m√©t√©orologiques.\n¬© Illustration AdobeStock"
  },
  {
    "objectID": "posts/post-with-code/creation_package/index.html#caract√©ristiques",
    "href": "posts/post-with-code/creation_package/index.html#caract√©ristiques",
    "title": "Package olympicsWeather",
    "section": "Caract√©ristiques",
    "text": "Caract√©ristiques\n\nGraphiques interactifs : Gr√¢ce √† plotly, le package produit des visualisations interactives des donn√©es m√©t√©orologiques, am√©liorant ainsi l‚Äôexp√©rience utilisateur par une exploration dynamique des pr√©visions.\nFacilit√© d‚Äôutilisation : Les pr√©visions sont accessibles via des coordonn√©es GPS ou des noms de lieux, facilitant l‚Äôacc√®s aux donn√©es m√©t√©orologiques sans expertise technique sp√©cifique.\nInt√©gration de packages R : olympicsWeather s‚Äôappuie sur des packages tels que httr pour les requ√™tes web, jsonlite pour le traitement JSON, et tibble pour la manipulation de donn√©es, optimisant ainsi le processus d‚Äôanalyse."
  },
  {
    "objectID": "posts/post-with-code/creation_package/index.html#installation",
    "href": "posts/post-with-code/creation_package/index.html#installation",
    "title": "Package olympicsWeather",
    "section": "Installation",
    "text": "Installation\nLe package olympicsWeather est disponible sur GitHub et peut √™tre install√© en utilisant le package remotes. Si vous n‚Äôavez pas encore install√© remotes, commencez par le faire avec la commande install.packages(\"remotes\").\nEnsuite, installez olympicsWeather en utilisant la commande suivante :\n\nremotes::install_github(\"isabel6198/olympicsWeather\")"
  },
  {
    "objectID": "posts/post-with-code/creation_package/index.html#fonctions",
    "href": "posts/post-with-code/creation_package/index.html#fonctions",
    "title": "Package olympicsWeather",
    "section": "Fonctions",
    "text": "Fonctions\nLes fonctions qui sont incluses dans le package sont :\n\nperform_request: Envoie une requ√™te √† l‚ÄôAPI Open-Meteo avec des coordonn√©es GPS et retourne les donn√©es m√©t√©orologiques horaires sous forme de tibble.\nunnest_data: Transforme les donn√©es m√©t√©orologiques brutes en un tibble structur√©, extrayant des informations telles que la date, l‚Äôheure, et les temp√©ratures.\nget_forecast: Fonction g√©n√©rique qui, selon le type d‚Äôentr√©e (adresse ou coordonn√©es GPS), renvoie des pr√©visions m√©t√©orologiques sous forme de tibble.\naddress_to_gps et get_gps_coordinate: Convertissent une adresse textuelle en coordonn√©es GPS √† l‚Äôaide du service de g√©ocodage OpenStreetMap.\nget_forecast.numeric et get_forecast.character: Sp√©cialisent get_forecast pour traiter respectivement des coordonn√©es GPS num√©riques et des adresses textuelles, renvoyant les pr√©visions m√©t√©orologiques pour l‚Äôemplacement sp√©cifi√©.\nvisualiser_temperatures: Cr√©e un graphique interactif avec plotly √† partir d‚Äôun tibble m√©t√©orologique, affichant la temp√©rature et la temp√©rature ressentie au fil du temps.\n\nChaque fonction est con√ßue pour simplifier l‚Äôacc√®s et la manipulation des donn√©es m√©t√©orologiques, depuis la r√©cup√©ration des informations depuis une API externe jusqu‚Äô√† la visualisation interactive des pr√©visions."
  },
  {
    "objectID": "posts/post-with-code/creation_package/index.html#exemples",
    "href": "posts/post-with-code/creation_package/index.html#exemples",
    "title": "Package olympicsWeather",
    "section": "Exemples",
    "text": "Exemples\n\nSite: le stade de France\n\n# librairie \nlibrary(olympicsWeather)\n\n\n# Obtenir les pr√©visions m√©t√©orologiques √† partir d'un lieu exacte\nmeteo &lt;- get_forecast(\"Stade de France, Saint-Denis, France\")\nmeteo\n\n# A tibble: 168 √ó 5\n   date_heure          temperature_celsius temperature_ressentie\n   &lt;dttm&gt;                            &lt;dbl&gt;                 &lt;dbl&gt;\n 1 2024-09-28 00:00:00                11.1                   9.5\n 2 2024-09-28 01:00:00                10.6                   9.3\n 3 2024-09-28 02:00:00                 9.7                   7.9\n 4 2024-09-28 03:00:00                 8.8                   7  \n 5 2024-09-28 04:00:00                 8.2                   6.3\n 6 2024-09-28 05:00:00                 8                     6.2\n 7 2024-09-28 06:00:00                 7.7                   5.9\n 8 2024-09-28 07:00:00                 8.5                   6.7\n 9 2024-09-28 08:00:00                10.2                   8.2\n10 2024-09-28 09:00:00                12.1                  10.1\n# ‚Ñπ 158 more rows\n# ‚Ñπ 2 more variables: precipitation_proba &lt;int&gt;, precipitation_mm &lt;dbl&gt;\n\n# Visualer les donn√©es\ngraphique &lt;- visualiser_temperatures(meteo)\ngraphique\n\n\n\n\n\n\n\nCoordonn√©es GPS\n\n# Obtenir les pr√©visions m√©t√©orologiques √† partir de Coordonn√©es GPS \ngps &lt;- c( 43.276703, 5.334791)\n\n# Obtenir les pr√©visions m√©t√©orologiques\nmeteo &lt;- get_forecast(gps)\nmeteo\n\n# A tibble: 168 √ó 5\n   date_heure          temperature_celsius temperature_ressentie\n   &lt;dttm&gt;                            &lt;dbl&gt;                 &lt;dbl&gt;\n 1 2024-09-28 00:00:00                16.9                  11.8\n 2 2024-09-28 01:00:00                16.8                  11.5\n 3 2024-09-28 02:00:00                16.8                  11.4\n 4 2024-09-28 03:00:00                15.9                  11.9\n 5 2024-09-28 04:00:00                15.6                  11  \n 6 2024-09-28 05:00:00                16                    10.5\n 7 2024-09-28 06:00:00                15.9                  10.3\n 8 2024-09-28 07:00:00                16.1                  10  \n 9 2024-09-28 08:00:00                16.8                  10.1\n10 2024-09-28 09:00:00                17.8                  11.3\n# ‚Ñπ 158 more rows\n# ‚Ñπ 2 more variables: precipitation_proba &lt;int&gt;, precipitation_mm &lt;dbl&gt;\n\n# Visualer les donn√©es\ngraphique &lt;- visualiser_temperatures(meteo)\ngraphique\n\n\n\n\n\n\n\nTahiti\n\n# Obtenir les pr√©visions m√©t√©orologiques \nmeteo &lt;- get_forecast(\"Tahiti\")\n# Visualer les donn√©es\ngraphique &lt;- visualiser_temperatures(meteo)\ngraphique"
  },
  {
    "objectID": "posts/post-with-code/biostatistiques/Final_projet.html",
    "href": "posts/post-with-code/biostatistiques/Final_projet.html",
    "title": "Biostatistiques",
    "section": "",
    "text": "Notre projet explore diverses strat√©gies pour g√©rer les valeurs manquantes, en s‚Äôappuyant sur un dataset provenant de la plateforme https://www.kaggle.com/datasets. Au c≈ìur de notre approche se trouve une analyse descriptive, qui nous a permis de comprendre la distribution des donn√©es en examinant les tendances et la dispersion √† travers des mesures comme la moyenne, la m√©diane et l‚Äô√©cart-type, et en utilisant des outils visuels tels que les histogrammes et les box-plots.\nConcernant le remplacement des N/A, nous avons opt√© pour trois techniques adapt√©es aux caract√©ristiques de notre dataset : La r√©gression lin√©aire, l‚Äôimputation multiple par MICE (Multiple Imputation by Chained Equations) et l‚Äôimputation multiple par Analyse en Composantes Principales (ACP)."
  },
  {
    "objectID": "posts/post-with-code/biostatistiques/Final_projet.html#librairies",
    "href": "posts/post-with-code/biostatistiques/Final_projet.html#librairies",
    "title": "Biostatistiques",
    "section": "Librairies",
    "text": "Librairies\n\nsuppressPackageStartupMessages({\nlibrary(naniar)\nlibrary(tidyverse)\nlibrary(dplyr)\nlibrary(EnvStats)\nlibrary(corrplot)\nlibrary(RColorBrewer)\nlibrary(FactoMineR)\nlibrary(factoextra)\nlibrary(missMDA)\nlibrary(mice)\nlibrary(ggplot2)\nlibrary(car)\nlibrary(tinytex)\nlibrary(ranger)\nlibrary(here)\n})\n\nWarning in check_dep_version(): ABI version mismatch: \nlme4 was built with Matrix ABI version 1\nCurrent Matrix ABI version is 0\nPlease re-install lme4 from source or restore original 'Matrix' package\n\nvecteur_couleur &lt;- c(\"F\"=\"darkred\", \"M\"=\"darkgreen\", \"I\"=\"darkblue\" )"
  },
  {
    "objectID": "posts/post-with-code/biostatistiques/Final_projet.html#t√©l√©chargement-de-la-base-de-donn√©es",
    "href": "posts/post-with-code/biostatistiques/Final_projet.html#t√©l√©chargement-de-la-base-de-donn√©es",
    "title": "Biostatistiques",
    "section": "T√©l√©chargement de la base de donn√©es",
    "text": "T√©l√©chargement de la base de donn√©es\n\ncrabe &lt;- read.csv(here(\"data\", \"CrabAgePrediction.csv\"))"
  },
  {
    "objectID": "posts/post-with-code/biostatistiques/Final_projet.html#pr√©sentation-de-la-base-de-donn√©es",
    "href": "posts/post-with-code/biostatistiques/Final_projet.html#pr√©sentation-de-la-base-de-donn√©es",
    "title": "Biostatistiques",
    "section": "Pr√©sentation de la base de donn√©es",
    "text": "Pr√©sentation de la base de donn√©es\n\nglimpse(crabe)\n\nRows: 3,893\nColumns: 9\n$ Sex            &lt;chr&gt; \"F\", \"M\", \"I\", \"F\", \"I\", \"F\", \"F\", \"M\", \"I\", \"I\", \"M\", ‚Ä¶\n$ Length         &lt;dbl&gt; 1.4375, 0.8875, 1.0375, 1.1750, 0.8875, 1.5500, 1.3000,‚Ä¶\n$ Diameter       &lt;dbl&gt; 1.1750, 0.6500, 0.7750, 0.8875, 0.6625, 1.1625, 1.0000,‚Ä¶\n$ Height         &lt;dbl&gt; 0.4125, 0.2125, 0.2500, 0.2500, 0.2125, 0.3500, 0.3250,‚Ä¶\n$ Weight         &lt;dbl&gt; 24.635715, 5.400580, 7.952035, 13.480187, 6.903103, 28.‚Ä¶\n$ Shucked.Weight &lt;dbl&gt; 12.332033, 2.296310, 3.231843, 4.748541, 3.458639, 13.5‚Ä¶\n$ Viscera.Weight &lt;dbl&gt; 5.5848515, 1.3749507, 1.6017467, 2.2821347, 1.4883488, ‚Ä¶\n$ Shell.Weight   &lt;dbl&gt; 6.7471810, 1.5592225, 2.7640763, 5.2446575, 1.7009700, ‚Ä¶\n$ Age            &lt;int&gt; 9, 6, 6, 10, 6, 8, 15, 10, 13, 7, 6, 10, 9, 10, 11, 12,‚Ä¶\n\n\n√Ä titre informatif, notre base de donn√©es est une base sur des crabes destin√©s √† la consommation dans des restaurants de la r√©gion de Boston.\nLe type de crabe le plus commun √† cet effet est le crabe bleu am√©ricain qui est natif des c√¥tes atlantiques am√©ricaines.\nLe crabe bleu am√©ricain est p√™ch√© et consomm√© en grande quantit√©, principalement aux Etats-Unis et au Mexique. Chaque ann√©e, 58 000 tonnes sont pr√©lev√©es ; son importance √©conomique et culinaire est consid√©rable sur la c√¥te est des Etats-Unis, en particulier dans les √©tats de Louisiane, du Maryland, de Caroline du Nord, du New Jersey et du Massachusetts."
  },
  {
    "objectID": "posts/post-with-code/biostatistiques/Final_projet.html#transformation-de-la-bd",
    "href": "posts/post-with-code/biostatistiques/Final_projet.html#transformation-de-la-bd",
    "title": "Biostatistiques",
    "section": "Transformation de la BD",
    "text": "Transformation de la BD\n\nTraduction des noms de nos variables en fran√ßais\n\nnames(crabe) &lt;- c(\"sexe\", \"longueur\", \"diametre\", \"hauteur\", \"poids\",\"poids.chair\", \"poids.visceres\", \"poids.coquille\", \"age\")\n\nNotre base de donn√©es est donc compos√©e de 3894 crabes bleus et de 9 variables qui sont :\nVariables qualitatives :\n\nSexe du crabe - M√¢le (Male), Femelle (Female) et Ind√©termin√© (Indeterminate).\n\nVariables quantitatives :\n\nLongueur : longueur du crabe (en pieds ; 1 pied = 30,48 cm).\nDiam√®tre : diam√®tre du crabe (en pieds ; 1 pied = 30,48 cm).\nHauteur : hauteur du crabe (en pieds ; 1 pied = 30,48 cm).\nPoids : poids du crabe (en onces ; 1 livre = 16 onces).\nPoids √©visc√©r√© : poids du crabe sans sa coquille (en onces ; 1 livre = 16 onces).\nPoids des visc√®res : poids des visc√®res, qui sont les organes entourant la cavit√© abdominale (en onces ; 1 livre = 16 onces).\nPoids de la coquille : poids de la coquille du crabe (en onces ; 1 livre = 16 onces).\nAge : √¢ge du crabe (en mois).\n\n\n\nConversion des variables √† l‚Äôorigine en pied en centim√®tre\n\ncrabe$longueur &lt;- crabe$longueur * 30.48\ncrabe$diametre &lt;- crabe$diametre * 30.48\ncrabe$hauteur &lt;- crabe$hauteur * 30.48"
  },
  {
    "objectID": "posts/post-with-code/biostatistiques/Final_projet.html#conversion-des-variables-√†-lorigine-en-onces-en-kilogramme",
    "href": "posts/post-with-code/biostatistiques/Final_projet.html#conversion-des-variables-√†-lorigine-en-onces-en-kilogramme",
    "title": "Biostatistiques",
    "section": "Conversion des variables √† l‚Äôorigine en onces en kilogramme",
    "text": "Conversion des variables √† l‚Äôorigine en onces en kilogramme\n\ncrabe$poids &lt;- crabe$poids * 0.0283495\ncrabe$poids.chair &lt;- crabe$poids.chair * 0.0283495\ncrabe$poids.visceres &lt;- crabe$poids.visceres * 0.0283495\ncrabe$poids.coquille &lt;- crabe$poids.coquille * 0.0283495\n\n\nstr(crabe)\n\n'data.frame':   3893 obs. of  9 variables:\n $ sexe          : chr  \"F\" \"M\" \"I\" \"F\" ...\n $ longueur      : num  43.8 27.1 31.6 35.8 27.1 ...\n $ diametre      : num  35.8 19.8 23.6 27.1 20.2 ...\n $ hauteur       : num  12.57 6.48 7.62 7.62 6.48 ...\n $ poids         : num  0.698 0.153 0.225 0.382 0.196 ...\n $ poids.chair   : num  0.3496 0.0651 0.0916 0.1346 0.0981 ...\n $ poids.visceres: num  0.1583 0.039 0.0454 0.0647 0.0422 ...\n $ poids.coquille: num  0.1913 0.0442 0.0784 0.1487 0.0482 ...\n $ age           : int  9 6 6 10 6 8 15 10 13 7 ...\n\n\nNos variables sont bien class√©es, nous n‚Äôavons pas √† les modifier.\n\nplot(crabe)\n\n\n\n\n\n\n\n\nApr√®s un aper√ßu rapide de nos donn√©es, nous pouvons observer que :\nLes graphiques ont diff√©rentes tendances et degr√©s de corr√©lation. Certains indiquent une corr√©lation positive marqu√©e, visible par les points qui forment une trajectoire nette ascendante de gauche √† droite.\nDes points paraissent s‚Äô√©carter de la tendance g√©n√©rale dans plusieurs scatter plots, sugg√©rant la pr√©sence de valeurs aberrantes.\nNotre jeu de donn√©es ne pr√©sente pas de valeurs manquantes. Cependant, en ce qui concerne la variable qualitative ‚Äúsexe‚Äù, nous observons une anomalie qui n√©cessite une analyse plus d√©taill√©e. En effet, nous recensons trois cat√©gories : M pour masculin, F pour f√©minin et I pour ind√©fini, ce qui pourrait indiquer une erreur.\nAfin de mieux comprendre nos donn√©es, nous allons r√©aliser une premi√®re analyse descriptive des variables qui pr√©sentent des valeurs atypiques."
  },
  {
    "objectID": "posts/post-with-code/biostatistiques/Final_projet.html#calcul-des-mesures-de-dispersion",
    "href": "posts/post-with-code/biostatistiques/Final_projet.html#calcul-des-mesures-de-dispersion",
    "title": "Biostatistiques",
    "section": "Calcul des mesures de dispersion",
    "text": "Calcul des mesures de dispersion\n\nsummary(crabe)\n\n     sexe              longueur         diametre         hauteur      \n Length:3893        Min.   : 5.715   Min.   : 4.191   Min.   : 0.000  \n Class :character   1st Qu.:34.290   1st Qu.:26.670   1st Qu.: 8.763  \n Mode  :character   Median :41.529   Median :32.385   Median :11.049  \n                    Mean   :39.969   Mean   :31.117   Mean   :10.649  \n                    3rd Qu.:46.863   3rd Qu.:36.576   3rd Qu.:12.573  \n                    Max.   :62.103   Max.   :49.530   Max.   :86.106  \n     poids           poids.chair        poids.visceres      poids.coquille    \n Min.   :0.001607   Min.   :0.0008037   Min.   :0.0004018   Min.   :0.001205  \n 1st Qu.:0.359251   1st Qu.:0.1514963   1st Qu.:0.0755473   1st Qu.:0.105284  \n Median :0.646170   Median :0.2704431   Median :0.1378335   Median :0.188868  \n Mean   :0.668121   Mean   :0.2893730   Mean   :0.1456185   Mean   :0.192659  \n 3rd Qu.:0.929472   3rd Qu.:0.4046600   3rd Qu.:0.2041383   3rd Qu.:0.265219  \n Max.   :2.270838   Max.   :1.1958969   Max.   :0.6108076   Max.   :0.807713  \n      age        \n Min.   : 1.000  \n 1st Qu.: 8.000  \n Median :10.000  \n Mean   : 9.955  \n 3rd Qu.:11.000  \n Max.   :29.000  \n\n\n\nLongueur : La longueur des crabes varie de 5.715 √† 62.103 avec une moyenne d‚Äôenviron 39.969. La m√©diane est de 41.529, ce qui sugg√®re une distribution l√©g√®rement asym√©trique vers les valeurs inf√©rieures puisque la moyenne est inf√©rieure √† la m√©diane. Les valeurs sont concentr√©es principalement entre 34.290 et 46.863, qui repr√©sentent les premiers et troisi√®me quartile, indiquant que 50 % des observations sont dans cette plage.\nDiam√®tre : le diam√®tre varie de 4.191 √† 49.530, avec une moyenne de 31.117. La m√©diane est de 32.385, sugg√©rant une distribution similaire √† celle de la longueur, avec une l√©g√®re asym√©trie. Le diam√®tre des crabes est g√©n√©ralement compris entre 26.670 et 36.576 (premier et troisi√®me quartiles).\nHauteur : la hauteur pr√©sente une gamme plus √©tendue allant de 0 √† 86.106, avec une moyenne de 10.649. La m√©diane de 11.049 est sup√©rieure √† la moyenne, ce qui pourrait indiquer une distribution asym√©trique avec une queue de distribution vers les valeurs inf√©rieures.\nPoids : le poids total des crabes est compris entre 0.001607 et 2.270838, avec une moyenne de 0.668121. La m√©diane est de 0.646170, indiquant une distribution des poids assez sym√©trique autour de la valeur centrale.\nPoids de chair : le poids de la chair varie de 0.0008037 √† 1.1958969, avec une moyenne de 0.2893730. La m√©diane, √† 0.2704431, est l√©g√®rement inf√©rieure √† la moyenne, sugg√©rant une distribution mod√©r√©ment asym√©trique.\nPoids des visc√®res : le poids des visc√®res varie de 0.0004018 √† 0.6108076, avec une moyenne de 0.1456185. La m√©diane est assez proche de la moyenne, ce qui indique une distribution assez √©quilibr√©e.\nPoids de la coquille : le poids de la coquille a une plage allant de 0.001205 √† 0.807713, avec une moyenne de 0.192659. La m√©diane est √©galement proche de la moyenne, ce qui sugg√®re une distribution r√©guli√®re.\nAge : l‚Äô√¢ge varie de 1 √† 29 mois, avec une moyenne proche de la m√©diane (9.955 contre 10), indiquant une distribution sym√©trique. La plupart des crabes ont entre 8 et 11 mois (premier et troisi√®me quartiles), ce qui montre que les √¢ges sont relativement concentr√©s."
  },
  {
    "objectID": "posts/post-with-code/biostatistiques/Final_projet.html#v√©rification-de-labsence-de-doublons",
    "href": "posts/post-with-code/biostatistiques/Final_projet.html#v√©rification-de-labsence-de-doublons",
    "title": "Biostatistiques",
    "section": "V√©rification de l‚Äôabsence de doublons",
    "text": "V√©rification de l‚Äôabsence de doublons\nNotre jeu de donn√©es est compos√© de 3 893 entr√©es. Nous allons v√©rifier s‚Äôil contient des doublons.\n\ncrabe |&gt;\n    distinct() |&gt;\n    nrow()\n\n[1] 3893\nAucune ligne n‚Äôest r√©p√©t√©e, nous pouvons donc conserver la totalit√© de nos donn√©es"
  },
  {
    "objectID": "posts/post-with-code/biostatistiques/Final_projet.html#diagramme-en-camembert",
    "href": "posts/post-with-code/biostatistiques/Final_projet.html#diagramme-en-camembert",
    "title": "Biostatistiques",
    "section": "Diagramme en camembert",
    "text": "Diagramme en camembert\nSexe\n\ncrabe |&gt;\n  count(sexe) |&gt;\n  mutate(pourcentage = n / sum(n) * 100) |&gt;\n  ggplot(aes(x = \"\", y = n, fill = sexe)) +\n  geom_bar(stat = \"identity\", width = 1) +\n  coord_polar(theta = \"y\") +\n  scale_fill_manual(values = vecteur_couleur) +\n  geom_text(aes(label = paste0(round(pourcentage, 1), \"%\")),\n         position = position_stack(vjust = 0.5),\n         color = \"white\") +  \n  labs(\n    title = \"Distribution des sexes dans le jeu de donn√©es \",\n    fill = \"Sexe\"\n  ) +\n  theme_void()  \n\n\n\n\n\n\n\n\nIl illustre la distribution des sexes dans notre jeu de donn√©es. Les m√¢les repr√©sentent la plus grande proportion avec 36,9 %, tandis que les femelles et les ind√©finis ont des proportions presque √©gales de 31,5 % et 31,7 % respectivement."
  },
  {
    "objectID": "posts/post-with-code/biostatistiques/Final_projet.html#repr√©sentation-des-valeurs-aberrantes-gr√¢ce-√†-des-boxplots",
    "href": "posts/post-with-code/biostatistiques/Final_projet.html#repr√©sentation-des-valeurs-aberrantes-gr√¢ce-√†-des-boxplots",
    "title": "Biostatistiques",
    "section": "Repr√©sentation des valeurs aberrantes gr√¢ce √† des boxplots",
    "text": "Repr√©sentation des valeurs aberrantes gr√¢ce √† des boxplots\n\ncrabe  |&gt;\n    pivot_longer(\n      cols = longueur:age,\n      names_to = \"mesure\",\n      values_to = \"valeur\"\n      ) |&gt;\n    ggplot() +\n    aes(y = valeur, x = sexe, color = sexe) +\n    geom_boxplot() +\n    geom_jitter(alpha = 0.3,  position = position_jitter(width = 0.2))  +\n    facet_wrap(~ mesure, scales = \"free_y\") +\n    scale_color_manual(values =vecteur_couleur)+\n    labs(title = \"Distribution des mesures par sexe\")+\n    theme_bw()\n\n\n\n\n\n\n\n\nNous pouvons donc observer la pr√©sence de valeurs aberrantes ou extr√™mes dans nos variables. Pour les identifier, nous avons utilis√© le test de Rosner.\n\nrosnerTest(crabe$longueur, k=10, alpha=0.05)\n\n\nResults of Outlier Test\n-------------------------\n\nTest Method:                     Rosner's Test for Outliers\n\nHypothesized Distribution:       Normal\n\nData:                            crabe$longueur\n\nSample Size:                     3893\n\nTest Statistics:                 R.1  = 3.740649\n                                 R.2  = 3.456138\n                                 R.3  = 3.294960\n                                 R.4  = 3.299993\n                                 R.5  = 3.263207\n                                 R.6  = 3.226213\n                                 R.7  = 3.230957\n                                 R.8  = 3.151732\n                                 R.9  = 3.114132\n                                 R.10 = 3.118429\n\nTest Statistic Parameter:        k = 10\n\nAlternative Hypothesis:          Up to 10 observations are not\n                                 from the same Distribution.\n\nType I Error:                    5%\n\nNumber of Outliers Detected:     0\n\n   i   Mean.i     SD.i  Value Obs.Num    R.i+1 lambda.i+1 Outlier\n1  0 39.96859 9.157125  5.715    1331 3.740649   4.357703   FALSE\n2  1 39.97739 9.141820  8.382     754 3.456138   4.357646   FALSE\n3  2 39.98551 9.128947  9.906    1178 3.294960   4.357588   FALSE\n4  3 39.99325 9.117367  9.906    3729 3.299993   4.357531   FALSE\n5  4 40.00098 9.105761 10.287    1901 3.263207   4.357474   FALSE\n6  5 40.00863 9.094449 10.668     308 3.226213   4.357416   FALSE\n7  6 40.01617 9.083430 10.668     956 3.230957   4.357359   FALSE\n8  7 40.02373 9.072385 11.430    1135 3.151732   4.357302   FALSE\n9  8 40.03109 9.061943 11.811     694 3.114132   4.357244   FALSE\n10 9 40.03835 9.051785 11.811    2766 3.118429   4.357187   FALSE\n\nrosnerTest(crabe$diametre, k=10, alpha=0.05)\n\n\nResults of Outlier Test\n-------------------------\n\nTest Method:                     Rosner's Test for Outliers\n\nHypothesized Distribution:       Normal\n\nData:                            crabe$diametre\n\nSample Size:                     3893\n\nTest Statistics:                 R.1  = 3.558731\n                                 R.2  = 3.211973\n                                 R.3  = 3.166162\n                                 R.4  = 3.120107\n                                 R.5  = 3.124422\n                                 R.6  = 3.078090\n                                 R.7  = 3.082245\n                                 R.8  = 3.086418\n                                 R.9  = 3.090607\n                                 R.10 = 3.043926\n\nTest Statistic Parameter:        k = 10\n\nAlternative Hypothesis:          Up to 10 observations are not\n                                 from the same Distribution.\n\nType I Error:                    5%\n\nNumber of Outliers Detected:     0\n\n   i   Mean.i     SD.i Value Obs.Num    R.i+1 lambda.i+1 Outlier\n1  0 31.11683 7.566132 4.191    1331 3.558731   4.357703   FALSE\n2  1 31.12375 7.554779 6.858     754 3.211973   4.357646   FALSE\n3  2 31.12998 7.545724 7.239    1178 3.166162   4.357588   FALSE\n4  3 31.13612 7.536961 7.620    1135 3.120107   4.357531   FALSE\n5  4 31.14217 7.528488 7.620    3729 3.124422   4.357474   FALSE\n6  5 31.14822 7.519995 8.001     308 3.078090   4.357416   FALSE\n7  6 31.15417 7.511789 8.001     956 3.082245   4.357359   FALSE\n8  7 31.16013 7.503564 8.001    2913 3.086418   4.357302   FALSE\n9  8 31.16609 7.495321 8.001    3634 3.090607   4.357244   FALSE\n10 9 31.17206 7.487061 8.382    1648 3.043926   4.357187   FALSE\n\nrosnerTest(crabe$hauteur, k=10, alpha=0.05)\n\n\nResults of Outlier Test\n-------------------------\n\nTest Method:                     Rosner's Test for Outliers\n\nHypothesized Distribution:       Normal\n\nData:                            crabe$hauteur\n\nSample Size:                     3893\n\nTest Statistics:                 R.1  = 23.582729\n                                 R.2  =  9.658305\n                                 R.3  =  3.628763\n                                 R.4  =  3.635390\n                                 R.5  =  3.380918\n                                 R.6  =  3.255592\n                                 R.7  =  3.260460\n                                 R.8  =  3.134283\n                                 R.9  =  3.007441\n                                 R.10 =  3.011338\n\nTest Statistic Parameter:        k = 10\n\nAlternative Hypothesis:          Up to 10 observations are not\n                                 from the same Distribution.\n\nType I Error:                    5%\n\nNumber of Outliers Detected:     2\n\n   i   Mean.i     SD.i  Value Obs.Num     R.i+1 lambda.i+1 Outlier\n1  0 10.64892 3.199676 86.106    2257 23.582729   4.357703    TRUE\n2  1 10.62953 2.962577 39.243     749  9.658305   4.357646    TRUE\n3  2 10.62217 2.927216  0.000     270  3.628763   4.357588   FALSE\n4  3 10.62490 2.922632  0.000    3868  3.635390   4.357531   FALSE\n5  4 10.62764 2.918035  0.762    1331  3.380918   4.357474   FALSE\n6  5 10.63017 2.914116  1.143    1124  3.255592   4.357416   FALSE\n7  6 10.63262 2.910514  1.143    3543  3.260460   4.357359   FALSE\n8  7 10.63506 2.906903  1.524     986  3.134283   4.357302   FALSE\n9  8 10.63740 2.903599  1.905     694  3.007441   4.357244   FALSE\n10 9 10.63965 2.900588  1.905    1135  3.011338   4.357187   FALSE\n\nrosnerTest(crabe$poids, k=10, alpha=0.05)\n\n\nResults of Outlier Test\n-------------------------\n\nTest Method:                     Rosner's Test for Outliers\n\nHypothesized Distribution:       Normal\n\nData:                            crabe$poids\n\nSample Size:                     3893\n\nTest Statistics:                 R.1  = 4.069788\n                                 R.2  = 3.984935\n                                 R.3  = 3.742623\n                                 R.4  = 3.540531\n                                 R.5  = 3.536432\n                                 R.6  = 3.538473\n                                 R.7  = 3.499292\n                                 R.8  = 3.483594\n                                 R.9  = 3.475026\n                                 R.10 = 3.473644\n\nTest Statistic Parameter:        k = 10\n\nAlternative Hypothesis:          Up to 10 observations are not\n                                 from the same Distribution.\n\nType I Error:                    5%\n\nNumber of Outliers Detected:     0\n\n   i    Mean.i      SD.i    Value Obs.Num    R.i+1 lambda.i+1 Outlier\n1  0 0.6681205 0.3938086 2.270838    2897 4.069788   4.357703   FALSE\n2  1 0.6677087 0.3930200 2.233868     773 3.984935   4.357646   FALSE\n3  2 0.6673062 0.3922674 2.135415    2572 3.742623   4.357588   FALSE\n4  3 0.6669288 0.3916107 2.053439     230 3.540531   4.357531   FALSE\n5  4 0.6665722 0.3910292 2.049420    2717 3.536432   4.357474   FALSE\n6  5 0.6662166 0.3904498 2.047813     539 3.538473   4.357416   FALSE\n7  6 0.6658611 0.3898704 2.030131     502 3.499292   4.357359   FALSE\n8  7 0.6655100 0.3893056 2.021693    1758 3.483594   4.357302   FALSE\n9  8 0.6651610 0.3887470 2.016067    1327 3.475026   4.357244   FALSE\n10 9 0.6648132 0.3881920 2.013254    3186 3.473644   4.357187   FALSE\n\nrosnerTest(crabe$poids.chair, k=10, alpha=0.05)\n\n\nResults of Outlier Test\n-------------------------\n\nTest Method:                     Rosner's Test for Outliers\n\nHypothesized Distribution:       Normal\n\nData:                            crabe$poids.chair\n\nSample Size:                     3893\n\nTest Statistics:                 R.1  = 5.095668\n                                 R.2  = 4.492498\n                                 R.3  = 4.493418\n                                 R.4  = 4.070734\n                                 R.5  = 4.045732\n                                 R.6  = 4.027361\n                                 R.7  = 4.001947\n                                 R.8  = 3.847766\n                                 R.9  = 3.846418\n                                 R.10 = 3.743692\n\nTest Statistic Parameter:        k = 10\n\nAlternative Hypothesis:          Up to 10 observations are not\n                                 from the same Distribution.\n\nType I Error:                    5%\n\nNumber of Outliers Detected:     3\n\n   i    Mean.i      SD.i     Value Obs.Num    R.i+1 lambda.i+1 Outlier\n1  0 0.2893730 0.1779009 1.1958969    2572 5.095668   4.357703    TRUE\n2  1 0.2891401 0.1773291 1.0857908    1950 4.492498   4.357646    TRUE\n3  2 0.2889354 0.1768912 1.0837816     773 4.493418   4.357588    TRUE\n4  3 0.2887310 0.1764541 1.0070288    2317 4.070734   4.357531   FALSE\n5  4 0.2885463 0.1761003 1.0010011    1294 4.045732   4.357474   FALSE\n6  5 0.2883631 0.1757518 0.9961789    3351 4.027361   4.357416   FALSE\n7  6 0.2881810 0.1754072 0.9901512    1327 4.001947   4.357359   FALSE\n8  7 0.2880004 0.1750678 0.9616201    3186 3.847766   4.357302   FALSE\n9  8 0.2878270 0.1747563 0.9600127     539 3.846418   4.357244   FALSE\n10 9 0.2876539 0.1744455 0.9407240     854 3.743692   4.357187   FALSE\n\nrosnerTest(crabe$poids.visceres, k=10, alpha=0.05)\n\n\nResults of Outlier Test\n-------------------------\n\nTest Method:                     Rosner's Test for Outliers\n\nHypothesized Distribution:       Normal\n\nData:                            crabe$poids.visceres\n\nSample Size:                     3893\n\nTest Statistics:                 R.1  = 5.286202\n                                 R.2  = 4.219961\n                                 R.3  = 3.757195\n                                 R.4  = 3.626516\n                                 R.5  = 3.628525\n                                 R.6  = 3.538250\n                                 R.7  = 3.415023\n                                 R.8  = 3.337302\n                                 R.9  = 3.342527\n                                 R.10 = 3.213223\n\nTest Statistic Parameter:        k = 10\n\nAlternative Hypothesis:          Up to 10 observations are not\n                                 from the same Distribution.\n\nType I Error:                    5%\n\nNumber of Outliers Detected:     1\n\n   i    Mean.i       SD.i     Value Obs.Num    R.i+1 lambda.i+1 Outlier\n1  0 0.1456185 0.08800062 0.6108076     773 5.286202   4.357703    TRUE\n2  1 0.1454990 0.08769532 0.5155698    1758 4.219961   4.357646   FALSE\n3  2 0.1454039 0.08750561 0.4741795     502 3.757195   4.357588   FALSE\n4  3 0.1453194 0.08735787 0.4621241    1205 3.626516   4.357531   FALSE\n5  4 0.1452379 0.08722122 0.4617223     539 3.628525   4.357474   FALSE\n6  5 0.1451565 0.08708457 0.4532835     692 3.538250   4.357416   FALSE\n7  6 0.1450772 0.08695537 0.4420318    1936 3.415023   4.357359   FALSE\n8  7 0.1450008 0.08683593 0.4347985    2317 3.337302   4.357302   FALSE\n9  8 0.1449262 0.08672250 0.4347985    2531 3.342527   4.357244   FALSE\n10 9 0.1448516 0.08660879 0.4231450    1828 3.213223   4.357187   FALSE\n\nrosnerTest(crabe$poids.coquille, k=10, alpha=0.05)\n\n\nResults of Outlier Test\n-------------------------\n\nTest Method:                     Rosner's Test for Outliers\n\nHypothesized Distribution:       Normal\n\nData:                            crabe$poids.coquille\n\nSample Size:                     3893\n\nTest Statistics:                 R.1  = 5.501712\n                                 R.2  = 4.744584\n                                 R.3  = 4.672147\n                                 R.4  = 4.685917\n                                 R.5  = 4.190527\n                                 R.6  = 4.072972\n                                 R.7  = 3.954369\n                                 R.8  = 3.816471\n                                 R.9  = 3.574841\n                                 R.10 = 3.573856\n\nTest Statistic Parameter:        k = 10\n\nAlternative Hypothesis:          Up to 10 observations are not\n                                 from the same Distribution.\n\nType I Error:                    5%\n\nNumber of Outliers Detected:     4\n\n   i    Mean.i      SD.i     Value Obs.Num    R.i+1 lambda.i+1 Outlier\n1  0 0.1926588 0.1117932 0.8077126    3296 5.501712   4.357703    TRUE\n2  1 0.1925008 0.1113718 0.7209137    2897 4.744584   4.357646    TRUE\n3  2 0.1923649 0.1110634 0.7112693    2726 4.672147   4.357588    TRUE\n4  3 0.1922316 0.1107655 0.7112693    3070 4.685917   4.357531    TRUE\n5  4 0.1920981 0.1104664 0.6550107     199 4.190527   4.357474   FALSE\n6  5 0.1919790 0.1102308 0.6409461    1486 4.072972   4.357416   FALSE\n7  6 0.1918635 0.1100094 0.6268814    1924 3.954369   4.357359   FALSE\n8  7 0.1917516 0.1098019 0.6108076    1826 3.816471   4.357302   FALSE\n9  8 0.1916437 0.1096100 0.5834820    1556 3.574841   4.357244   FALSE\n10 9 0.1915428 0.1094435 0.5826783    1847 3.573856   4.357187   FALSE\n\nrosnerTest(crabe$age, k=10, alpha=0.05)\n\n\nResults of Outlier Test\n-------------------------\n\nTest Method:                     Rosner's Test for Outliers\n\nHypothesized Distribution:       Normal\n\nData:                            crabe$age\n\nSample Size:                     3893\n\nTest Statistics:                 R.1  = 5.912886\n                                 R.2  = 5.316734\n                                 R.3  = 5.336843\n                                 R.4  = 5.043142\n                                 R.5  = 4.745335\n                                 R.6  = 4.443844\n                                 R.7  = 4.455752\n                                 R.8  = 4.150310\n                                 R.9  = 4.160079\n                                 R.10 = 4.169918\n\nTest Statistic Parameter:        k = 10\n\nAlternative Hypothesis:          Up to 10 observations are not\n                                 from the same Distribution.\n\nType I Error:                    5%\n\nNumber of Outliers Detected:     7\n\n   i   Mean.i     SD.i Value Obs.Num    R.i+1 lambda.i+1 Outlier\n1  0 9.954791 3.220967    29    1730 5.912886   4.357703    TRUE\n2  1 9.949897 3.206875    27    3070 5.316734   4.357646    TRUE\n3  2 9.945515 3.195613    27    3523 5.336843   4.357588    TRUE\n4  3 9.941131 3.184299    26      90 5.043142   4.357531    TRUE\n5  4 9.937002 3.174275    25    2424 4.745335   4.357474    TRUE\n6  5 9.933128 3.165474    24     374 4.443844   4.357416    TRUE\n7  6 9.929509 3.157827    24    3308 4.455752   4.357359    TRUE\n8  7 9.925888 3.150153    23     138 4.150310   4.357302   FALSE\n9  8 9.922523 3.143564    23     502 4.160079   4.357244   FALSE\n10 9 9.919156 3.136955    23    1215 4.169918   4.357187   FALSE\n\n\nNous utilisons le test de Rosner pour identifier les observations qui peuvent √™tre consid√©r√©es comme aberrantes ou extr√™mes, afin de les analyser en d√©tail.\n\nHauteur pour les observations num√©ros 2257 (86,106 cm) et 749 (39,24 cm)\nPoids de la chair pour les observations 2257 (1,19 kg), 1950 (1,08 kg) et 773 (1,08 kg)\nPoids des visc√®res pour l‚Äôobservation 773 (0,61 kg)\nPoids de la coquille pour les observations 3296 (0,8 kg), 2897 (0,72 kg), 2726 (0,71 kg) et 3070 (0,71 kg)\nAge pour les observations 1730 (29 mois), 3070 (27 mois), 3535 (27 mois), 90 (26 mois), 2424 (25 mois), 374 (24 mois) et 3308 (24 mois).\n\nLors de nos recherches, nous avons cherch√© √† comprendre la normalit√© de notre base de donn√©es.\nOn apprend ainsi que le crabe bleu √† une long√©vit√© d‚Äôenviron 3 ans donc nous d√©cidons de conserver les valeurs extr√™mes de la variable √¢ge. Concernant les variables poids de la chair, poids des visc√®res et poids de la coquille, nous d√©cidons √©galement de les garder.\nPour la suite, nous allons donc traiter les deux valeurs de la variable ‚Äúhauteur‚Äù.\nObservation n¬∞2257\n\ncrabe[2257,]\n\n     sexe longueur diametre hauteur     poids poids.chair poids.visceres\n2257    F   34.671   27.051  86.106 0.4773943   0.2668265     0.09322852\n     poids.coquille age\n2257      0.1072932   8\n\nresultat &lt;- crabe %&gt;%\n  filter(sexe == \"F\", age == 8) %&gt;%\n  summarise(mean_hauteur = mean(hauteur))\nprint(resultat)\n\n  mean_hauteur\n1     11.39628\n\n\nNous constatons que la moyenne des hauteurs pour les crabes √¢g√©s de 8 mois et de sexe f√©minin est de 11,39. Nous pouvons donc supposer que notre valeur de 86,106 est une valeur aberrante, probablement due √† une erreur de saisie de virgule, que nous pouvons corriger.\n\ncrabe[2257,\"hauteur\"]&lt;-8.6106"
  },
  {
    "objectID": "posts/post-with-code/biostatistiques/Final_projet.html#visualisation-des-valeurs-manquantes",
    "href": "posts/post-with-code/biostatistiques/Final_projet.html#visualisation-des-valeurs-manquantes",
    "title": "Biostatistiques",
    "section": "Visualisation des valeurs manquantes",
    "text": "Visualisation des valeurs manquantes\n\ngg_miss_upset(crabe)\n\n`geom_line()`: Each group consists of only one observation.\n‚Ñπ Do you need to adjust the group aesthetic?\n\n\n\n\n\nDescription de la figure.\n\n\n\n\nLe graphique ci-dessus, illustre la r√©partition des valeurs manquantes (N/A) que nous avons g√©n√©r√©es et ins√©r√©es de mani√®re al√©atoire dans les colonnes s√©lectionn√©es de notre jeu de donn√©es. Au total, 50 valeurs manquantes ont √©t√© introduites : 19 dans la colonne du poids, 16 dans celle du diam√®tre et 15 dans celle de l‚Äô√¢ge.\nAfin de mieux comprendre la distribution des colonnes o√π nous avons ins√©r√© des valeurs manquantes, et pour d√©terminer les m√©thodes de remplacement les plus adapt√©es, nous proc√©dons √† l‚Äôexamen de la normalit√© et √† l‚Äôanalyse de la corr√©lation entre nos variables."
  },
  {
    "objectID": "posts/post-with-code/biostatistiques/Final_projet.html#test-de-normalit√©",
    "href": "posts/post-with-code/biostatistiques/Final_projet.html#test-de-normalit√©",
    "title": "Biostatistiques",
    "section": "Test de normalit√©",
    "text": "Test de normalit√©\nQQ plot Age\n\nqqnorm(crabe$age, main = \"Q-Q plot - Age\")\nqqline(crabe$age, col = 2)\n\n\n\n\n\n\n\n\nQQ plot Poids\n\nqqnorm(crabe$poids, main = \"Q-Q Plot - Poids\")\n\nqqline(crabe$poids, col = 2)\n\n\n\n\n\n\n\n\nQQ plot Diametre\n\nqqnorm(crabe$diametre, main = \"Q-Q Plot - Diam√®tre\")\n\nqqline(crabe$diametre, col = 2)\n\n\n\n\n\n\n\n\nUn graphique Q-Q (quantile-quantile) est un outil visuel utilis√© en statistique pour comparer deux distributions de probabilit√© en tra√ßant leurs quantiles l‚Äôun contre l‚Äôautre. Il est souvent utilis√© pour v√©rifier si deux ensembles de donn√©es suivent une m√™me distribution. Si les points s‚Äôalignent approximativement sur une ligne droite, cela sugg√®re que les deux distributions sont similaires.\nDans notre cas, les Q-Q plots ne suivent pas la droite de la loi normale, nous pouvons donc supposer qu‚Äôils ne suivent pas une distribution normale.\nCalculer la moyenne et l‚Äô√©cart-type de nos donn√©es\n\nmoyenne_age &lt;- mean(crabe$age, na.rm = TRUE)\necart_type_age &lt;- sd(crabe$age, na.rm = TRUE)\n\nmoyenne_poids &lt;- mean(crabe$poids, na.rm = TRUE)\necart_type_poids &lt;- sd(crabe$poids, na.rm = TRUE)\n\nmoyenne_diametre &lt;- mean(crabe$diametre, na.rm = TRUE)\necart_type_diametre &lt;- sd(crabe$diametre, na.rm = TRUE)\n\nTest KS pour comparer nos donn√©es √† une distribution normale\n\nage.ks&lt;-ks.test(crabe$age, \"pnorm\", mean = moyenne_age, sd = ecart_type_age)\n\nWarning in ks.test.default(crabe$age, \"pnorm\", mean = moyenne_age, sd =\necart_type_age): ties should not be present for the Kolmogorov-Smirnov test\n\nage.ks\n\n\n    Asymptotic one-sample Kolmogorov-Smirnov test\n\ndata:  crabe$age\nD = 0.14369, p-value &lt; 2.2e-16\nalternative hypothesis: two-sided\n\npoids.ks&lt;-ks.test(crabe$poids, \"pnorm\", mean = moyenne_poids, sd = ecart_type_poids)\n\nWarning in ks.test.default(crabe$poids, \"pnorm\", mean = moyenne_poids, sd =\necart_type_poids): ties should not be present for the Kolmogorov-Smirnov test\n\npoids.ks\n\n\n    Asymptotic one-sample Kolmogorov-Smirnov test\n\ndata:  crabe$poids\nD = 0.046722, p-value = 9.026e-08\nalternative hypothesis: two-sided\n\ndiametre.ks&lt;-ks.test(crabe$diametre, \"pnorm\", mean = moyenne_diametre, sd = ecart_type_diametre)\n\nWarning in ks.test.default(crabe$diametre, \"pnorm\", mean = moyenne_diametre, :\nties should not be present for the Kolmogorov-Smirnov test\n\ndiametre.ks\n\n\n    Asymptotic one-sample Kolmogorov-Smirnov test\n\ndata:  crabe$diametre\nD = 0.080708, p-value &lt; 2.2e-16\nalternative hypothesis: two-sided\n\n\nNous avons par la suite effectu√© les tests de Kolmogorov-Smirnov, notre √©chantillon √©tant compos√© de plus de 50 observations. Ces tests confirment ce qu‚Äôon a constat√© avec les Q-Q plots, nos variables ne pr√©sentent pas une distribution normale. De ce fait, nous excluons l‚Äôoption de remplacement par la moyenne."
  },
  {
    "objectID": "posts/post-with-code/biostatistiques/Final_projet.html#matrice-de-corr√©lation",
    "href": "posts/post-with-code/biostatistiques/Final_projet.html#matrice-de-corr√©lation",
    "title": "Biostatistiques",
    "section": "Matrice de corr√©lation",
    "text": "Matrice de corr√©lation\n\ncrabe |&gt;\n  select(longueur:age) |&gt;\n  drop_na() |&gt;\n  cor() |&gt;\n  corrplot::corrplot.mixed()\n\n\n\n\n\n\n\n\nNous observons une corr√©lation existante entre les variables √¢ge, diam√®tre et poids.\n\n\n\n\n\n\nRisque de multicolinarit√©\n\n\n\nLes variables longueur, diam√®tre, hauteur, poids, poids.chair, poids.visceres, et poids.coquille ont des coefficients sup√©rieurs √† 0.9. Dans le cadre de notre projet, l‚Äôobjectif est d‚Äôutiliser la r√©gression pour pr√©dire et imputer des valeurs manquantes plut√¥t que pour l‚Äôinf√©rence statistique, la multicolin√©arit√© est un peu moins probl√©matique. Cependant, elle peut affecter la stabilit√© des coefficients de r√©gression utilis√©s dans l‚Äôimputation.\n\n\nAinsi, pour la suite, nous opterons pour des m√©thodes d‚Äôimputation plus robustes telles que l‚Äôimputation MICE (Multiple Imputation by Chained Equations) et la m√©thode bas√©e sur l‚ÄôAnalyse en Composantes Principales (ACP), ainsi qu‚Äôun remplacement global des valeurs manquantes."
  },
  {
    "objectID": "posts/post-with-code/biostatistiques/Final_projet.html#al√©atoire",
    "href": "posts/post-with-code/biostatistiques/Final_projet.html#al√©atoire",
    "title": "Biostatistiques",
    "section": "Al√©atoire",
    "text": "Al√©atoire\n\ncrabe_mice_aleatoire &lt;- mice(crabe_mice, m = 5)\n\n\n iter imp variable\n  1   1  diametre  poids  age\n  1   2  diametre  poids  age\n  1   3  diametre  poids  age\n  1   4  diametre  poids  age\n  1   5  diametre  poids  age\n  2   1  diametre  poids  age\n  2   2  diametre  poids  age\n  2   3  diametre  poids  age\n  2   4  diametre  poids  age\n  2   5  diametre  poids  age\n  3   1  diametre  poids  age\n  3   2  diametre  poids  age\n  3   3  diametre  poids  age\n  3   4  diametre  poids  age\n  3   5  diametre  poids  age\n  4   1  diametre  poids  age\n  4   2  diametre  poids  age\n  4   3  diametre  poids  age\n  4   4  diametre  poids  age\n  4   5  diametre  poids  age\n  5   1  diametre  poids  age\n  5   2  diametre  poids  age\n  5   3  diametre  poids  age\n  5   4  diametre  poids  age\n  5   5  diametre  poids  age\n\n\nWarning: Number of logged events: 1\n\ncrabe_mice_aleatoire$imp\n\n$sexe\n[1] 1 2 3 4 5\n&lt;0 rows&gt; (or 0-length row.names)\n\n$longueur\n[1] 1 2 3 4 5\n&lt;0 rows&gt; (or 0-length row.names)\n\n$diametre\n          1      2      3      4      5\n195  39.624 41.148 39.624 38.862 38.481\n211  34.290 33.147 33.909 33.528 32.385\n348  34.671 36.195 34.671 36.195 36.576\n1038 39.624 39.624 39.624 38.862 39.243\n1614 14.478 14.097 14.097 14.097 14.097\n1790 21.717 22.479 20.955 20.955 22.860\n1842 39.624 41.148 41.529 40.005 39.243\n1866 39.624 38.100 37.338 39.243 36.957\n1895 30.480 29.337 30.480 30.099 30.480\n2013 33.909 31.623 34.290 33.147 33.909\n2074 27.051 27.051 27.432 26.670 26.670\n2592 34.671 35.433 34.290 33.147 34.290\n2888 20.574 21.717 23.622 24.003 20.574\n3693 32.385 32.766 31.623 34.290 33.528\n3721 29.718 29.337 29.337 31.242 28.575\n3840 19.050 19.812 19.050 20.193 19.812\n\n$hauteur\n[1] 1 2 3 4 5\n&lt;0 rows&gt; (or 0-length row.names)\n\n$poids\n             1         2         3         4         5\n555  0.3725122 0.3596531 0.3307201 0.3596531 0.3913991\n665  1.0315414 1.0335507 0.9993937 1.0214953 0.9993937\n1115 0.8511121 0.8708026 0.9226409 0.9226409 0.9178187\n1142 0.3785399 0.3873806 0.3938101 0.3913991 0.4191265\n1167 0.7410060 0.6984102 0.6984102 0.7128767 0.7494448\n1268 0.5236067 0.5300363 0.5191864 0.4753851 0.5280271\n1627 0.3262998 0.3443829 0.3359442 0.3415700 0.3142444\n1673 0.5171772 0.5027107 0.5171772 0.4826183 0.5091402\n1799 1.7637068 1.7464274 1.7464274 1.7464274 1.7464274\n2227 0.9138002 0.8824562 0.9431351 0.9700588 0.9700588\n2463 1.4824139 1.4824139 1.4599104 1.5864923 1.4599104\n2538 1.0652966 1.1062850 1.1175367 1.0773520 1.0869963\n2641 0.3528217 0.3496070 0.3443829 0.3283091 0.3403645\n2757 0.4673481 0.4737777 0.4902534 0.4633297 0.4673481\n2971 0.8503084 0.8760266 0.8667841 0.8511121 0.8358419\n2980 0.3958194 0.3873806 0.3938101 0.3913991 0.3966231\n2986 0.4323875 0.4356022 0.4147062 0.4323875 0.4356022\n3371 0.3186647 0.3041982 0.3106278 0.3041982 0.3262998\n3446 0.4609186 0.4962811 0.4906553 0.4773943 0.4609186\n\n$poids.chair\n[1] 1 2 3 4 5\n&lt;0 rows&gt; (or 0-length row.names)\n\n$poids.visceres\n[1] 1 2 3 4 5\n&lt;0 rows&gt; (or 0-length row.names)\n\n$poids.coquille\n[1] 1 2 3 4 5\n&lt;0 rows&gt; (or 0-length row.names)\n\n$age\n      1  2  3  4  5\n373   6  6  5  5  6\n526  11 13 10 13  9\n905   9 11 14  9  9\n953  14  9 12 10  9\n1011  8 11  9  8  8\n1017  9  9  9 10  9\n1047  7  8  8 10  6\n1253 17 10  9 14  9\n1379 10  9  9  7 10\n1450  8 11  5  8  9\n2511 10 11 13  7 11\n2567 12  9 10  9  9\n2650 12 10 11 11 19\n2892  8  8 10 11  9\n2985 10  8 11 15 12\n\ncrabe_mice_aleatoire$method\n\n          sexe       longueur       diametre        hauteur          poids \n            \"\"             \"\"          \"pmm\"             \"\"          \"pmm\" \n   poids.chair poids.visceres poids.coquille            age \n            \"\"             \"\"             \"\"          \"pmm\" \n\nplot(crabe_mice_aleatoire)\n\n\n\n\n\n\n\n\nLorsque nous effectuons la m√©thode de mani√®re al√©atoire, le logiciel propose d‚Äôeffectuer l‚Äôimputation avec la m√©thode PMM."
  },
  {
    "objectID": "posts/post-with-code/biostatistiques/Final_projet.html#imputation-par-la-pmm",
    "href": "posts/post-with-code/biostatistiques/Final_projet.html#imputation-par-la-pmm",
    "title": "Biostatistiques",
    "section": "Imputation par la PMM",
    "text": "Imputation par la PMM\n\nmeth_pmm &lt;- c(\"\", \"\", \"pmm\", \"\", \"pmm\", \"\", \"\", \"\", \"pmm\")\nset.seed(123)\ncrabe_pmm &lt;- mice(crabe_mice, method = meth_pmm, m = 6, maxit = 6)\n\n\n iter imp variable\n  1   1  diametre  poids  age\n  1   2  diametre  poids  age\n  1   3  diametre  poids  age\n  1   4  diametre  poids  age\n  1   5  diametre  poids  age\n  1   6  diametre  poids  age\n  2   1  diametre  poids  age\n  2   2  diametre  poids  age\n  2   3  diametre  poids  age\n  2   4  diametre  poids  age\n  2   5  diametre  poids  age\n  2   6  diametre  poids  age\n  3   1  diametre  poids  age\n  3   2  diametre  poids  age\n  3   3  diametre  poids  age\n  3   4  diametre  poids  age\n  3   5  diametre  poids  age\n  3   6  diametre  poids  age\n  4   1  diametre  poids  age\n  4   2  diametre  poids  age\n  4   3  diametre  poids  age\n  4   4  diametre  poids  age\n  4   5  diametre  poids  age\n  4   6  diametre  poids  age\n  5   1  diametre  poids  age\n  5   2  diametre  poids  age\n  5   3  diametre  poids  age\n  5   4  diametre  poids  age\n  5   5  diametre  poids  age\n  5   6  diametre  poids  age\n  6   1  diametre  poids  age\n  6   2  diametre  poids  age\n  6   3  diametre  poids  age\n  6   4  diametre  poids  age\n  6   5  diametre  poids  age\n  6   6  diametre  poids  age\n\n\nWarning: Number of logged events: 1\n\ncrabe_pmm$imp\n\n$sexe\n[1] 1 2 3 4 5 6\n&lt;0 rows&gt; (or 0-length row.names)\n\n$longueur\n[1] 1 2 3 4 5 6\n&lt;0 rows&gt; (or 0-length row.names)\n\n$diametre\n          1      2      3      4      5      6\n195  38.862 38.862 39.243 38.481 39.243 38.481\n211  33.528 34.290 32.004 33.528 33.528 32.766\n348  35.433 35.814 34.671 36.576 36.195 35.433\n1038 39.243 38.481 39.624 39.624 39.624 41.910\n1614 13.716 14.097 13.716 14.097 14.478 13.716\n1790 20.955 21.717 21.717 23.622 22.479 21.717\n1842 41.529 40.005 41.148 41.529 40.005 39.243\n1866 38.100 36.957 38.100 37.338 38.862 38.481\n1895 30.861 30.480 29.718 30.099 30.480 30.099\n2013 34.671 31.242 33.528 33.909 33.909 33.528\n2074 26.670 27.432 27.432 26.670 25.146 26.670\n2592 33.909 34.290 35.814 34.290 33.147 32.766\n2888 21.717 22.860 23.241 22.860 22.479 21.336\n3693 33.528 33.909 35.052 33.528 32.004 35.052\n3721 28.575 28.956 29.337 31.242 30.480 30.480\n3840 19.431 19.431 19.812 19.050 18.669 19.812\n\n$hauteur\n[1] 1 2 3 4 5 6\n&lt;0 rows&gt; (or 0-length row.names)\n\n$poids\n             1         2         3         4         5         6\n555  0.3592513 0.3913991 0.3913991 0.3556347 0.3913991 0.3576439\n665  0.9993937 1.0476153 1.0162713 0.9993937 1.0022066 1.0162713\n1115 0.8511121 0.8708026 0.8908950 0.8217773 0.8812506 0.8908950\n1142 0.4114914 0.3978286 0.3785399 0.4010434 0.3913991 0.3966231\n1167 0.7385949 0.7518559 0.7229229 0.7213155 0.7385949 0.7518559\n1268 0.5236067 0.5280271 0.5288308 0.5043181 0.5288308 0.5441009\n1627 0.3142444 0.3415700 0.3781381 0.3142444 0.3359442 0.3415700\n1673 0.4826183 0.4998978 0.4978885 0.5087384 0.5023088 0.5111495\n1799 1.7464274 1.7637068 1.7464274 1.7689308 1.7761641 1.7689308\n2227 0.9109873 0.9495646 0.9431351 1.0315414 1.0315414 0.9085762\n2463 1.5109450 1.4920582 1.5213930 1.5141598 1.5213930 1.4920582\n2538 1.0869963 1.0869963 1.0652966 1.0580633 1.0745391 1.0701188\n2641 0.3275054 0.3283091 0.3387571 0.3283091 0.3283091 0.3351405\n2757 0.4625260 0.4790017 0.4665445 0.4790017 0.4918608 0.4790017\n2971 0.8531213 0.8531213 0.8531213 0.8358419 0.8358419 0.8032923\n2980 0.4046600 0.4046600 0.3938101 0.3913991 0.4010434 0.3841658\n2986 0.4022489 0.4243505 0.3946138 0.4243505 0.4159117 0.4022489\n3371 0.3190666 0.3190666 0.3262998 0.3146463 0.3262998 0.3226832\n3446 0.4713666 0.5019070 0.4922627 0.4794036 0.4922627 0.4524798\n\n$poids.chair\n[1] 1 2 3 4 5 6\n&lt;0 rows&gt; (or 0-length row.names)\n\n$poids.visceres\n[1] 1 2 3 4 5 6\n&lt;0 rows&gt; (or 0-length row.names)\n\n$poids.coquille\n[1] 1 2 3 4 5 6\n&lt;0 rows&gt; (or 0-length row.names)\n\n$age\n      1  2  3  4  5  6\n373   6  6  7  7  6 13\n526  10 11 11 15  9 11\n905  11  9 10 13 11 10\n953  10 10  9 11  9  9\n1011  9 10  8 13  9 10\n1017 10 10 12  8 11 12\n1047  9  9 11  9  8  9\n1253  9  9 12  9 13  9\n1379  8  8 13 10  9  9\n1450  5  6  9  6  7 10\n2511  9 10  8  8 10 11\n2567 10 10  9 11  7 10\n2650 13  9 23  8  9 10\n2892  8 12  9 12 11  7\n2985  9 10 11 11 10 15\n\nplot(crabe_pmm, main=\"Plot selon la m√©thode pmm\")"
  },
  {
    "objectID": "posts/post-with-code/biostatistiques/Final_projet.html#imputation-par-la-rf",
    "href": "posts/post-with-code/biostatistiques/Final_projet.html#imputation-par-la-rf",
    "title": "Biostatistiques",
    "section": "Imputation par la RF",
    "text": "Imputation par la RF\n\nset.seed(123)\nmeth_rf &lt;- c(\"\", \"\", \"rf\", \"\", \"rf\", \"\", \"\", \"\", \"rf\")\ncrabe_rf &lt;- mice(crabe_mice, method = meth_rf, m = 6, maxit = 6, )\n\n\n iter imp variable\n  1   1  diametre  poids  age\n  1   2  diametre  poids  age\n  1   3  diametre  poids  age\n  1   4  diametre  poids  age\n  1   5  diametre  poids  age\n  1   6  diametre  poids  age\n  2   1  diametre  poids  age\n  2   2  diametre  poids  age\n  2   3  diametre  poids  age\n  2   4  diametre  poids  age\n  2   5  diametre  poids  age\n  2   6  diametre  poids  age\n  3   1  diametre  poids  age\n  3   2  diametre  poids  age\n  3   3  diametre  poids  age\n  3   4  diametre  poids  age\n  3   5  diametre  poids  age\n  3   6  diametre  poids  age\n  4   1  diametre  poids  age\n  4   2  diametre  poids  age\n  4   3  diametre  poids  age\n  4   4  diametre  poids  age\n  4   5  diametre  poids  age\n  4   6  diametre  poids  age\n  5   1  diametre  poids  age\n  5   2  diametre  poids  age\n  5   3  diametre  poids  age\n  5   4  diametre  poids  age\n  5   5  diametre  poids  age\n  5   6  diametre  poids  age\n  6   1  diametre  poids  age\n  6   2  diametre  poids  age\n  6   3  diametre  poids  age\n  6   4  diametre  poids  age\n  6   5  diametre  poids  age\n  6   6  diametre  poids  age\n\n\nWarning: Number of logged events: 1\n\ncrabe_rf$imp\n\n$sexe\n[1] 1 2 3 4 5 6\n&lt;0 rows&gt; (or 0-length row.names)\n\n$longueur\n[1] 1 2 3 4 5 6\n&lt;0 rows&gt; (or 0-length row.names)\n\n$diametre\n          1      2      3      4      5      6\n195  40.767 40.005 43.053 44.196 41.148 40.767\n211  33.528 33.909 34.290 32.766 31.242 31.623\n348  33.909 35.814 35.433 34.671 35.814 34.290\n1038 40.005 39.243 40.005 38.481 41.148 38.100\n1614 14.859 13.716 13.716 14.478 14.097 13.335\n1790 23.622 22.098 22.860 22.479 22.479 22.860\n1842 40.767 38.862 40.005 41.148 40.386 40.005\n1866 36.576 38.100 35.433 39.243 38.862 38.481\n1895 29.337 29.718 29.718 30.861 33.147 30.099\n2013 32.766 34.290 33.528 32.766 34.290 34.290\n2074 27.051 26.670 28.194 27.051 27.813 28.575\n2592 34.671 34.671 35.433 34.290 34.671 33.528\n2888 28.194 26.289 27.813 27.813 20.574 28.956\n3693 33.147 32.385 33.147 35.433 32.004 33.528\n3721 28.194 31.242 29.718 30.861 29.718 30.099\n3840 19.050 19.812 19.812 20.193 15.621 19.431\n\n$hauteur\n[1] 1 2 3 4 5 6\n&lt;0 rows&gt; (or 0-length row.names)\n\n$poids\n             1         2         3         4         5         6\n555  0.3520180 0.3158518 0.3837640 0.3664845 0.3644753 0.3837640\n665  1.0918185 1.0255137 0.9853290 0.9198280 1.0701188 0.9853290\n1115 0.8495047 0.8495047 0.7803870 0.7988720 0.8282068 0.8008812\n1142 0.4167154 0.4263597 0.3753252 0.5119532 0.4130988 0.4287708\n1167 0.7430152 0.6546089 0.6449646 0.7036342 0.7076527 0.7277451\n1268 0.4769925 0.4633297 0.5617822 0.5091402 0.5549508 0.4633297\n1627 0.3013853 0.3106278 0.3230850 0.3013853 0.2684338 0.3371497\n1673 0.5123550 0.5123550 0.5224012 0.5436991 0.5726321 0.5075329\n1799 1.7464274 1.5306355 1.7761641 2.1354154 1.6110049 1.7966583\n2227 0.7920406 0.8764285 0.7393986 0.7715464 0.9644330 1.0435969\n2463 1.1561140 1.4120906 1.4599104 1.5519334 1.7464274 1.5326447\n2538 1.0906130 1.0669040 1.0504283 1.0427932 0.9487609 1.1870563\n2641 0.3226832 0.2985724 0.1056858 0.3271035 0.3391589 0.3226832\n2757 0.4970848 0.4649371 0.4544890 0.4621241 0.4540872 0.4247524\n2971 0.8844654 0.9278649 0.8559343 0.8491029 0.8852691 0.8683915\n2980 0.4159117 0.3733159 0.3701012 0.3950157 0.3845677 0.3789418\n2986 0.3475977 0.3596531 0.3479996 0.4396207 0.4472558 0.4392189\n3371 0.3182629 0.3488033 0.3158518 0.3037964 0.3415700 0.3210758\n3446 0.5441009 0.5091402 0.4998978 0.4942719 0.5111495 0.4544890\n\n$poids.chair\n[1] 1 2 3 4 5 6\n&lt;0 rows&gt; (or 0-length row.names)\n\n$poids.visceres\n[1] 1 2 3 4 5 6\n&lt;0 rows&gt; (or 0-length row.names)\n\n$poids.coquille\n[1] 1 2 3 4 5 6\n&lt;0 rows&gt; (or 0-length row.names)\n\n$age\n      1  2  3  4  5  6\n373   6  8  6  5  6  6\n526  11 12 13  8 10  9\n905  10  9 13  9 19 10\n953   9 19  9 12  9  8\n1011  8  8  9  8  9  8\n1017  9  8 10 10  8 10\n1047  7 13 10 10  8 16\n1253 11 10  7 10  9 17\n1379  9 11 11 12  9 10\n1450  9  9  9  8  9  8\n2511  8  9  9  9 11  8\n2567  9  8 11  9  9  9\n2650  9  9 10 12  8 11\n2892 11 10 10 15 10  8\n2985 19 12 10 15 11 10\n\nplot(crabe_rf, main=\"Plot selon la m√©thode rf\")"
  },
  {
    "objectID": "posts/post-with-code/biostatistiques/Final_projet.html#imputation-mix-entre-pmm-et-rf",
    "href": "posts/post-with-code/biostatistiques/Final_projet.html#imputation-mix-entre-pmm-et-rf",
    "title": "Biostatistiques",
    "section": "Imputation mix entre PMM et RF",
    "text": "Imputation mix entre PMM et RF\n\nmeth_mix &lt;- c(\"\", \"\", \"pmm\", \"\", \"pmm\", \"\", \"\", \"\", \"rf\")\nset.seed(123)\ncrabe_mix &lt;- mice(crabe_mice, method = meth_mix,m = 6, maxit = 6)\n\n\n iter imp variable\n  1   1  diametre  poids  age\n  1   2  diametre  poids  age\n  1   3  diametre  poids  age\n  1   4  diametre  poids  age\n  1   5  diametre  poids  age\n  1   6  diametre  poids  age\n  2   1  diametre  poids  age\n  2   2  diametre  poids  age\n  2   3  diametre  poids  age\n  2   4  diametre  poids  age\n  2   5  diametre  poids  age\n  2   6  diametre  poids  age\n  3   1  diametre  poids  age\n  3   2  diametre  poids  age\n  3   3  diametre  poids  age\n  3   4  diametre  poids  age\n  3   5  diametre  poids  age\n  3   6  diametre  poids  age\n  4   1  diametre  poids  age\n  4   2  diametre  poids  age\n  4   3  diametre  poids  age\n  4   4  diametre  poids  age\n  4   5  diametre  poids  age\n  4   6  diametre  poids  age\n  5   1  diametre  poids  age\n  5   2  diametre  poids  age\n  5   3  diametre  poids  age\n  5   4  diametre  poids  age\n  5   5  diametre  poids  age\n  5   6  diametre  poids  age\n  6   1  diametre  poids  age\n  6   2  diametre  poids  age\n  6   3  diametre  poids  age\n  6   4  diametre  poids  age\n  6   5  diametre  poids  age\n  6   6  diametre  poids  age\n\n\nWarning: Number of logged events: 1\n\ncrabe_mix$imp\n\n$sexe\n[1] 1 2 3 4 5 6\n&lt;0 rows&gt; (or 0-length row.names)\n\n$longueur\n[1] 1 2 3 4 5 6\n&lt;0 rows&gt; (or 0-length row.names)\n\n$diametre\n          1      2      3      4      5      6\n195  38.862 37.719 39.243 38.481 38.862 38.862\n211  30.480 29.718 32.385 34.290 32.004 33.909\n348  35.433 35.814 36.576 35.814 36.195 36.195\n1038 39.624 38.481 39.243 38.481 39.624 39.624\n1614 14.859 14.097 14.859 14.478 14.478 14.478\n1790 20.574 20.574 21.717 20.955 21.336 23.622\n1842 39.243 41.148 40.005 40.767 38.481 39.243\n1866 38.100 38.100 39.624 38.481 37.719 38.481\n1895 30.099 30.099 29.337 29.337 30.480 30.099\n2013 32.385 33.528 32.766 33.528 33.528 32.385\n2074 27.432 27.051 26.289 27.432 26.289 26.670\n2592 33.909 34.290 36.195 34.290 34.290 33.909\n2888 21.336 20.574 22.860 22.860 22.860 23.622\n3693 34.290 33.147 35.052 33.528 33.909 35.052\n3721 31.242 30.480 30.099 28.575 30.480 28.575\n3840 19.431 19.431 20.193 19.431 19.050 19.812\n\n$hauteur\n[1] 1 2 3 4 5 6\n&lt;0 rows&gt; (or 0-length row.names)\n\n$poids\n             1         2         3         4         5         6\n555  0.3753252 0.3604568 0.3905954 0.3644753 0.3692975 0.3592513\n665  1.0222990 1.0158694 0.9977863 0.9977863 1.0142620 0.9977863\n1115 1.0407839 0.8732137 0.9178187 0.8752229 0.8217773 0.9226409\n1142 0.3873806 0.3978286 0.4130988 0.4191265 0.3785399 0.3978286\n1167 0.7128767 0.7044379 0.8044978 0.7518559 0.7329691 0.7385949\n1268 0.5441009 0.5280271 0.5215975 0.5441009 0.5304381 0.5441009\n1627 0.3262998 0.3311220 0.3781381 0.3387571 0.3142444 0.3142444\n1673 0.5027107 0.4826183 0.5171772 0.5091402 0.4978885 0.5027107\n1799 1.7464274 1.7637068 1.9135958 1.9135958 1.7689308 1.7464274\n2227 0.8776340 0.9652367 0.9495646 0.8824562 0.9226409 0.9495646\n2463 1.5109450 1.5897070 1.5864923 1.5141598 1.4824139 1.5141598\n2538 1.0745391 1.0652966 1.0994536 1.0693151 1.0532412 1.0604744\n2641 0.3391589 0.3347386 0.3283091 0.3528217 0.3387571 0.3283091\n2757 0.4625260 0.4625260 0.4665445 0.4673481 0.4665445 0.4681518\n2971 0.8772322 0.8667841 0.8503084 0.9065670 0.8478973 0.8603546\n2980 0.3479996 0.3990341 0.3958194 0.3958194 0.3938101 0.4046600\n2986 0.4468539 0.4231450 0.4356022 0.4319856 0.4243505 0.4468539\n3371 0.3371497 0.3319257 0.3262998 0.3070112 0.3041982 0.3166555\n3446 0.4886460 0.4609186 0.4962811 0.4725722 0.4886460 0.4886460\n\n$poids.chair\n[1] 1 2 3 4 5 6\n&lt;0 rows&gt; (or 0-length row.names)\n\n$poids.visceres\n[1] 1 2 3 4 5 6\n&lt;0 rows&gt; (or 0-length row.names)\n\n$poids.coquille\n[1] 1 2 3 4 5 6\n&lt;0 rows&gt; (or 0-length row.names)\n\n$age\n      1  2  3  4  5  6\n373   6  9  6  6  5  5\n526  10 11 11  9 10 10\n905  10  9 15 11 14  9\n953  13 10 12 12 12 17\n1011  8  8  8  8  8  9\n1017 11  9 11 12 11  8\n1047 10 12 12  7  9 12\n1253 10 10 11  8 15 12\n1379 12  9  8 12  9 12\n1450  8  9  9  7  9  9\n2511 10  8 10  9  9 10\n2567  8 10  8  9  9 11\n2650 11 14  9 10 10 11\n2892 11  9 18 10  9 11\n2985  9  8 18 12  8 10\n\nnames(crabe)\n\n[1] \"sexe\"           \"longueur\"       \"diametre\"       \"hauteur\"       \n[5] \"poids\"          \"poids.chair\"    \"poids.visceres\" \"poids.coquille\"\n[9] \"age\"           \n\nplot(crabe_mix, main=\"Plot avec la m√©thode mix\")\n\n\n\n\n\n\n\n\nNous observons donc que la m√©thode de remplacement par la PMM n‚Äôest pas optimale, choisissons donc l‚Äôimputation par la m√©thode de random forest.\nApr√®s avoir analys√© les graphiques, nous pouvons dire que la meilleure it√©ration est la 2√®me, c‚Äôest pourquoi nous proc√©dons √† l‚Äôimputation avec celle-ci."
  },
  {
    "objectID": "posts/post-with-code/biostatistiques/Final_projet.html#imputation-des-valeurs-manquantes",
    "href": "posts/post-with-code/biostatistiques/Final_projet.html#imputation-des-valeurs-manquantes",
    "title": "Biostatistiques",
    "section": "Imputation des valeurs manquantes",
    "text": "Imputation des valeurs manquantes\n\ncrabe_complet_mice_rf2 &lt;- mice::complete(crabe_rf, 2)"
  },
  {
    "objectID": "posts/post-with-code/biostatistiques/Final_projet.html#v√©rification",
    "href": "posts/post-with-code/biostatistiques/Final_projet.html#v√©rification",
    "title": "Biostatistiques",
    "section": "V√©rification",
    "text": "V√©rification\n\nmd.pattern(crabe_complet_mice_rf2, rotate.names = TRUE)\n\n /\\     /\\\n{  `---'  }\n{  O   O  }\n==&gt;  V &lt;==  No need for mice. This data set is completely observed.\n \\  \\|/  /\n  `-----'\n\n\n\n\n\n\n\n\n\n     sexe longueur diametre hauteur poids poids.chair poids.visceres\n3893    1        1        1       1     1           1              1\n        0        0        0       0     0           0              0\n     poids.coquille age  \n3893              1   1 0\n                  0   0 0\n\n\nToutes les valeurs manquantes ont bien √©t√© imput√©es."
  },
  {
    "objectID": "posts/post-with-code/biostatistiques/Final_projet.html#analyse-descriptive-univari√©e",
    "href": "posts/post-with-code/biostatistiques/Final_projet.html#analyse-descriptive-univari√©e",
    "title": "Biostatistiques",
    "section": "Analyse descriptive univari√©e",
    "text": "Analyse descriptive univari√©e\nLes variables quantitatives sont longueur, diam√®tre, hauteur, poids, poids de la chair, poids des visc√®res, poids de la coquille et √¢ge.\nEt nous avons une seule variable qualitative: le sexe."
  },
  {
    "objectID": "posts/post-with-code/biostatistiques/Final_projet.html#variable-qualitative",
    "href": "posts/post-with-code/biostatistiques/Final_projet.html#variable-qualitative",
    "title": "Biostatistiques",
    "section": "Variable Qualitative",
    "text": "Variable Qualitative\nTableau de contingence\n\ncount(crabe_complet_mice_rf2, sexe)\n\n  sexe    n\n1    F 1225\n2    I 1233\n3    M 1435\n\n\nNous avons trois cat√©gories de sexe : femelle (F), ind√©termin√© (I) et m√¢le (M), avec respectivement 1225, 1233 et 1435 individus dans chaque cat√©gorie."
  },
  {
    "objectID": "posts/post-with-code/biostatistiques/Final_projet.html#variables-quantitatives",
    "href": "posts/post-with-code/biostatistiques/Final_projet.html#variables-quantitatives",
    "title": "Biostatistiques",
    "section": "Variables quantitatives",
    "text": "Variables quantitatives\n\nBoite √† moustache\n\ncrabe_complet_mice_rf2 |&gt;\n    pivot_longer(\n    cols = where(is.numeric)\n    ) |&gt;\n    ggplot() +\n    aes(y = value) +\n    facet_wrap(~ name, scales = \"free_y\") +\n    geom_boxplot() +\n    theme_light()\n\n\n\n\n\n\n\n\nApr√®s avoir v√©rifi√© et corrig√© les deux valeurs aberrantes pour la variable ¬´ hauteur ¬ª, nous avons d√©cid√© de conserver les valeurs extr√™mes pr√©sentes pour les autres variables de type poids et taille. De m√™me, concernant l‚Äô√¢ge, √©tant donn√© que la long√©vit√© d‚Äôun crabe peut atteindre 3 √† 4 ans et que nos donn√©es incluent des valeurs jusqu‚Äô√† 30 mois, soit 2,5 ans, ces observations sont jug√©es coh√©rentes avec le comportement naturel des crabes.\n\n\nHistogrammes\nPour enrichir l‚Äôanalyse, nous visualisons la forme de la distribution √† l‚Äôaide d‚Äôhistogrammes et superposons une courbe de densit√©. Cela nous permet d‚Äô√©valuer visuellement la normalit√© de la distribution et de souligner les modes ainsi que les asym√©tries.\n\n#| warning: false\nggplot(crabe_complet_mice_rf2, aes(x = longueur)) +\n  geom_histogram(aes(y = ..density..), binwidth = 1, fill = \"blue\", color = \"black\", alpha = 0.4) +\n  geom_density(color = \"red\", size = 1) +  \n  labs(title = \"Distribution de la longueur \", x = \"Longueur\", y = \"Densit√©\") +  \n  theme_minimal()\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\n‚Ñπ Please use `linewidth` instead.\n\n\nWarning: The dot-dot notation (`..density..`) was deprecated in ggplot2 3.4.0.\n‚Ñπ Please use `after_stat(density)` instead.\n\n\n\n\n\n\n\n\n\nLa distribution pr√©sente une l√©g√®re asym√©trie √† droite. Cela signifie qu‚Äôil y a une proportion de crabes qui ont des longueurs plus grandes que la moyenne.\n\nggplot(crabe, aes(x = diametre)) +\n  geom_histogram(aes(y = ..density..), binwidth = 1, fill = \"blue\", color = \"black\", alpha = 0.4) +  \n  geom_density(color = \"red\", size = 1) +  \n  labs(title = \"Distribution du diam√®tre  avec courbe de densit√©\",\n    x = \"Diam√®tre\",\n    y = \"Densit√©\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\nLa distribution du diam√®tre n‚Äôest pas sym√©trique ; elle pr√©sente une forme qui semble multimodale et qui n‚Äôest pas normale en raison de ses multiples pics.\n\nggplot(crabe_complet_mice_rf2, aes(x = hauteur)) +\n  geom_histogram(aes(y = ..density..), binwidth = 0.5, fill = \"blue\",color = \"black\", alpha = 0.6) +\n  geom_density(color = \"red\", size = 1) +\n  labs(title = \"Distribution de la hauteur \", x = \"Hauteur\", y = \"Densit√©\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\nLe graphique nous montre une distribution de la hauteur des crabes qui semble √™tre multimodale, car il y a plusieurs pics.\n\nggplot(crabe_complet_mice_rf2, aes(x = poids)) +\n  geom_histogram(aes(y = ..density..), binwidth = 0.1, fill = \"orange\", color = \"black\", alpha = 0.6) +\n  geom_density(color = \"red\", size = 1) +\n  labs(title = \"Distribution du poids \", x = \"Poids\", y = \"Densit√©\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nggplot(crabe_complet_mice_rf2, aes(x = poids.chair)) +\n  geom_histogram(aes(y = ..density..), binwidth = 0.01, fill = \"orange\",  alpha = 0.6) +\n  geom_density(color = \"red\", size = 1) +\n  labs(title = \"Distribution du poids de chair \", x = \"Poids de chair\", y = \"Densit√©\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nggplot(crabe_complet_mice_rf2, aes(x = poids.visceres)) +\n  geom_histogram(aes(y = ..density..), binwidth = 0.01, fill = \"orange\",  alpha = 0.6) +\n  geom_density(color = \"red\", size = 1) +\n  labs(title = \"Distribution du poids des visc√®res \", x = \"Poids des visc√®res\", y = \"Densit√©\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nggplot(crabe_complet_mice_rf2, aes(x = poids.coquille)) +\n  geom_histogram(aes(y = ..density..), binwidth = 0.01, fill = \"orange\",  alpha = 0.6) +\n  geom_density(color = \"red\", size = 1) +\n  labs(title = \"Distribution du poids de la coquille \", x = \"Poids de la coquille\", y = \"Densit√©\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\nLes poids de visc√®res, de la coquille et de la chair, pressentent des distribution asym√©triques √† droite, avec une concentration plus √©lev√©e de valeurs faibles et une queue qui s‚Äô√©tend vers des valeurs plus √©lev√©es.\n\nggplot(crabe_complet_mice_rf2, aes(x = age)) +\n  geom_histogram(aes(y = ..density..), binwidth = 1, fill = \"blue\", alpha = 0.6) +\n  geom_density(color = \"red\", size = 1) +\n  labs(title = \"Distribution de l'√¢ge \", x = \" ge\", y = \"Densit√©\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\nLa queue de la distribution s‚Äô√©tend jusqu‚Äô√† environ 30 mois, avec une diminution progressive de la densit√© au fur et √† mesure que l‚Äô√¢ge augmente, indiquant moins de crabes plus √¢g√©s."
  },
  {
    "objectID": "posts/post-with-code/biostatistiques/Final_projet.html#quantitative---quantitative",
    "href": "posts/post-with-code/biostatistiques/Final_projet.html#quantitative---quantitative",
    "title": "Biostatistiques",
    "section": "Quantitative - Quantitative",
    "text": "Quantitative - Quantitative\n\n ggplot(crabe, aes(x = age, y = diametre, color = sexe)) +\n  geom_point() +\n  scale_color_manual(values = vecteur_couleur) +  \n  theme_minimal() +  \n  labs(title = \"Relation entre l'√¢ge et le diam√®tre \",\n    x = \" ge\",\n    y = \"Diam√®tre\")  \n\n\n\n\n\n\n\n\nNous pouvons observer une tendance positive entre l‚Äô√¢ge et le diam√®tre, ce qui signifie que, en g√©n√©ral, le diam√®tre des crabes augmente avec l‚Äô√¢ge. Et on peut aussi observer que les crabes de sexe ind√©fini sont tr√®s pr√©sents jusqu‚Äô√† l‚Äô√¢ge de 10 mois.\nCorr√©lation (variables type poids)\n\ncor(crabe_complet_mice_rf2[c(\"poids\", \"poids.chair\", \"poids.visceres\", \"poids.coquille\")])\n\n                   poids poids.chair poids.visceres poids.coquille\npoids          1.0000000   0.9689417      0.9655096      0.9552759\npoids.chair    0.9689417   1.0000000      0.9312796      0.8824063\npoids.visceres 0.9655096   0.9312796      1.0000000      0.9061047\npoids.coquille 0.9552759   0.8824063      0.9061047      1.0000000\n\n\nEn ce qui concerne la relation entre le ‚Äúpoids‚Äù, ‚Äúpoids.chair‚Äù, ‚Äúpoids.visceres‚Äù, ‚Äúpoids.coquille‚Äù les fortes corr√©lations indiquent que les diff√©rentes mesures de poids sont interd√©pendantes, ce qui n‚Äôest pas surprenant compte tenu de leur nature biologique.\nLes lignes de r√©gression sont bien ajust√©es √† la distribution des points, bien que quelques points √©loign√©s (valeurs extr√™mes) en particulier dans la plage sup√©rieure des valeurs.\n\nvariables_quantitatives &lt;- c(\"longueur\", \"diametre\", \"hauteur\", \"poids\")\n\n# Cr√©ation de toutes les paires possibles sans r√©p√©tition ni inversion\npaires &lt;- combn(variables_quantitatives, 2, simplify = FALSE)\n\n\ngraphiques &lt;- map(paires, ~ ggplot(crabe_complet_mice_rf2, aes_string(x = .[1], y = .[2], color = \"sexe\")) +\n    geom_point() +\n    geom_smooth(method = \"lm\", se = FALSE) +\n    scale_color_manual(values = vecteur_couleur) +\n    labs(title = paste(\"Relation entre\", .[1], \"et\", .[2])) +\n    theme_classic()\n)\n\n\ngraphiques\n\n[[1]]\n\n\n\n\n\n\n\n\n\n\n[[2]]\n\n\n\n\n\n\n\n\n\n\n[[3]]\n\n\n\n\n\n\n\n\n\n\n[[4]]\n\n\n\n\n\n\n\n\n\n\n[[5]]\n\n\n\n\n\n\n\n\n\n\n[[6]]\n\n\n\n\n\n\n\n\n\nToutes les relations que nous observons sont positives, par exemple la relation entre le diam√®tre et le poids signifie qu‚Äô√† mesure que le diam√®tre augmente, le poids augmente aussi. La ligne de r√©gression pour les femelles est l√©g√®rement sup√©rieure √† celle des m√¢les et des jeunes (I), indiquant que pour un m√™me diam√®tre, les femelles ont tendance √† √™tre plus lourdes.\nLa relation lin√©aire entre longueur et diam√®tre, mais aussi le diam√®tre et la hauteur et elle est presque uniforme entre les sexes et les points autour des lignes de r√©gression sugg√®re une variance faible des r√©sidus.\nEn examinant de plus pr√®s la r√©partition des points selon les cat√©gories de sexe, nous constatons que les donn√©es des m√¢les et des femelles se superposent sur une large gamme de valeurs pour toutes les paires de variables √©tudi√©es, ce qui indique des caract√©ristiques similaires entre ces deux groupes. En revanche, les points repr√©sentant la cat√©gorie ind√©termin√©e (I) se concentrent davantage sur les √©chelons inf√©rieurs des variables mesur√©es, sugg√©rant que les individus class√©s comme ind√©termin√©s tendent √† avoir des longueurs, des diam√®tres et des poids inf√©rieurs par rapport aux m√¢les et aux femelles."
  },
  {
    "objectID": "posts/post-with-code/biostatistiques/Final_projet.html#qualitative---quantitative",
    "href": "posts/post-with-code/biostatistiques/Final_projet.html#qualitative---quantitative",
    "title": "Biostatistiques",
    "section": "Qualitative - quantitative",
    "text": "Qualitative - quantitative\nAfin d‚Äôexaminer les relations entre nos variables quantitatives et notre variable qualitative, nous proc√©dons √† une visualisations deux √† deux :\n\nggplot(crabe_complet_mice_rf2, aes(x = sexe, y = longueur)) +\n  geom_boxplot() +\n  labs(title = \"Comparaison de la taille entre les sexes \", x = \"Sexe\", y = \"Longueur\")\n\n\n\n\n\n\n\n\nNous pouvons observer que la m√©diane semble √™tre l√©g√®rement plus √©lev√©e pour les femelles que pour les m√¢les et aussi elles semblent avoir une √©tendue interquartile (entre le premier et le troisi√®me quartile) plus √©troite que celle des m√¢les. Cela indique que les longueurs des femelles sont moins dispers√©es autour de la m√©diane.\n\nggplot(crabe_complet_mice_rf2, aes(x = sexe, y = poids)) +\n  geom_boxplot() +\n  labs(title = \"Comparaison du poids entre les sexes \", x = \"Sexe\", y = \"Poids\")\n\n\n\n\n\n\n\n\nLes m√©dianes semblent similaires entre les sexes.\n\nggplot(crabe_complet_mice_rf2) +\n    aes(x = poids, fill = sexe) +\n    geom_histogram(bins = 50) +\n    scale_fill_manual(values = vecteur_couleur) +\n    theme_bw()\n\n\n\n\n\n\n\n\nLes crabes f√©minins et masculins ont des distributions similaires, avec une gamme de poids √©tendue, tandis que les ind√©termin√©es ont une distribution plus concentr√©e vers les poids inf√©rieurs.\nFr√©quences en fonction du sexe\n\ncrabe_complet_mice_rf2 |&gt;\n  group_by(sexe, diametre) |&gt;\n  count()\n\n# A tibble: 266 √ó 3\n# Groups:   sexe, diametre [266]\n   sexe  diametre     n\n   &lt;chr&gt;    &lt;dbl&gt; &lt;int&gt;\n 1 F         14.9     1\n 2 F         16.0     1\n 3 F         16.8     1\n 4 F         17.1     2\n 5 F         17.5     1\n 6 F         19.0     1\n 7 F         19.4     2\n 8 F         19.8     3\n 9 F         20.2     3\n10 F         20.6     2\n# ‚Ñπ 256 more rows\n\n\n\ncrabe_complet_mice_rf2 |&gt;\n  group_by(sexe, poids) |&gt;\n  count()\n\n# A tibble: 3,093 √ó 3\n# Groups:   sexe, poids [3,093]\n   sexe   poids     n\n   &lt;chr&gt;  &lt;dbl&gt; &lt;int&gt;\n 1 F     0.0643     1\n 2 F     0.113      1\n 3 F     0.119      1\n 4 F     0.125      1\n 5 F     0.137      1\n 6 F     0.149      1\n 7 F     0.151      1\n 8 F     0.154      1\n 9 F     0.158      1\n10 F     0.161      1\n# ‚Ñπ 3,083 more rows\n\n\n\ncrabe_complet_mice_rf2 |&gt;\n  group_by(sexe, age) |&gt;\n  count()\n\n# A tibble: 68 √ó 3\n# Groups:   sexe, age [68]\n   sexe    age     n\n   &lt;chr&gt; &lt;int&gt; &lt;int&gt;\n 1 F         5     4\n 2 F         6    15\n 3 F         7    39\n 4 F         8   114\n 5 F         9   220\n 6 F        10   237\n 7 F        11   185\n 8 F        12   120\n 9 F        13    85\n10 F        14    54\n# ‚Ñπ 58 more rows"
  },
  {
    "objectID": "posts/post-with-code/biostatistiques/Final_projet.html#base-avec-crabe-jeune",
    "href": "posts/post-with-code/biostatistiques/Final_projet.html#base-avec-crabe-jeune",
    "title": "Biostatistiques",
    "section": "Base avec crabe jeune",
    "text": "Base avec crabe jeune\n\ncrabe_jeune&lt;-crabe |&gt; filter (age&lt;=9)"
  },
  {
    "objectID": "posts/post-with-code/biostatistiques/Final_projet.html#boite-√†-moustache-avec-crabe-jeune",
    "href": "posts/post-with-code/biostatistiques/Final_projet.html#boite-√†-moustache-avec-crabe-jeune",
    "title": "Biostatistiques",
    "section": "Boite √† moustache avec crabe jeune",
    "text": "Boite √† moustache avec crabe jeune\n\ncrabe_jeune |&gt;\n  pivot_longer(\n    cols = where(is.numeric)\n    ) |&gt;\n  ggplot() +\n  aes(y = value) +\n  facet_wrap(~ name, scales = \"free_y\") +\n  geom_boxplot() +\n  theme_light()\n\nWarning: Removed 22 rows containing non-finite outside the scale range\n(`stat_boxplot()`).\n\n\n\n\n\n\n\n\n\n\ncrabe_jeune|&gt;\n  pivot_longer(\n    cols = longueur:age,\n    names_to = \"mesure\",\n    values_to = \"valeur\"\n    ) |&gt;\n  ggplot() +\n  aes(y = valeur, x = sexe, color = sexe) +\n  geom_boxplot() +\n  geom_jitter(alpha = 0.3) +\n  scale_fill_manual(values = vecteur_couleur)+\n  facet_wrap(~ mesure, scales = \"free_y\") +\n  theme_bw()"
  },
  {
    "objectID": "posts/post-with-code/biostatistiques/Final_projet.html#regresion",
    "href": "posts/post-with-code/biostatistiques/Final_projet.html#regresion",
    "title": "Biostatistiques",
    "section": "Regresion",
    "text": "Regresion\n\ncrabes_reg &lt;- crabe_jeune |&gt;\n  mutate(sexe = case_when(\n    sexe == \"M\" ~ 0,\n    sexe == \"F\" ~ 1\n    ))\n\ncount(crabes_reg, sexe)\n\n  sexe    n\n1    0  533\n2    1  390\n3   NA 1000\n\ncrabes_reg |&gt;\n  pivot_longer(\n    cols = longueur:age,\n    names_to = \"mesure\",\n    values_to = \"valeur\"\n    ) |&gt;\n  ggplot() +\n  aes(y = valeur) +\n  geom_boxplot() +\n  facet_wrap(~ mesure, scales = \"free_y\") +\n  theme_bw()\n\nWarning: Removed 22 rows containing non-finite outside the scale range\n(`stat_boxplot()`).\n\n\n\n\n\n\n\n\nstr(crabes_reg)\n\n'data.frame':   1923 obs. of  9 variables:\n $ sexe          : num  1 0 NA NA 1 NA 0 0 NA NA ...\n $ longueur      : num  43.8 27.1 31.6 27.1 47.2 ...\n $ diametre      : num  35.8 19.8 23.6 20.2 35.4 ...\n $ hauteur       : num  12.57 6.48 7.62 6.48 10.67 ...\n $ poids         : num  0.698 0.153 0.225 0.196 0.813 ...\n $ poids.chair   : num  0.3496 0.0651 0.0916 0.0981 0.385 ...\n $ poids.visceres: num  0.1583 0.039 0.0454 0.0422 0.1917 ...\n $ poids.coquille: num  0.1913 0.0442 0.0784 0.0482 0.2049 ...\n $ age           : int  9 6 6 6 8 7 6 9 7 6 ...\n\n\nS√©paration des donn√©es en ensembles d‚Äôentra√Ænement et de test\n\ncrabes_entrainement &lt;- crabes_reg |&gt;\n  filter(!is.na(sexe)) |&gt;\n  slice_sample(prop = 0.8)\n\nV√©rification\n\ncrabes_verification &lt;- anti_join(\n  crabes_reg,\n  crabes_entrainement\n\n) |&gt;\n  filter(!is.na(sexe))\n\nJoining with `by = join_by(sexe, longueur, diametre, hauteur, poids,\npoids.chair, poids.visceres, poids.coquille, age)`"
  },
  {
    "objectID": "posts/post-with-code/biostatistiques/Final_projet.html#r√©gression-logistique",
    "href": "posts/post-with-code/biostatistiques/Final_projet.html#r√©gression-logistique",
    "title": "Biostatistiques",
    "section": "R√©gression logistique",
    "text": "R√©gression logistique\n\nregression_logistique &lt;- glm(\n  sexe ~ longueur + diametre + hauteur + poids + poids.chair + poids.visceres + poids.coquille + age,\n  data = crabes_entrainement,\n  family = binomial\n)\n\ncar::Anova(regression_logistique)\n\nAnalysis of Deviance Table (Type II tests)\n\nResponse: sexe\n               LR Chisq Df Pr(&gt;Chisq)  \nlongueur         2.5231  1    0.11219  \ndiametre         0.0935  1    0.75978  \nhauteur          0.0963  1    0.75633  \npoids            0.3523  1    0.55283  \npoids.chair      3.4108  1    0.06477 .\npoids.visceres   0.0200  1    0.88750  \npoids.coquille   0.4589  1    0.49813  \nage              0.0015  1    0.96905  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nSelon les r√©sultats, aucun des pr√©dicteurs n‚Äôest significatif au seuil traditionnel de 0.05, bien que poids.chair soit proche avec une valeur de p de 0.06477. Cela sugg√®re qu‚Äôil pourrait y avoir une association entre le poids de la chair et le sexe des crabes.\n\nregression_logistique2 &lt;- glm(\n  sexe ~ poids.chair,\n  data = crabes_entrainement,\n  family = binomial\n)\n\ncar::Anova(regression_logistique2)\n\nAnalysis of Deviance Table (Type II tests)\n\nResponse: sexe\n            LR Chisq Df Pr(&gt;Chisq)    \npoids.chair   11.391  1   0.000738 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nplot(regression_logistique2)"
  },
  {
    "objectID": "posts/post-with-code/variables_latentes/variables_latentes.html",
    "href": "posts/post-with-code/variables_latentes/variables_latentes.html",
    "title": "Variables latentes",
    "section": "",
    "text": "Discrimination des saumons suivant leur provenance et leur mode de production sur la base de donn√©es de caract√©risation chimique.\n\n\n\n\nVous avez la possibilit√© de t√©l√©charger le document ici :) üì• T√©l√©charger le fichier PDF\nPr√©sentation du code\nJe vous pr√©sente ci-dessous, le code utilis√© pour mener √† bien ce projet, avec les √©tapes et explications correspondantes.\nLibrairies\n\nsuppressPackageStartupMessages({\nlibrary(caret)\nlibrary(corrplot)\nlibrary(ggplot2)\nlibrary(FactoMineR)\nlibrary(factoextra)\nlibrary(mixOmics)\nlibrary(tidyr)\nlibrary(here)\n})  \n\n\nsaumon &lt;- read.csv(here(\"data\", \"ICPMS_raw_data.csv\"))"
  },
  {
    "objectID": "posts/post-with-code/variables_latentes/variables_latentes.html#convertir-la-colonne-pays-en-factor",
    "href": "posts/post-with-code/variables_latentes/variables_latentes.html#convertir-la-colonne-pays-en-factor",
    "title": "Variables latentes",
    "section": "Convertir la colonne pays en factor",
    "text": "Convertir la colonne pays en factor\n\nsaumon$pays &lt;- as.factor(saumon$pays)\nsummary(saumon)\n\n        pays           Li              B                Al         \n Alaskan  : 99   Min.   : 0.00   Min.   :   0.0   Min.   :   35.7  \n Iceland-F: 55   1st Qu.: 9.95   1st Qu.:  92.1   1st Qu.:  943.5  \n Iceland-W: 90   Median :17.79   Median : 359.7   Median : 1447.5  \n Norway   :100   Mean   :20.61   Mean   : 382.7   Mean   : 2408.3  \n Scotland :177   3rd Qu.:28.96   3rd Qu.: 585.3   3rd Qu.: 2736.1  \n                 Max.   :87.00   Max.   :1346.1   Max.   :45092.6  \n       V               Cr               Mn              Fe       \n Min.   : 0.00   Min.   :  5.72   Min.   :104.7   Min.   : 2921  \n 1st Qu.: 6.30   1st Qu.: 18.52   1st Qu.:191.4   1st Qu.: 5423  \n Median :10.20   Median : 30.30   Median :228.3   Median : 7012  \n Mean   :11.56   Mean   : 42.62   Mean   :245.1   Mean   : 8231  \n 3rd Qu.:15.30   3rd Qu.: 51.60   3rd Qu.:289.2   3rd Qu.:10301  \n Max.   :95.70   Max.   :396.75   Max.   :774.9   Max.   :40184  \n       Co              Ni                Cu               Zn       \n Min.   : 3.50   Min.   :   3.90   Min.   : 458.4   Min.   : 5765  \n 1st Qu.: 7.50   1st Qu.:  15.30   1st Qu.: 873.3   1st Qu.:10471  \n Median :10.80   Median :  23.68   Median :1159.3   Median :13916  \n Mean   :10.92   Mean   :  58.92   Mean   :1252.4   Mean   :13747  \n 3rd Qu.:13.57   3rd Qu.:  50.70   3rd Qu.:1476.0   3rd Qu.:16421  \n Max.   :29.90   Max.   :1596.60   Max.   :8928.6   Max.   :26602  \n       As               Se               Rb             Sr        \n Min.   : 788.1   Min.   : 453.3   Min.   :1838   Min.   : 281.1  \n 1st Qu.:1343.4   1st Qu.: 825.6   1st Qu.:2879   1st Qu.: 845.8  \n Median :1799.1   Median :1296.8   Median :3438   Median :1200.0  \n Mean   :2091.7   Mean   :1375.0   Mean   :3523   Mean   :1379.4  \n 3rd Qu.:2530.9   3rd Qu.:1833.3   3rd Qu.:4127   3rd Qu.:1738.2  \n Max.   :6746.5   Max.   :3154.4   Max.   :6320   Max.   :8613.3  \n       Nb               Mo              Cd               Cs        \n Min.   :  0.00   Min.   : 3.00   Min.   : 0.000   Min.   : 47.10  \n 1st Qu.:  2.70   1st Qu.: 9.00   1st Qu.: 0.300   1st Qu.: 68.39  \n Median :  6.30   Median :11.70   Median : 0.990   Median : 82.20  \n Mean   : 15.66   Mean   :12.26   Mean   : 4.723   Mean   : 89.19  \n 3rd Qu.: 13.78   3rd Qu.:14.40   3rd Qu.: 7.800   3rd Qu.:107.40  \n Max.   :296.92   Max.   :66.00   Max.   :51.900   Max.   :217.19  \n       Ta        \n Min.   :  0.30  \n 1st Qu.:  4.94  \n Median : 10.52  \n Mean   : 19.09  \n 3rd Qu.: 20.15  \n Max.   :268.14"
  },
  {
    "objectID": "posts/post-with-code/variables_latentes/variables_latentes.html#configurer-preprocess-pour-la-normalisation-min-max",
    "href": "posts/post-with-code/variables_latentes/variables_latentes.html#configurer-preprocess-pour-la-normalisation-min-max",
    "title": "Variables latentes",
    "section": "Configurer preProcess pour la normalisation min-max",
    "text": "Configurer preProcess pour la normalisation min-max\n\npreproc &lt;- preProcess(saumon,  method = \"range\")\nsaumon_norm &lt;- predict(preproc, saumon)"
  },
  {
    "objectID": "posts/post-with-code/variables_latentes/variables_latentes.html#v√©rification-de-valeurs-manquantes",
    "href": "posts/post-with-code/variables_latentes/variables_latentes.html#v√©rification-de-valeurs-manquantes",
    "title": "Variables latentes",
    "section": "V√©rification de valeurs manquantes",
    "text": "V√©rification de valeurs manquantes\n{sum(is.null(saumon))} str(saumon_norm)"
  },
  {
    "objectID": "posts/post-with-code/variables_latentes/variables_latentes.html#matrice-de-corr√©lation",
    "href": "posts/post-with-code/variables_latentes/variables_latentes.html#matrice-de-corr√©lation",
    "title": "Variables latentes",
    "section": "Matrice de corr√©lation",
    "text": "Matrice de corr√©lation\n\ncor(saumon_norm[, -1], use = \"complete.obs\")\n\n            Li            B          Al            V         Cr          Mn\nLi  1.00000000  0.724641027  0.04008869  0.024334770 0.08005162  0.12836481\nB   0.72464103  1.000000000 -0.11376094  0.070988674 0.04267486 -0.16201305\nAl  0.04008869 -0.113760939  1.00000000 -0.122583713 0.07338391  0.30331472\nV   0.02433477  0.070988674 -0.12258371  1.000000000 0.09779409 -0.01296994\nCr  0.08005162  0.042674861  0.07338391  0.097794089 1.00000000  0.14218022\nMn  0.12836481 -0.162013053  0.30331472 -0.012969938 0.14218022  1.00000000\nFe  0.25317831  0.008776603  0.27505466  0.159549917 0.28942941  0.46487195\nCo -0.26034878 -0.425520211  0.17365018 -0.038118096 0.05600151  0.50677703\nNi  0.15426275  0.174676930 -0.04150267  0.094758157 0.23774355 -0.03411629\nCu  0.25409546  0.022376096  0.09103141  0.111587130 0.30627305  0.33886807\nZn  0.26209502 -0.091873578  0.21303529  0.039069060 0.12705212  0.62871674\nAs  0.07282843 -0.231511136  0.24805751 -0.127048528 0.04332965  0.45817103\nSe  0.19054180 -0.161683420  0.18229134 -0.008138077 0.16589213  0.51642643\nRb  0.04282060 -0.217158345  0.21644267 -0.074508843 0.18615152  0.64335441\nSr  0.36064173  0.275550424  0.13837845  0.114383963 0.06042190  0.34308817\nNb -0.05934258 -0.021515850 -0.01853557 -0.019491929 0.03429055  0.10774112\nMo  0.10421444  0.140319783  0.01026243  0.088107541 0.42042750  0.20471256\nCd  0.09084172 -0.135760711  0.15647636  0.093146759 0.14878504  0.29846500\nCs  0.02233589 -0.273479302  0.28315336 -0.111128301 0.16923000  0.60488525\nTa -0.09605333 -0.128510184  0.01275089 -0.049036467 0.06082321  0.20172671\n            Fe          Co            Ni         Cu            Zn          As\nLi 0.253178306 -0.26034878  0.1542627477 0.25409546  0.2620950186  0.07282843\nB  0.008776603 -0.42552021  0.1746769304 0.02237610 -0.0918735782 -0.23151114\nAl 0.275054656  0.17365018 -0.0415026707 0.09103141  0.2130352910  0.24805751\nV  0.159549917 -0.03811810  0.0947581574 0.11158713  0.0390690600 -0.12704853\nCr 0.289429410  0.05600151  0.2377435505 0.30627305  0.1270521172  0.04332965\nMn 0.464871950  0.50677703 -0.0341162865 0.33886807  0.6287167425  0.45817103\nFe 1.000000000  0.23142264  0.1519759449 0.60107970  0.6699140899  0.17341713\nCo 0.231422638  1.00000000 -0.2197332620 0.16829169  0.4893560155  0.37495967\nNi 0.151975945 -0.21973326  1.0000000000 0.59157403  0.0009223212 -0.16137993\nCu 0.601079703  0.16829169  0.5915740256 1.00000000  0.5935674243  0.13872561\nZn 0.669914090  0.48935602  0.0009223212 0.59356742  1.0000000000  0.52222525\nAs 0.173417127  0.37495967 -0.1613799282 0.13872561  0.5222252491  1.00000000\nSe 0.769207606  0.30519477  0.0590346669 0.62420299  0.8192668000  0.34391452\nRb 0.465893237  0.62962681 -0.0820321103 0.41919822  0.6855785324  0.46802316\nSr 0.145974273 -0.01132413 -0.0046252187 0.06733761  0.1647603608  0.03433229\nNb 0.083513250  0.17287801 -0.0011868805 0.07977229  0.1744046862  0.09849027\nMo 0.101636738  0.31989378  0.2582018447 0.37676314  0.2552816609  0.09634495\nCd 0.667687354  0.10537444  0.0858341537 0.44220436  0.5185553926  0.05601936\nCs 0.380361544  0.53676923 -0.1205520641 0.29233323  0.5767797766  0.61844455\nTa 0.158705002  0.27069289  0.0063345396 0.15556021  0.2734057750  0.15783964\n             Se          Rb           Sr          Nb          Mo          Cd\nLi  0.190541801  0.04282060  0.360641733 -0.05934258  0.10421444  0.09084172\nB  -0.161683420 -0.21715834  0.275550424 -0.02151585  0.14031978 -0.13576071\nAl  0.182291343  0.21644267  0.138378448 -0.01853557  0.01026243  0.15647636\nV  -0.008138077 -0.07450884  0.114383963 -0.01949193  0.08810754  0.09314676\nCr  0.165892135  0.18615152  0.060421901  0.03429055  0.42042750  0.14878504\nMn  0.516426429  0.64335441  0.343088165  0.10774112  0.20471256  0.29846500\nFe  0.769207606  0.46589324  0.145974273  0.08351325  0.10163674  0.66768735\nCo  0.305194769  0.62962681 -0.011324131  0.17287801  0.31989378  0.10537444\nNi  0.059034667 -0.08203211 -0.004625219 -0.00118688  0.25820184  0.08583415\nCu  0.624202989  0.41919822  0.067337612  0.07977229  0.37676314  0.44220436\nZn  0.819266800  0.68557853  0.164760361  0.17440469  0.25528166  0.51855539\nAs  0.343914522  0.46802316  0.034332287  0.09849027  0.09634495  0.05601936\nSe  1.000000000  0.67263481  0.064750989  0.20787315  0.10240250  0.71970435\nRb  0.672634807  1.00000000  0.042192750  0.23350173  0.23237317  0.36564902\nSr  0.064750989  0.04219275  1.000000000 -0.18928860 -0.05813792  0.11870994\nNb  0.207873151  0.23350173 -0.189288598  1.00000000  0.24765213  0.12228641\nMo  0.102402501  0.23237317 -0.058137918  0.24765213  1.00000000 -0.05689127\nCd  0.719704345  0.36564902  0.118709942  0.12228641 -0.05689127  1.00000000\nCs  0.542852861  0.86687886  0.115683237  0.15873294  0.09295079  0.27459355\nTa  0.332121329  0.36836121 -0.208432236  0.94275429  0.28107000  0.19763015\n            Cs          Ta\nLi  0.02233589 -0.09605333\nB  -0.27347930 -0.12851018\nAl  0.28315336  0.01275089\nV  -0.11112830 -0.04903647\nCr  0.16923000  0.06082321\nMn  0.60488525  0.20172671\nFe  0.38036154  0.15870500\nCo  0.53676923  0.27069289\nNi -0.12055206  0.00633454\nCu  0.29233323  0.15556021\nZn  0.57677978  0.27340577\nAs  0.61844455  0.15783964\nSe  0.54285286  0.33212133\nRb  0.86687886  0.36836121\nSr  0.11568324 -0.20843224\nNb  0.15873294  0.94275429\nMo  0.09295079  0.28107000\nCd  0.27459355  0.19763015\nCs  1.00000000  0.28032163\nTa  0.28032163  1.00000000\n\ncorrplot::corrplot(cor(saumon_norm[, -1]), method = \"color\", type = \"upper\", order=\"FPC\", \n                   tl.cex = 0.6,\n                   number.cex = 0.5,\n                   addCoef.col = \"black\")\n\n\n\n\n\n\n\n\nDistribution des valeurs observ√©s pour les diff√©rents variables"
  },
  {
    "objectID": "posts/post-with-code/variables_latentes/variables_latentes.html#transformation-des-donn√©es-en-format-long",
    "href": "posts/post-with-code/variables_latentes/variables_latentes.html#transformation-des-donn√©es-en-format-long",
    "title": "Variables latentes",
    "section": "Transformation des donn√©es en format long",
    "text": "Transformation des donn√©es en format long\n\nsaumon_norm_long &lt;- pivot_longer(saumon_norm, cols = -1, names_to = \"variable\", values_to = \"value\")\n\nHistogrammes avec courbes de densit√© pour chaque variable\n\nggplot(saumon_norm_long, aes(x = value)) +\n  geom_histogram(aes(y = after_stat(density)), bins = 30, fill = \"blue\", color = \"white\") +\n  geom_density(color = \"red\", linewidth = 1) +\n  facet_wrap(~variable, scales = \"free\") +\n  theme_minimal() +\n  labs(y = \"Densit√©\", title = \"Distribution des Variables avec Courbe de Densit√©\")\n\n\n\n\n\n\n\n\nTableau de contingence des pays\n\ntable(saumon_norm$pays)\n\n\n  Alaskan Iceland-F Iceland-W    Norway  Scotland \n       99        55        90       100       177"
  },
  {
    "objectID": "posts/post-with-code/variables_latentes/variables_latentes.html#acp-factominer",
    "href": "posts/post-with-code/variables_latentes/variables_latentes.html#acp-factominer",
    "title": "Variables latentes",
    "section": "ACP FactoMineR",
    "text": "ACP FactoMineR\n\npca_res &lt;- PCA(saumon_norm[, -1], scale.unit = FALSE)\n\n\n\n\n\n\n\n\nWarning: ggrepel: 18 unlabeled data points (too many overlaps). Consider\nincreasing max.overlaps\n\n\n\n\n\n\n\n\nfviz_screeplot(pca_res)\n\n\n\n\n\n\n\nfviz_pca_var(pca_res)\n\n\n\n\n\n\n\nfviz_pca_var(pca_res, axes = c(2,3))\n\n\n\n\n\n\n\nround(pca_res$var$cos2,2)\n\n   Dim.1 Dim.2 Dim.3 Dim.4 Dim.5\nLi  0.00  0.79  0.03  0.02  0.00\nB   0.11  0.80  0.04  0.02  0.00\nAl  0.08  0.00  0.01  0.03  0.01\nV   0.00  0.01  0.03  0.00  0.03\nCr  0.04  0.02  0.00  0.03  0.08\nMn  0.51  0.00  0.05  0.00  0.05\nFe  0.46  0.11  0.14  0.00  0.02\nCo  0.38  0.14  0.09  0.06  0.10\nNi  0.00  0.06  0.05  0.01  0.00\nCu  0.31  0.10  0.08  0.00  0.01\nZn  0.78  0.06  0.00  0.01  0.00\nAs  0.35  0.01  0.28  0.12  0.17\nSe  0.77  0.05  0.14  0.00  0.01\nRb  0.77  0.00  0.05  0.04  0.03\nSr  0.01  0.14  0.02  0.08  0.13\nNb  0.06  0.00  0.00  0.54  0.28\nMo  0.04  0.02  0.04  0.22  0.02\nCd  0.33  0.03  0.36  0.01  0.00\nCs  0.65  0.01  0.14  0.00  0.00\nTa  0.15  0.01  0.00  0.51  0.24"
  },
  {
    "objectID": "posts/post-with-code/variables_latentes/variables_latentes.html#acp-mixomics",
    "href": "posts/post-with-code/variables_latentes/variables_latentes.html#acp-mixomics",
    "title": "Variables latentes",
    "section": "ACP mixOmics",
    "text": "ACP mixOmics\n\npca.saumon = pca(saumon_norm[, -1], scale = FALSE, ncomp = 10, center = TRUE)\nplotIndiv(pca.saumon, group = saumon_norm$pays, ind.names = FALSE,  legend = TRUE, \n          title = 'Saumons par Pays - ACP',\n          size.title = rel(1))"
  },
  {
    "objectID": "posts/post-with-code/variables_latentes/variables_latentes.html#s√©paration-du-jeu-de-donn√©es-en-jeu-dentra√Ænement-et-jeu-test",
    "href": "posts/post-with-code/variables_latentes/variables_latentes.html#s√©paration-du-jeu-de-donn√©es-en-jeu-dentra√Ænement-et-jeu-test",
    "title": "Variables latentes",
    "section": "S√©paration du jeu de donn√©es en jeu d‚Äôentra√Ænement et jeu test",
    "text": "S√©paration du jeu de donn√©es en jeu d‚Äôentra√Ænement et jeu test\n\nintrain &lt;- createDataPartition(saumon_norm$pays, p=0.8, list=FALSE)\n#save(intrain,file=\"intrain.Rdata\") # enregistrer intrain pour la reprod \nload(file = here(\"data\", \"intrain.Rdata\"))# t√©lecharger le fichier\n\nX.app &lt;- saumon_norm[intrain, -1]\nY.app &lt;- saumon_norm[intrain, 1]\nX.test &lt;- saumon_norm[-intrain, -1]\nY.test &lt;- saumon_norm[-intrain, 1]"
  },
  {
    "objectID": "posts/post-with-code/memoire/memoire_m1.html",
    "href": "posts/post-with-code/memoire/memoire_m1.html",
    "title": "M√©moire",
    "section": "",
    "text": "SensibiliteÃÅ des prix agricoles face aux chocs climatiques\nSeÃÅries temporelles au BreÃÅsil de janvier 2000 aÃÄ deÃÅcembre 2022"
  },
  {
    "objectID": "posts/post-with-code/memoire/memoire_m1.html#chargement-de-donn√©es",
    "href": "posts/post-with-code/memoire/memoire_m1.html#chargement-de-donn√©es",
    "title": "M√©moire",
    "section": "Chargement de donn√©es",
    "text": "Chargement de donn√©es\nLes donn√©es de la variable du prix du p√©trole ont une fr√©quence journali√®re, nous calculons donc la moyenne pour avoir un prix moyen mensuel\n\npetrole &lt;- read_excel(here(\"data\", \"donnees_br.xlsx\"), sheet = 'prix_petrole')\n\npetrole$date &lt;- as.Date(petrole$date)\n\n#  Colonnes pour l'ann√©e et le mois\npetrole &lt;- petrole %&gt;%\n  mutate(\n    year = year(date),\n    month = month(date)\n  )\n\nprix_petrole &lt;- petrole %&gt;%\n  group_by(year, month) %&gt;%\n  summarise(\n    prix_moyen = mean(prix, na.rm = TRUE), \n    .groups = 'drop'  # regroupement apr√®s le summarise\n  )\nrm(petrole) # supprime p√©trole en jours\n\nR√©cup√©ration de l‚Äôensemble de nos variables et remplacement de la variable prix du p√©trole en jours, par le prix moyen mensuel\n\n# ensemble de variables\n\ndata &lt;- read_excel(here(\"data\", \"donnees_br.xlsx\"))\n\ndata$petrole &lt;- prix_petrole$prix_moyen \n\n\nValeurs manquantes et format des donn√©es\n\nsum(is.na(data)) # v√©rification des valeurs manquants\n\n[1] 48\n\ndata &lt;- drop_na(data)\ndim(data)\n\n[1] 276  10\n\nstr(data) # v√©rification format\n\ntibble [276 √ó 10] (S3: tbl_df/tbl/data.frame)\n $ date         : chr [1:276] \"2000.01\" \"2000.02\" \"2000.03\" \"2000.04\" ...\n $ IPA          : num [1:276] 199 196 193 192 193 ...\n $ CDD          : num [1:276] 2.86 2.94 3.03 4.61 12.14 ...\n $ precipitation: num [1:276] 255 241 247 206 124 ...\n $ temperature  : num [1:276] 0.558 0.226 0.159 0.607 0.548 ...\n $ exportations : num [1:276] 7.5 8.4 11.7 20.2 23.2 22.7 22.1 27.4 16.5 16 ...\n $ importations : num [1:276] 81.8 113 117.5 116.5 128.4 ...\n $ SMIC         : num [1:276] 136 136 136 151 151 151 151 151 151 151 ...\n $ taux_change  : num [1:276] 1.8 1.78 1.74 1.77 1.83 ...\n $ petrole      : num [1:276] 25.5 27.8 27.5 22.8 27.7 ...\n\n# On transforme la variable smic en num√©rique\ndata$SMIC &lt;- as.numeric(data$SMIC)\n\n\n# Conversion la colonne de date en type  yearmon\ndata$date &lt;- as.yearmon(data$date, \"%Y.%m\")\n\nLes donn√©es climatiques sont compl√®tes jusqu‚Äôau mois de d√©cembre 2022, on conserve donc l‚Äôensemble des donn√©es du mois de janvier 2000 √† d√©cembre 2022. Au total nous avons 276 observations pour 13 variables."
  },
  {
    "objectID": "posts/post-with-code/memoire/memoire_m1.html#statistiques-descriptives",
    "href": "posts/post-with-code/memoire/memoire_m1.html#statistiques-descriptives",
    "title": "M√©moire",
    "section": "Statistiques descriptives",
    "text": "Statistiques descriptives\n\nsummary(data)\n\n      date           IPA              CDD         precipitation   \n Min.   :2000   Min.   : 191.6   Min.   : 2.380   Min.   : 33.16  \n 1st Qu.:2006   1st Qu.: 401.5   1st Qu.: 4.728   1st Qu.: 72.14  \n Median :2011   Median : 649.3   Median : 8.440   Median :148.39  \n Mean   :2011   Mean   : 748.4   Mean   :10.107   Mean   :147.15  \n 3rd Qu.:2017   3rd Qu.: 944.3   3rd Qu.:15.315   3rd Qu.:212.66  \n Max.   :2023   Max.   :2133.2   Max.   :23.340   Max.   :288.10  \n  temperature       exportations     importations         SMIC       \n Min.   :-0.0920   Min.   :  7.50   Min.   : 50.80   Min.   : 136.0  \n 1st Qu.: 0.7768   1st Qu.: 31.70   1st Qu.: 81.00   1st Qu.: 300.0  \n Median : 1.0695   Median : 48.40   Median : 92.60   Median : 545.0  \n Mean   : 1.0869   Mean   : 59.26   Mean   : 93.65   Mean   : 602.5  \n 3rd Qu.: 1.3250   3rd Qu.: 82.65   3rd Qu.:107.47   3rd Qu.: 937.0  \n Max.   : 2.4310   Max.   :194.10   Max.   :149.80   Max.   :1212.0  \n  taux_change       petrole      \n Min.   :1.564   Min.   : 18.47  \n 1st Qu.:2.002   1st Qu.: 42.53  \n Median :2.473   Median : 62.81  \n Mean   :2.901   Mean   : 65.40  \n 3rd Qu.:3.521   3rd Qu.: 85.50  \n Max.   :5.651   Max.   :134.03  \n\n\n\nBoxplot\n\ndata|&gt;\npivot_longer(\ncols = where(is.numeric)\n) |&gt;\nggplot() +\naes(y = value) +\nfacet_wrap(~ name, scales = \"free_y\") +\ngeom_boxplot() +\ntheme_light()\n\n\n\n\n\n\n\n\n\n\nGraphiques des s√©ries\n\ndata$date &lt;- as.Date(as.yearmon(data$date))\n\n# Boucle sur chaque colonne sauf la date pour cr√©er des graphiques\nfor (column_name in names(data)[-1]) {\np &lt;- ggplot(data, aes(x = date, y = .data[[column_name]], colour = .data[[column_name]])) + \n        geom_line() +\n        scale_color_gradient(low = \"blue\", high = \"red\") + \n        labs(title = paste(\"S√©rie temporelle: \", column_name),\n             x = \"Date\",\n             y = column_name,\n             colour = \"Intensit√©\") +  \n        theme_minimal()\n print(p)\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    print(p)\n\n\n\n\n\n\n\n\n\n\nConvertir en time series\n\n# Boucle pour convertir chaque colonne en ts et les stocker comme variables s√©par√©es\nfor(column_name in names(data)[-1]) {  # Exclure la colonne de date\n    # Cr√©er une s√©rie temporelle pour la colonne actuelle\n    ts_data &lt;- ts(data[[column_name]], start = c(2000, 1), frequency = 12)\n  # variable dans l'environnement global avec un nom dynamique\n    assign(paste0(\"ts_\", column_name), ts_data)\n}"
  },
  {
    "objectID": "posts/post-with-code/memoire/memoire_m1.html#points-atypiques-ou-outliers",
    "href": "posts/post-with-code/memoire/memoire_m1.html#points-atypiques-ou-outliers",
    "title": "M√©moire",
    "section": "Points atypiques ou Outliers",
    "text": "Points atypiques ou Outliers\n(attention cela peut prendre quelques minutes, possibilit√© de charger le fichier apr√®s correction data.adj (pour donn√©es ajust√©es))\n\n#|warning: false\n#|message: false\n\n# on utilise tso() pour chercher les outliers\nfit_CDD &lt;- tso(ts_CDD)\nfit_IPA &lt;- tso(ts_IPA)\n\nWarning in locate.outliers.iloop(resid = resid, pars = pars, cval = cval, :\nstopped when 'maxit.iloop' was reached\n\n\nWarning in locate.outliers.oloop(y = y, fit = fit, types = types, cval = cval,\n: stopped when 'maxit.oloop = 4' was reached\n\nfit_importations &lt;- tso(ts_importations)\nfit_exportations &lt;- tso(ts_exportations)\n\nWarning in locate.outliers.iloop(resid = resid, pars = pars, cval = cval, :\nstopped when 'maxit.iloop' was reached\n\nfit_petrole &lt;- tso(ts_petrole)\nfit_taux_change &lt;- tso(ts_taux_change)\nfit_SMIC &lt;- tso(ts_SMIC)\n\nWarning in locate.outliers.iloop(resid = resid, pars = pars, cval = cval, :\nstopped when 'maxit.iloop' was reached\nWarning in locate.outliers.iloop(resid = resid, pars = pars, cval = cval, :\nstopped when 'maxit.oloop = 4' was reached\n\nfit_precipitation &lt;- tso(ts_precipitation)\nfit_temperature &lt;- tso(ts_temperature)\n\n\n# pour regarder les points atypiques de chaque serie \nfit_CDD # sans outliers \n\nSeries:  \nARIMA(0,0,2)(2,1,2)[12] \n\nCoefficients:\n         ma1     ma2     sar1     sar2     sma1     sma2\n      0.4183  0.2297  -0.8083  -0.0933  -0.0277  -0.6980\ns.e.  0.0635  0.0596   0.1733   0.0830   0.1735   0.1586\n\nsigma^2 = 2.206:  log likelihood = -484.75\nAIC=983.5   AICc=983.94   BIC=1008.53\n\nNo outliers were detected.\n\nfit_IPA \n\nSeries: ts_IPA \nRegression with ARIMA(1,1,0) errors \n\nCoefficients:\n         ar1      LS252     TC258     TC263\n      0.6912  -149.6890  -77.9185  -42.7527\ns.e.  0.0435    13.6418   11.6972   11.6982\n\nsigma^2 = 275.1:  log likelihood = -1160.87\nAIC=2331.73   AICc=2331.96   BIC=2349.82\n\nOutliers:\n  type ind    time coefhat   tstat\n1   LS 252 2020:12 -149.69 -10.973\n2   TC 258 2021:06  -77.92  -6.661\n3   TC 263 2021:11  -42.75  -3.655\n\nfit_importations \n\nSeries: ts_importations \nRegression with ARIMA(1,1,2)(1,0,0)[12] errors \n\nCoefficients:\n         ar1      ma1      ma2    sar1      LS47     AO98    LS195     LS206\n      0.0432  -0.7165  -0.1532  0.2900  -29.4529  47.8804  40.0092  -30.3560\ns.e.  0.3300   0.3263   0.2703  0.0597    7.4462  12.0018   7.3329    7.3662\n\nsigma^2 = 175.7:  log likelihood = -1097.94\nAIC=2213.88   AICc=2214.56   BIC=2246.43\n\nOutliers:\n  type ind    time coefhat  tstat\n1   LS  47 2003:11  -29.45 -3.955\n2   AO  98 2008:02   47.88  3.989\n3   LS 195 2016:03   40.01  5.456\n4   LS 206 2017:02  -30.36 -4.121\n\nfit_exportations \n\nSeries: ts_exportations \nRegression with ARIMA(1,0,0)(0,1,1)[12] errors \n\nCoefficients:\n         ar1     sma1     AO33    AO114    LS185     AO254\n      0.7625  -0.6238  25.6306  31.0681  26.0407  -27.9435\ns.e.  0.0426   0.0510   6.9851   6.8995   6.8729    7.1521\n\nsigma^2 = 94.47:  log likelihood = -975.31\nAIC=1964.61   AICc=1965.05   BIC=1989.65\n\nOutliers:\n  type ind    time coefhat  tstat\n1   AO  33 2002:09   25.63  3.669\n2   AO 114 2009:06   31.07  4.503\n3   LS 185 2015:05   26.04  3.789\n4   AO 254 2021:02  -27.94 -3.907\n\nfit_petrole  # sans outliers\n\nSeries:  \nARIMA(1,1,0) \n\nCoefficients:\n         ar1\n      0.3497\ns.e.  0.0567\n\nsigma^2 = 32.51:  log likelihood = -868.48\nAIC=1740.95   AICc=1741   BIC=1748.19\n\nNo outliers were detected.\n\nfit_taux_change \n\nSeries: ts_taux_change \nRegression with ARIMA(0,1,1) errors \n\nCoefficients:\n         ma1    AO34\n      0.3165  0.3361\ns.e.  0.0573  0.0697\n\nsigma^2 = 0.0143:  log likelihood = 194.75\nAIC=-383.5   AICc=-383.41   BIC=-372.65\n\nOutliers:\n  type ind    time coefhat tstat\n1   AO  34 2002:10  0.3361 4.824\n\nfit_SMIC \n\nSeries: ts_SMIC \nRegression with ARIMA(0,0,5)(0,0,2)[12] errors \n\nCoefficients:\n         ma1     ma2     ma3     ma4     ma5     sma1    sma2  intercept\n      0.8636  0.6544  0.5548  0.3908  0.1828  -0.9308  0.3063   144.4274\ns.e.  0.0632  0.0802  0.0792  0.0747  0.0548   0.0625  0.0594     4.3551\n         LS16     LS40     LS65     LS88    AO121     LS122    LS145    LS157\n      44.9926  61.3801  71.3287  94.4402  76.0256  120.9066  88.0599  44.6969\ns.e.   5.7660   4.2806   3.8698   3.8999   5.0530    4.4605   8.0303  10.7124\n        LS169     LS193    AO229     LS230    LS253     LS265\n      77.6692  177.1326  95.2608  104.2519  74.4118  107.2180\ns.e.   7.9620    4.3219   5.1179    4.4431   8.0232   11.0379\n\nsigma^2 = 69.78:  log likelihood = -972.05\nAIC=1990.11   AICc=1994.49   BIC=2073.38\n\nOutliers:\n   type ind    time coefhat  tstat\n1    LS  16 2001:04   44.99  7.803\n2    LS  40 2003:04   61.38 14.339\n3    LS  65 2005:05   71.33 18.432\n4    LS  88 2007:04   94.44 24.216\n5    AO 121 2010:01   76.03 15.046\n6    LS 122 2010:02  120.91 27.106\n7    LS 145 2012:01   88.06 10.966\n8    LS 157 2013:01   44.70  4.172\n9    LS 169 2014:01   77.67  9.755\n10   LS 193 2016:01  177.13 40.985\n11   AO 229 2019:01   95.26 18.613\n12   LS 230 2019:02  104.25 23.464\n13   LS 253 2021:01   74.41  9.275\n14   LS 265 2022:01  107.22  9.714\n\nfit_precipitation \n\nSeries: ts_precipitation \nRegression with ARIMA(0,0,1)(2,1,0)[12] errors \n\nCoefficients:\n         ma1     sar1     sar2     TC49    AO193\n      0.2476  -0.6126  -0.3736  59.2558  86.5774\ns.e.  0.0571   0.0580   0.0589  14.5850  18.3329\n\nsigma^2 = 424.8:  log likelihood = -1174.07\nAIC=2360.14   AICc=2360.46   BIC=2381.59\n\nOutliers:\n  type ind    time coefhat tstat\n1   TC  49 2004:01   59.26 4.063\n2   AO 193 2016:01   86.58 4.723\n\nfit_temperature # sans outliers\n\nSeries:  \nARIMA(0,1,2) \n\nCoefficients:\n          ma1      ma2\n      -0.6600  -0.1641\ns.e.   0.0588   0.0651\n\nsigma^2 = 0.1426:  log likelihood = -121.87\nAIC=249.74   AICc=249.83   BIC=260.59\n\nNo outliers were detected.\n\n# Graphique\nplot(fit_IPA)\n\n\n\n\n\n\n\nplot(fit_SMIC)\n\n\n\n\n\n\n\nplot(fit_precipitation)\n\n\n\n\n\n\n\nplot(fit_taux_change)\n\n\n\n\n\n\n\nplot(fit_exportations)\n\n\n\n\n\n\n\nplot(fit_importations)\n\n\n\n\n\n\n\nplot(fit_CDD )\n\n'x' does not contain outliers to display\n\n\nNULL\n\n# recuperation des s√©ries ajust√©s \nadj_IPA &lt;- fit_IPA$yadj \nadj_CDD &lt;- fit_CDD$yadj \nadj_importations &lt;- fit_importations$yadj \nadj_exportations &lt;- fit_exportations$yadj \nadj_petrole &lt;- fit_petrole$yadj \nadj_taux_change &lt;- fit_taux_change$yadj \nadj_SMIC &lt;- fit_SMIC$yadj \nadj_precipitation &lt;- fit_precipitation$yadj \nadj_temperature &lt;- fit_temperature$yadj \n\n\nEnregistrement donn√©es ajust√©s\n\n# cr√©ation d'un dataframe o√π les s√©ries ajust√©s seront stock√©s pour √™tres r√©utilises si n√©cessaire plus tard \ndata_adj &lt;- data.frame(\n  Date = data$date,  \n  IPA = adj_IPA,\n  CDD = adj_CDD,\n  importations = adj_importations,\n  exportations = adj_exportations,\n  petrole = adj_petrole,\n  taux_change = adj_taux_change,\n  SMIC = adj_SMIC,\n  precipitation = adj_precipitation,\n  temperature = adj_temperature\n)\n\n#write.csv(data_adj, \"data_adj.csv\", row.names = FALSE)"
  },
  {
    "objectID": "posts/post-with-code/memoire/memoire_m1.html#r√©cup√©ration-base-de-donn√©es-ajust√©es",
    "href": "posts/post-with-code/memoire/memoire_m1.html#r√©cup√©ration-base-de-donn√©es-ajust√©es",
    "title": "M√©moire",
    "section": "R√©cup√©ration base de donn√©es ajust√©es",
    "text": "R√©cup√©ration base de donn√©es ajust√©es\n\n#data_adj &lt;- read.csv(\"/Users/Isabel/Desktop/memoire3/data_adj.csv\")\n\ndata_adj$Date &lt;- as.Date(data_adj$Date)\n\n\n#  variables\nvariables &lt;- c(\"IPA\", \"CDD\", \"precipitation\", \"temperature\",  \"exportations\", \"importations\", \"taux_change\", \"SMIC\", \"petrole\")\n\n\nSkewness, kurtosis\n\nskew_kurt_df &lt;- data.frame(\n  Variable = variables,\n  # Calcul de skewness\n  Skewness = sapply(data_adj[variables], PerformanceAnalytics::skewness),\n  # Calcul de kurtosis\n  Kurtosis = sapply(data_adj[variables], PerformanceAnalytics::kurtosis)\n)\nskew_kurt_df\n\n                   Variable     Skewness    Kurtosis\nIPA                     IPA  1.587451131  2.02938496\nCDD                     CDD  0.515154009 -1.09215980\nprecipitation precipitation  0.003335255 -1.39981138\ntemperature     temperature  0.354093594  0.24637826\nexportations   exportations  0.991190627  0.83599348\nimportations   importations -0.035585053 -0.48953698\ntaux_change     taux_change  0.982023281 -0.04678673\nSMIC                   SMIC  0.038077541 -0.44421037\npetrole             petrole  0.340169157 -0.94096896\n\n\n\n\nTest de normalit√©\n\n#v√©rification de la normalit√© des variables \nlapply(data_adj[variables], shapiro.test)\n\n$IPA\n\n    Shapiro-Wilk normality test\n\ndata:  X[[i]]\nW = 0.81162, p-value &lt; 2.2e-16\n\n\n$CDD\n\n    Shapiro-Wilk normality test\n\ndata:  X[[i]]\nW = 0.90346, p-value = 2.662e-12\n\n\n$precipitation\n\n    Shapiro-Wilk normality test\n\ndata:  X[[i]]\nW = 0.92737, p-value = 2.312e-10\n\n\n$temperature\n\n    Shapiro-Wilk normality test\n\ndata:  X[[i]]\nW = 0.98853, p-value = 0.02765\n\n\n$exportations\n\n    Shapiro-Wilk normality test\n\ndata:  X[[i]]\nW = 0.93141, p-value = 5.389e-10\n\n\n$importations\n\n    Shapiro-Wilk normality test\n\ndata:  X[[i]]\nW = 0.99312, p-value = 0.2348\n\n\n$taux_change\n\n    Shapiro-Wilk normality test\n\ndata:  X[[i]]\nW = 0.87498, p-value = 3.167e-14\n\n\n$SMIC\n\n    Shapiro-Wilk normality test\n\ndata:  X[[i]]\nW = 0.97073, p-value = 2.005e-05\n\n\n$petrole\n\n    Shapiro-Wilk normality test\n\ndata:  X[[i]]\nW = 0.94924, p-value = 3.449e-08\n\n\n\n\nCorr√©lation\n\n#|warning: false\n#|message: false\n\n#  Matrice de corr√©lation\ncor_matrix &lt;- cor(data_adj[, variables], use = \"complete.obs\", method = \"spearman\")\ncor_matrix\n\n                      IPA         CDD precipitation temperature exportations\nIPA            1.00000000  0.07576372   -0.04386296  0.37647867   0.64924172\nCDD            0.07576372  1.00000000   -0.96428022  0.32220175   0.39372744\nprecipitation -0.04386296 -0.96428022    1.00000000 -0.33938317  -0.35647340\ntemperature    0.37647867  0.32220175   -0.33938317  1.00000000   0.28936878\nexportations   0.64924172  0.39372744   -0.35647340  0.28936878   1.00000000\nimportations   0.53493377 -0.11595776    0.14735573  0.09049610   0.42171195\ntaux_change    0.60748523  0.07445183   -0.06679673  0.36570691   0.32702233\nSMIC           0.01955579 -0.02748573    0.02980255  0.00564068   0.04615657\npetrole        0.42210699  0.08940170   -0.05840727 -0.02391271   0.44837226\n              importations taux_change         SMIC     petrole\nIPA            0.534933773  0.60748523  0.019555787  0.42210699\nCDD           -0.115957758  0.07445183 -0.027485733  0.08940170\nprecipitation  0.147355729 -0.06679673  0.029802545 -0.05840727\ntemperature    0.090496098  0.36570691  0.005640680 -0.02391271\nexportations   0.421711949  0.32702233  0.046156570  0.44837226\nimportations   1.000000000  0.06006558 -0.008959876  0.50385277\ntaux_change    0.060065584  1.00000000  0.098030177 -0.30572061\nSMIC          -0.008959876  0.09803018  1.000000000 -0.08122171\npetrole        0.503852770 -0.30572061 -0.081221712  1.00000000\n\n# Visualiser la matrice de corr√©lation\n\nggcorrplot(cor_matrix,\n  hc.order = TRUE, type = \"lower\",\n  lab = TRUE,\n  ggtheme = ggplot2::theme_gray,\n  colors = c(\"blue\", \"white\", \"red\"))\n\n\n\n\n\n\n\n# spearman correlation test\n#chart.Correlation(data_adj[variables], histogram=TRUE, pch=19,method = c(\"spearman\"))\n\nLe calcul de la corr√©lation de Spearman est recommand√© lorsque les variables ne suivent pas une loi normaleÔÉ®ce type de corr√©lation est dit robuste car il ne d√©pend pas de la distribution des donn√©es. (cours M.Travers)"
  },
  {
    "objectID": "posts/post-with-code/memoire/memoire_m1.html#composants",
    "href": "posts/post-with-code/memoire/memoire_m1.html#composants",
    "title": "M√©moire",
    "section": "Composants",
    "text": "Composants\nNous commen√ßons cette partie par deux tests : le premier est le test de tendance monotone de Mann-Kendall,et le deuxi√®me est le test de saisonalit√©"
  },
  {
    "objectID": "posts/post-with-code/memoire/memoire_m1.html#test-de-tendance-mann-kendall",
    "href": "posts/post-with-code/memoire/memoire_m1.html#test-de-tendance-mann-kendall",
    "title": "M√©moire",
    "section": "Test de tendance Mann-Kendall",
    "text": "Test de tendance Mann-Kendall\n\n# Test de tenance pour chaque variable \nlapply(data_adj[variables], function(x) {\n  mk.test(x, alternative = \"greater\")\n})\n\n$IPA\n\n    Mann-Kendall trend test\n\ndata:  x\nz = 22.407, n = 276, p-value &lt; 2.2e-16\nalternative hypothesis: true S is greater than 0\nsample estimates:\n           S         varS          tau \n3.434000e+04 2.348683e+06 9.048748e-01 \n\n\n$CDD\n\n    Mann-Kendall trend test\n\ndata:  x\nz = 1.4414, n = 276, p-value = 0.07474\nalternative hypothesis: true S is greater than 0\nsample estimates:\n           S         varS          tau \n2.210000e+03 2.348661e+06 5.825141e-02 \n\n\n$precipitation\n\n    Mann-Kendall trend test\n\ndata:  x\nz = -0.87893, n = 276, p-value = 0.8103\nalternative hypothesis: true S is greater than 0\nsample estimates:\n            S          varS           tau \n-1.348000e+03  2.348683e+06 -3.552042e-02 \n\n\n$temperature\n\n    Mann-Kendall trend test\n\ndata:  x\nz = 6.3914, n = 276, p-value = 8.22e-11\nalternative hypothesis: true S is greater than 0\nsample estimates:\n           S         varS          tau \n9.796000e+03 2.348657e+06 2.582176e-01 \n\n\n$exportations\n\n    Mann-Kendall trend test\n\ndata:  x\nz = 12.289, n = 276, p-value &lt; 2.2e-16\nalternative hypothesis: true S is greater than 0\nsample estimates:\n           S         varS          tau \n1.883500e+04 2.348658e+06 4.964745e-01 \n\n\n$importations\n\n    Mann-Kendall trend test\n\ndata:  x\nz = 9.3009, n = 276, p-value &lt; 2.2e-16\nalternative hypothesis: true S is greater than 0\nsample estimates:\n           S         varS          tau \n1.425500e+04 2.348659e+06 3.757397e-01 \n\n\n$taux_change\n\n    Mann-Kendall trend test\n\ndata:  x\nz = 10.163, n = 276, p-value &lt; 2.2e-16\nalternative hypothesis: true S is greater than 0\nsample estimates:\n           S         varS          tau \n1.557600e+04 2.348681e+06 4.104456e-01 \n\n\n$SMIC\n\n    Mann-Kendall trend test\n\ndata:  x\nz = 0.57934, n = 276, p-value = 0.2812\nalternative hypothesis: true S is greater than 0\nsample estimates:\n           S         varS          tau \n8.880000e+02 2.344153e+06 2.385489e-02 \n\n\n$petrole\n\n    Mann-Kendall trend test\n\ndata:  x\nz = 8.2693, n = 276, p-value &lt; 2.2e-16\nalternative hypothesis: true S is greater than 0\nsample estimates:\n           S         varS          tau \n1.267400e+04 2.348683e+06 3.339657e-01"
  },
  {
    "objectID": "posts/post-with-code/memoire/memoire_m1.html#test-saisonni√®re",
    "href": "posts/post-with-code/memoire/memoire_m1.html#test-saisonni√®re",
    "title": "M√©moire",
    "section": "Test Saisonni√®re",
    "text": "Test Saisonni√®re\n\n# On transforme en format tsv\nts_data &lt;- ts(data_adj[, 2:10], frequency = 12,  start = c(2000, 1))\n\n## Verfication de la saisonnalit√© \ntest_saison &lt;- vector(\"logical\", ncol(ts_data))  # vecteur pour stocker les r√©sultats\nnames(test_saison) &lt;- colnames(ts_data)  # nomme les r√©sultats selon les variables\n\nfor (i in 1:ncol(ts_data)) {\n  test_saison[i] &lt;- isSeasonal(ts_data[, i], test = \"wo\")\n}\ntest_saison\n\n          IPA           CDD  importations  exportations       petrole \n        FALSE          TRUE          TRUE          TRUE         FALSE \n  taux_change          SMIC precipitation   temperature \n        FALSE         FALSE          TRUE          TRUE \n\n# Deuxi√®me test Seasonal dummies\nfor (i in 1:ncol(ts_data)) {\n  nom_var &lt;- colnames(ts_data)[i]\n  result &lt;- seasdum(ts_data[, i])\n  cat(\"\\nTest Seasonal dummies: \", nom_var, \":\\n\")\n  print(result)\n}\n\n\nTest Seasonal dummies:  IPA :\nTest used:  SeasonalDummies \n \nTest statistic:  1.27 \nP-value:  0.2414814\n\nTest Seasonal dummies:  CDD :\nTest used:  SeasonalDummies \n \nTest statistic:  283.33 \nP-value:  0\n\nTest Seasonal dummies:  importations :\nTest used:  SeasonalDummies \n \nTest statistic:  6.31 \nP-value:  2.993919e-09\n\nTest Seasonal dummies:  exportations :\nTest used:  SeasonalDummies \n \nTest statistic:  23.43 \nP-value:  0\n\nTest Seasonal dummies:  petrole :\nTest used:  SeasonalDummies \n \nTest statistic:  1.06 \nP-value:  0.390488\n\nTest Seasonal dummies:  taux_change :\nTest used:  SeasonalDummies \n \nTest statistic:  1.31 \nP-value:  0.218587\n\nTest Seasonal dummies:  SMIC :\nTest used:  SeasonalDummies \n \nTest statistic:  0.06 \nP-value:  0.999995\n\nTest Seasonal dummies:  precipitation :\nTest used:  SeasonalDummies \n \nTest statistic:  351.69 \nP-value:  0\n\nTest Seasonal dummies:  temperature :\nTest used:  SeasonalDummies \n \nTest statistic:  4.35 \nP-value:  5.416069e-06\n\n\nLes variables pressentant une saisonnalit√© d‚Äôapr√®s les tests sont CDD, importations, Exportations, Pr√©cipitation et temp√©rature\nLe code ci-dessous et similaire √† celui que nous avons fait precedement pour transformer les variables en time series, on a besoin si nous t√©l√©chargeons le fichier data.adj\n\n# Boucle pour convertir chaque colonne en ts et les stocker comme variables s√©par√©es\nfor(column_name in names(data_adj)[-1]) {  # Exclure la colonne de date\n    # Cr√©er une s√©rie temporelle pour la colonne actuelle\n    ts_list &lt;- ts(data_adj[[column_name]], start = c(2000, 1), frequency = 12)\n  # variable dans l'environnement global avec un nom dynamique\n    assign(paste0(\"ts_\", column_name), ts_list)\n}\n\n\nCorrelogramme des variables saisonni√®res\n\npar(mfrow=c(2,2))\n\n# ACF pour les variables presentant une saisonalit√© \n# CDD\nacf(ts_CDD, main = \"ACF CDD sur la s√©rie en niveau\")\nacf(diff(ts_CDD,differences = 1), main = \"ACF CDD sur la s√©rie en diff√©rence premi√©re\")\n# Pr√©cipitation\nacf(ts_precipitation, main = \"ACF Precipitations sur la s√©rie en niveau\")\nacf(diff(ts_precipitation,differences = 1), main = \"ACF Precipitations sur la s√©rie en diff√©rence premi√©re\")\n\n\n\n\n\n\n\n# T√©mperature\nacf(ts_temperature, main = \"ACF T√©mperature sur la s√©rie en niveau \")\nacf(diff(ts_temperature,differences = 1), main = \"ACF T√©mperature sur la s√©rie en diff√©rence premi√©re\")\n# Importations\nacf(ts_importations, main = \"ACF Importations sur la s√©rie en niveau\")\nacf(diff(ts_importations, differences = 1),main = \"ACF Importations sur la s√©rie en diff√©rence premi√©re\")\n\n\n\n\n\n\n\n# Exportations\nacf(ts_exportations, main = \"ACF Exportations sur la s√©rie en niveau\")\nacf(diff(ts_exportations,differences = 1), main = \"ACF Exportations sur la s√©rie en diff√©rence premi√©re\")\n\n\n\n\n\n\n\n\n\n\nP√©riodogramme\n\n# P√©riodogramme ou filtre spectra pour les s√©rires presentant une saisonalit√©\n# CDD\nperiodogram(ts_CDD, main = \"P√©riodogramme CDD sur la s√©rie en niveau\")\n\n\n\n\n\n\n\nperiodogram(diff(ts_CDD,differences = 1), main = \"P√©riodogramme CDD sur la s√©rie en diff√©rence premi√©re\")\n\n\n\n\n\n\n\n# Precipitations\nperiodogram(ts_precipitation, main = \"P√©riodogramme Precipitations sur la s√©rie en niveau\")\n\n\n\n\n\n\n\nperiodogram(diff(ts_precipitation,differences = 1), main = \"P√©riodogramme Precipitations sur la s√©rie en diff√©rence premi√©re\")\n\n\n\n\n\n\n\n# Temperature\nperiodogram(ts_temperature, main = \"P√©riodogramme T√©mperature sur la s√©rie en niveau \")\n\n\n\n\n\n\n\nperiodogram(diff(ts_temperature,differences = 1), main = \"P√©riodogramme T√©mperature sur la s√©rie en diff√©rence premi√©re\")\n\n\n\n\n\n\n\n# Importations\nperiodogram(ts_importations, main = \"P√©riodogramme Importations sur la s√©rie en niveau\")\n\n\n\n\n\n\n\nperiodogram(diff(ts_importations, differences = 1),main = \"P√©riodogramme Importations sur la s√©rie en diff√©rence premi√©re\")\n\n\n\n\n\n\n\n# Exportations \nperiodogram(ts_exportations, main = \"P√©riodogramme Exportations sur la s√©rie en niveau\")\n\n\n\n\n\n\n\nperiodogram(diff(ts_exportations,differences = 1), main = \"P√©riodogramme Exportations sur la s√©rie en diff√©rence premi√©re\")\n\n\n\n\n\n\n\n\n\npar(mfrow=c(1,2))\n\n# Boxplots pour les variables climatiques avec les cycles correspondants √† chaque s√©rie\nboxplot(ts_CDD ~ cycle(ts_CDD), main = \"Bo√Æte √† moustaches des CDD par cycle\", xlab = \"Cycle\", ylab = \"CDD en jours\")\nboxplot(ts_precipitation ~ cycle(ts_precipitation), main = \"Bo√Æte √† moustaches des pr√©cipitations par cycle\", xlab = \"Cycle\", ylab = \"Pr√©cipitations en mm\")\n\n\n\n\n\n\n\nboxplot(ts_temperature ~ cycle(ts_temperature), main = \"Bo√Æte √† moustaches de la temp√©rature par cycle\", xlab = \"Cycle\", ylab = \"Variations de temp√©rature\")\n\n# Variables export - importation\nboxplot(ts_importations ~ cycle(ts_importations), main = \"Bo√Æte √† moustaches des importations par cycle\", xlab = \"Cycle\", ylab = \"Valeurs des importations\")\n\n\n\n\n\n\n\nboxplot(ts_exportations ~ cycle(ts_exportations), main = \"Bo√Æte √† moustaches des exportations par cycle\", xlab = \"Cycle\", ylab = \"Valeurs des exportations\")"
  },
  {
    "objectID": "posts/post-with-code/memoire/memoire_m1.html#test-adf",
    "href": "posts/post-with-code/memoire/memoire_m1.html#test-adf",
    "title": "M√©moire",
    "section": "Test ADF",
    "text": "Test ADF\n\n#|warning: false\n#|message: false\n\n# test ADF \nlapply(data_adj[variables], function(x) {\n  adf.test(x, alternative = \"stationary\")\n})\n\nWarning in adf.test(x, alternative = \"stationary\"): p-value smaller than\nprinted p-value\nWarning in adf.test(x, alternative = \"stationary\"): p-value smaller than\nprinted p-value\nWarning in adf.test(x, alternative = \"stationary\"): p-value smaller than\nprinted p-value\nWarning in adf.test(x, alternative = \"stationary\"): p-value smaller than\nprinted p-value\nWarning in adf.test(x, alternative = \"stationary\"): p-value smaller than\nprinted p-value\n\n\n$IPA\n\n    Augmented Dickey-Fuller Test\n\ndata:  x\nDickey-Fuller = -2.0623, Lag order = 6, p-value = 0.5498\nalternative hypothesis: stationary\n\n\n$CDD\n\n    Augmented Dickey-Fuller Test\n\ndata:  x\nDickey-Fuller = -15.661, Lag order = 6, p-value = 0.01\nalternative hypothesis: stationary\n\n\n$precipitation\n\n    Augmented Dickey-Fuller Test\n\ndata:  x\nDickey-Fuller = -12.168, Lag order = 6, p-value = 0.01\nalternative hypothesis: stationary\n\n\n$temperature\n\n    Augmented Dickey-Fuller Test\n\ndata:  x\nDickey-Fuller = -4.9028, Lag order = 6, p-value = 0.01\nalternative hypothesis: stationary\n\n\n$exportations\n\n    Augmented Dickey-Fuller Test\n\ndata:  x\nDickey-Fuller = -8.6625, Lag order = 6, p-value = 0.01\nalternative hypothesis: stationary\n\n\n$importations\n\n    Augmented Dickey-Fuller Test\n\ndata:  x\nDickey-Fuller = -3.7022, Lag order = 6, p-value = 0.02434\nalternative hypothesis: stationary\n\n\n$taux_change\n\n    Augmented Dickey-Fuller Test\n\ndata:  x\nDickey-Fuller = -1.4862, Lag order = 6, p-value = 0.7925\nalternative hypothesis: stationary\n\n\n$SMIC\n\n    Augmented Dickey-Fuller Test\n\ndata:  x\nDickey-Fuller = -6.0839, Lag order = 6, p-value = 0.01\nalternative hypothesis: stationary\n\n\n$petrole\n\n    Augmented Dickey-Fuller Test\n\ndata:  x\nDickey-Fuller = -2.178, Lag order = 6, p-value = 0.5011\nalternative hypothesis: stationary\n\n\n\nGraphiques des variables non stationnaires Test ADF\n\n# Graphique pour la s√©rie IPA\nggplot(data = data_adj, aes(x = Date, y = IPA)) +\n  geom_line(color = \"blue\", size = 0.5) +\n  stat_smooth(color = \"red\", fill = \"red\", method = \"loess\", show.legend = TRUE,  size = 0.2) +\n  ggtitle(\"Analyse de la tendance de l'IPA-DI sur la p√©riode 01/2000 - 12/2022\") +\n  xlab(\"Date\") +\n  ylab(\"IPA Value\") \n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\n‚Ñπ Please use `linewidth` instead.\n\n\nDon't know how to automatically pick scale for object of type &lt;ts&gt;. Defaulting\nto continuous.\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n# Graphique pour la s√©rie petrole\n\nggplot(data = data_adj, aes(x = Date, y = petrole)) +\n  geom_line(color = \"blue\", size = 0.5) +\n  stat_smooth(color = \"red\", fill = \"red\", method = \"loess\", show.legend = TRUE, size = 0.2) +\n  ggtitle(\"Analyse de la tendance du prix du p√©trole sur la p√©riode 01/2000 - 12/2022\") +\n  xlab(\"Date\") +\n  ylab(\"Petrole Value\") \n\nDon't know how to automatically pick scale for object of type &lt;ts&gt;. Defaulting\nto continuous.\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n# Graphique pour la s√©rie taux de change \n\nggplot(data = data_adj, aes(x = Date, y = taux_change)) +\n  geom_line(color = \"blue\", size = 0.5) +\n  stat_smooth(color = \"red\", fill = \"red\", method = \"loess\", show.legend = TRUE, size = 0.2) +\n  ggtitle(\"Analyse de la tendance du taux de change sur la p√©riode 01/2000 - 12/2022\") +\n  xlab(\"Date\") +\n  ylab(\"Taux de change\") \n\nDon't know how to automatically pick scale for object of type &lt;ts&gt;. Defaulting\nto continuous.\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nLa fonction stat_smooth(method = ‚Äúloess‚Äù) ajoute une courbe de lissage aux donn√©es, utilisant la m√©thode LOESS (Locally Estimated Scatterplot Smoothing). Cette courbe est utile pour visualiser une tendance centrale plus lisse dans les donn√©es, ce qui peut √™tre particuli√®rement b√©n√©fique dans les cas o√π les donn√©es sont bruyantes ou volatiles"
  },
  {
    "objectID": "posts/post-with-code/memoire/memoire_m1.html#test-kpss",
    "href": "posts/post-with-code/memoire/memoire_m1.html#test-kpss",
    "title": "M√©moire",
    "section": "Test KPSS",
    "text": "Test KPSS\n\n#|warning: false\n#|message: false\n\n## Trend \nfor (i in 1:ncol(ts_data)) {\n  nom_var &lt;- colnames(ts_data)[i]\n  result &lt;- kpss.test(ts_data[, i], null = \"Trend\")\n  cat(\"\\nTest KPSS: \", nom_var, \":\\n\")\n  print(result)\n}\n\nWarning in kpss.test(ts_data[, i], null = \"Trend\"): p-value smaller than\nprinted p-value\n\n\n\nTest KPSS:  IPA :\n\n    KPSS Test for Trend Stationarity\n\ndata:  ts_data[, i]\nKPSS Trend = 0.59792, Truncation lag parameter = 5, p-value = 0.01\n\n\nWarning in kpss.test(ts_data[, i], null = \"Trend\"): p-value greater than\nprinted p-value\n\n\n\nTest KPSS:  CDD :\n\n    KPSS Test for Trend Stationarity\n\ndata:  ts_data[, i]\nKPSS Trend = 0.0099421, Truncation lag parameter = 5, p-value = 0.1\n\n\nWarning in kpss.test(ts_data[, i], null = \"Trend\"): p-value smaller than\nprinted p-value\n\n\n\nTest KPSS:  importations :\n\n    KPSS Test for Trend Stationarity\n\ndata:  ts_data[, i]\nKPSS Trend = 0.37607, Truncation lag parameter = 5, p-value = 0.01\n\n\nWarning in kpss.test(ts_data[, i], null = \"Trend\"): p-value greater than\nprinted p-value\n\n\n\nTest KPSS:  exportations :\n\n    KPSS Test for Trend Stationarity\n\ndata:  ts_data[, i]\nKPSS Trend = 0.034185, Truncation lag parameter = 5, p-value = 0.1\n\n\nWarning in kpss.test(ts_data[, i], null = \"Trend\"): p-value smaller than\nprinted p-value\n\n\n\nTest KPSS:  petrole :\n\n    KPSS Test for Trend Stationarity\n\ndata:  ts_data[, i]\nKPSS Trend = 0.63433, Truncation lag parameter = 5, p-value = 0.01\n\n\nWarning in kpss.test(ts_data[, i], null = \"Trend\"): p-value smaller than\nprinted p-value\n\n\n\nTest KPSS:  taux_change :\n\n    KPSS Test for Trend Stationarity\n\ndata:  ts_data[, i]\nKPSS Trend = 0.94899, Truncation lag parameter = 5, p-value = 0.01\n\n\nWarning in kpss.test(ts_data[, i], null = \"Trend\"): p-value greater than\nprinted p-value\n\n\n\nTest KPSS:  SMIC :\n\n    KPSS Test for Trend Stationarity\n\ndata:  ts_data[, i]\nKPSS Trend = 0.018996, Truncation lag parameter = 5, p-value = 0.1\n\n\nWarning in kpss.test(ts_data[, i], null = \"Trend\"): p-value greater than\nprinted p-value\n\n\n\nTest KPSS:  precipitation :\n\n    KPSS Test for Trend Stationarity\n\ndata:  ts_data[, i]\nKPSS Trend = 0.010157, Truncation lag parameter = 5, p-value = 0.1\n\n\nTest KPSS:  temperature :\n\n    KPSS Test for Trend Stationarity\n\ndata:  ts_data[, i]\nKPSS Trend = 0.13529, Truncation lag parameter = 5, p-value = 0.06984\n\n## Level \nfor (i in 1:ncol(ts_data)) {\n  nom_var &lt;- colnames(ts_data)[i]\n  result &lt;- kpss.test(ts_data[, i], null = \"Level\")\n  cat(\"\\nTest KPSS: \", nom_var, \":\\n\")\n  print(result)\n}\n\nWarning in kpss.test(ts_data[, i], null = \"Level\"): p-value smaller than\nprinted p-value\n\n\n\nTest KPSS:  IPA :\n\n    KPSS Test for Level Stationarity\n\ndata:  ts_data[, i]\nKPSS Level = 3.5331, Truncation lag parameter = 5, p-value = 0.01\n\n\nWarning in kpss.test(ts_data[, i], null = \"Level\"): p-value greater than\nprinted p-value\n\n\n\nTest KPSS:  CDD :\n\n    KPSS Test for Level Stationarity\n\ndata:  ts_data[, i]\nKPSS Level = 0.089483, Truncation lag parameter = 5, p-value = 0.1\n\n\nWarning in kpss.test(ts_data[, i], null = \"Level\"): p-value smaller than\nprinted p-value\n\n\n\nTest KPSS:  importations :\n\n    KPSS Test for Level Stationarity\n\ndata:  ts_data[, i]\nKPSS Level = 2.666, Truncation lag parameter = 5, p-value = 0.01\n\n\nWarning in kpss.test(ts_data[, i], null = \"Level\"): p-value smaller than\nprinted p-value\n\n\n\nTest KPSS:  exportations :\n\n    KPSS Test for Level Stationarity\n\ndata:  ts_data[, i]\nKPSS Level = 3.1023, Truncation lag parameter = 5, p-value = 0.01\n\n\nWarning in kpss.test(ts_data[, i], null = \"Level\"): p-value smaller than\nprinted p-value\n\n\n\nTest KPSS:  petrole :\n\n    KPSS Test for Level Stationarity\n\ndata:  ts_data[, i]\nKPSS Level = 1.2759, Truncation lag parameter = 5, p-value = 0.01\n\n\nWarning in kpss.test(ts_data[, i], null = \"Level\"): p-value smaller than\nprinted p-value\n\n\n\nTest KPSS:  taux_change :\n\n    KPSS Test for Level Stationarity\n\ndata:  ts_data[, i]\nKPSS Level = 2.6251, Truncation lag parameter = 5, p-value = 0.01\n\n\nWarning in kpss.test(ts_data[, i], null = \"Level\"): p-value greater than\nprinted p-value\n\n\n\nTest KPSS:  SMIC :\n\n    KPSS Test for Level Stationarity\n\ndata:  ts_data[, i]\nKPSS Level = 0.020247, Truncation lag parameter = 5, p-value = 0.1\n\n\nWarning in kpss.test(ts_data[, i], null = \"Level\"): p-value greater than\nprinted p-value\n\n\n\nTest KPSS:  precipitation :\n\n    KPSS Test for Level Stationarity\n\ndata:  ts_data[, i]\nKPSS Level = 0.030274, Truncation lag parameter = 5, p-value = 0.1\n\n\nWarning in kpss.test(ts_data[, i], null = \"Level\"): p-value smaller than\nprinted p-value\n\n\n\nTest KPSS:  temperature :\n\n    KPSS Test for Level Stationarity\n\ndata:  ts_data[, i]\nKPSS Level = 1.7517, Truncation lag parameter = 5, p-value = 0.01"
  },
  {
    "objectID": "posts/post-with-code/memoire/memoire_m1.html#correction",
    "href": "posts/post-with-code/memoire/memoire_m1.html#correction",
    "title": "M√©moire",
    "section": "Correction",
    "text": "Correction\nNous allons maintenant d√©terminer le type de sch√©ma des s√©ries, multiplicatif ou addif\n\n# Approche Graphique \nplot(ts_CDD)\n\n\n\n\n\n\n\nplot(ts_precipitation)\n\n\n\n\n\n\n\nplot(ts_temperature)\n\n\n\n\n\n\n\nplot(ts_importations)\n\n\n\n\n\n\n\nplot(ts_exportations)\n\n\n\n\n\n\n\n#  Test log-level\nregx13_CDD &lt;- regarima_x13(ts_CDD, spec =\"RG5c\") \ns_transform(regx13_CDD)\n\n tfunction adjust aicdiff\n      Auto   None      -2\n\nregx13_precipitation &lt;- regarima_x13(ts_precipitation, spec =\"RG5c\") \ns_transform(regx13_precipitation)\n\n tfunction adjust aicdiff\n      Auto   None      -2\n\nregx13_temperature &lt;- regarima_x13(ts_temperature, spec =\"RG5c\") \ns_transform(regx13_temperature)\n\n tfunction adjust aicdiff\n      Auto   None      -2\n\nregx13_importations &lt;- regarima_x13(ts_importations, spec =\"RG5c\") \ns_transform(regx13_importations)\n\n tfunction adjust aicdiff\n      Auto   None      -2\n\nregx13_exportations &lt;- regarima_x13(ts_exportations, spec =\"RG5c\") \ns_transform(regx13_exportations)\n\n tfunction adjust aicdiff\n      Auto   None      -2\n\n\nCe test est sp√©cifiquement con√ßu pour d√©cider si une transformation logarithmique des donn√©es est appropri√©e\n\nD√©composition\nUtilisation de decompose pour une d√©composition additive\n\n# D√©composition \ndecom_CDD &lt;- decompose(ts_CDD, type=\"additive\")\ndecom_precipitations&lt;- decompose(ts_precipitation, type=\"additive\")\ndecom_temperature &lt;- decompose(ts_temperature, type=\"additive\")\ndecom_importations &lt;- decompose(ts_importations, type=\"additive\")\ndecom_importations &lt;- decompose(ts_importations, type=\"additive\")\ndecom_exportations &lt;- decompose(ts_exportations, type = \"additive\")\n\n# Plot \n\n\nplot(decom_CDD)\n\n\n\n\n\n\n\nplot(decom_temperature)\n\n\n\n\n\n\n\nplot(decom_precipitations)\n\n\n\n\n\n\n\nplot(decom_importations)\n\n\n\n\n\n\n\nplot(decom_exportations)\n\n\n\n\n\n\n\n\nChacune de nos variables saisonni√®res est d√©compos√© en ‚Äòtrend‚Äô, ‚Äòseasonl‚Äô, ‚Äòrandom‚Äô\n\n\nD√©saisonalitation\nCDD\n\nCDD_deseason &lt;- ts_CDD - decom_CDD$seasonal\ncdd &lt;- ts.intersect(ts_CDD, CDD_deseason)\n# Graphique \nplot.ts(cdd, \n        plot.type = \"single\",\n        col = c(\"red\", \"blue\"),\n        main = \"CDD s√©rie originale (rouge) et d√©saisonnalis√©e (bleu)\",\n        xlab = \"P√©riode\",\n        ylab= \"Nombre de jours\")\n\n\n\n\n\n\n\n\nTemp√©rature\n\ntemperature_deseason &lt;- ts_temperature - decom_temperature$seasonal\ntemperature &lt;- ts.intersect(ts_temperature, temperature_deseason)\n# Graphique \nplot.ts(temperature, \n        plot.type = \"single\",\n        col = c(\"red\", \"blue\"),\n        main = \"T√©mperature s√©rie originale (rouge) et d√©saisonnalis√©e (bleu)\",\n        xlab = \"P√©riode\",\n        ylab= \"Variation de la t√©mperature\")\n\n\n\n\n\n\n\n\nPr√©cipitations\n\nprecipitations_deseason &lt;- ts_precipitation - decom_precipitations$seasonal\n\nprecipitations &lt;- ts.intersect(ts_precipitation, precipitations_deseason)\n# Graphique \nplot.ts(precipitations, \n        plot.type = \"single\",\n        col = c(\"red\", \"blue\"),\n        main = \"Pr√©cipitations s√©rie originale (rouge) et d√©saisonnalis√©e (bleu)\",\n        xlab = \"P√©riode\",\n        ylab= \"Pr√©cipations en mm\")\n\n\n\n\n\n\n\n\nExportation\n\nexportations_deseason &lt;- ts_exportations - decom_exportations$seasonal\n\nexportations &lt;- ts.intersect(ts_exportations, exportations_deseason)\n# Graphique \nplot.ts(exportations, \n        plot.type = \"single\",\n        col = c(\"red\", \"blue\"),\n        main = \"Exportations s√©rie originale (rouge) et d√©saisonnalis√©e (bleu)\",\n        xlab = \"P√©riode\",\n        ylab= \"Indice exportation\")\n\n\n\n\n\n\n\n\nImportation\n\nimportations_deseason &lt;- ts_importations - decom_importations$seasonal\n\nimportations &lt;- ts.intersect(ts_importations, importations_deseason)\n# Graphique \nplot.ts(importations, \n        plot.type = \"single\",\n        col = c(\"red\", \"blue\"),\n        main = \"Importations s√©rie originale (rouge) et d√©saisonnalis√©e (bleu)\",\n        xlab = \"P√©riode\",\n        ylab= \"Indice importations\")\n\n\n\n\n\n\n\n\n\n# CDD \nadf.test(CDD_deseason, alternative = \"stationary\")\n\nWarning in adf.test(CDD_deseason, alternative = \"stationary\"): p-value smaller\nthan printed p-value\n\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  CDD_deseason\nDickey-Fuller = -6.1831, Lag order = 6, p-value = 0.01\nalternative hypothesis: stationary\n\nkpss.test(CDD_deseason,  null = \"Trend\")\n\nWarning in kpss.test(CDD_deseason, null = \"Trend\"): p-value greater than\nprinted p-value\n\n\n\n    KPSS Test for Trend Stationarity\n\ndata:  CDD_deseason\nKPSS Trend = 0.053447, Truncation lag parameter = 5, p-value = 0.1\n\nkpss.test(CDD_deseason,  null = \"Level\")\n\nWarning in kpss.test(CDD_deseason, null = \"Level\"): p-value smaller than\nprinted p-value\n\n\n\n    KPSS Test for Level Stationarity\n\ndata:  CDD_deseason\nKPSS Level = 0.85893, Truncation lag parameter = 5, p-value = 0.01\n\n\n\n# temperature \nadf.test(temperature_deseason, alternative = \"stationary\")\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  temperature_deseason\nDickey-Fuller = -3.9825, Lag order = 6, p-value = 0.01032\nalternative hypothesis: stationary\n\nkpss.test(temperature_deseason,  null = \"Trend\")\n\n\n    KPSS Test for Trend Stationarity\n\ndata:  temperature_deseason\nKPSS Trend = 0.14896, Truncation lag parameter = 5, p-value = 0.04753\n\nkpss.test(temperature_deseason,  null = \"Level\")\n\nWarning in kpss.test(temperature_deseason, null = \"Level\"): p-value smaller\nthan printed p-value\n\n\n\n    KPSS Test for Level Stationarity\n\ndata:  temperature_deseason\nKPSS Level = 1.7965, Truncation lag parameter = 5, p-value = 0.01\n\n\n\n# precipitation\nadf.test(precipitations_deseason, alternative = \"stationary\")\n\nWarning in adf.test(precipitations_deseason, alternative = \"stationary\"):\np-value smaller than printed p-value\n\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  precipitations_deseason\nDickey-Fuller = -5.8362, Lag order = 6, p-value = 0.01\nalternative hypothesis: stationary\n\nkpss.test(precipitations_deseason,  null = \"Trend\")\n\nWarning in kpss.test(precipitations_deseason, null = \"Trend\"): p-value greater\nthan printed p-value\n\n\n\n    KPSS Test for Trend Stationarity\n\ndata:  precipitations_deseason\nKPSS Trend = 0.078174, Truncation lag parameter = 5, p-value = 0.1\n\nkpss.test(precipitations_deseason,  null = \"Level\")\n\nWarning in kpss.test(precipitations_deseason, null = \"Level\"): p-value greater\nthan printed p-value\n\n\n\n    KPSS Test for Level Stationarity\n\ndata:  precipitations_deseason\nKPSS Level = 0.22839, Truncation lag parameter = 5, p-value = 0.1\n\n\n\n# Importations\nadf.test(importations_deseason, alternative = \"stationary\")\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  importations_deseason\nDickey-Fuller = -3.3037, Lag order = 6, p-value = 0.07096\nalternative hypothesis: stationary\n\nkpss.test(importations_deseason,  null = \"Trend\")\n\nWarning in kpss.test(importations_deseason, null = \"Trend\"): p-value smaller\nthan printed p-value\n\n\n\n    KPSS Test for Trend Stationarity\n\ndata:  importations_deseason\nKPSS Trend = 0.39913, Truncation lag parameter = 5, p-value = 0.01\n\nkpss.test(importations_deseason,  null = \"Level\")\n\nWarning in kpss.test(importations_deseason, null = \"Level\"): p-value smaller\nthan printed p-value\n\n\n\n    KPSS Test for Level Stationarity\n\ndata:  importations_deseason\nKPSS Level = 2.7696, Truncation lag parameter = 5, p-value = 0.01\n\n# Differenciaiton\nimportation_diff &lt;- diff(importations_deseason, differences = 1)\nadf.test(importation_diff, alternative = \"stationary\")\n\nWarning in adf.test(importation_diff, alternative = \"stationary\"): p-value\nsmaller than printed p-value\n\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  importation_diff\nDickey-Fuller = -10.305, Lag order = 6, p-value = 0.01\nalternative hypothesis: stationary\n\nkpss.test(importation_diff,  null = \"Trend\")\n\nWarning in kpss.test(importation_diff, null = \"Trend\"): p-value greater than\nprinted p-value\n\n\n\n    KPSS Test for Trend Stationarity\n\ndata:  importation_diff\nKPSS Trend = 0.014578, Truncation lag parameter = 5, p-value = 0.1\n\nkpss.test(importation_diff,  null = \"Level\")\n\nWarning in kpss.test(importation_diff, null = \"Level\"): p-value greater than\nprinted p-value\n\n\n\n    KPSS Test for Level Stationarity\n\ndata:  importation_diff\nKPSS Level = 0.031579, Truncation lag parameter = 5, p-value = 0.1\n\n\n\n# Exportations \nadf.test(exportations_deseason, alternative = \"stationary\")\n\nWarning in adf.test(exportations_deseason, alternative = \"stationary\"): p-value\nsmaller than printed p-value\n\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  exportations_deseason\nDickey-Fuller = -6.2104, Lag order = 6, p-value = 0.01\nalternative hypothesis: stationary\n\nkpss.test(exportations_deseason,  null = \"Trend\")\n\nWarning in kpss.test(exportations_deseason, null = \"Trend\"): p-value greater\nthan printed p-value\n\n\n\n    KPSS Test for Trend Stationarity\n\ndata:  exportations_deseason\nKPSS Trend = 0.067186, Truncation lag parameter = 5, p-value = 0.1\n\nkpss.test(exportations_deseason,  null = \"Level\")\n\nWarning in kpss.test(exportations_deseason, null = \"Level\"): p-value smaller\nthan printed p-value\n\n\n\n    KPSS Test for Level Stationarity\n\ndata:  exportations_deseason\nKPSS Level = 3.7622, Truncation lag parameter = 5, p-value = 0.01\n\n\n\n\nDiff√©renciation des s√©ries non stationnaires par la tendance stochastique\n\n\nTests apr√®s corrections\n\n#|warning: false\n#|message: false\n\n# Differenciation \nipa_diff &lt;- diff(ts_data[, \"IPA\"])\ntaux_change_diff &lt;- diff(ts_data[, \"taux_change\"])\npetrole_diff &lt;- diff(ts_data[, \"petrole\"])\n\n# TESTS FINAL ADF ET KPSS \n\n#IPA\nadf.test(ipa_diff, alternative = \"stationary\")\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  ipa_diff\nDickey-Fuller = -3.9389, Lag order = 6, p-value = 0.01251\nalternative hypothesis: stationary\n\nkpss.test(ipa_diff,  null = \"Trend\")\n\n\n    KPSS Test for Trend Stationarity\n\ndata:  ipa_diff\nKPSS Trend = 0.12657, Truncation lag parameter = 5, p-value = 0.08599\n\nkpss.test(ipa_diff,  null = \"Level\")\n\n\n    KPSS Test for Level Stationarity\n\ndata:  ipa_diff\nKPSS Level = 0.58846, Truncation lag parameter = 5, p-value = 0.02369\n\n# Taux de change\nadf.test(taux_change_diff, alternative = \"stationary\")\n\nWarning in adf.test(taux_change_diff, alternative = \"stationary\"): p-value\nsmaller than printed p-value\n\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  taux_change_diff\nDickey-Fuller = -6.4556, Lag order = 6, p-value = 0.01\nalternative hypothesis: stationary\n\nkpss.test(taux_change_diff,  null = \"Trend\")\n\nWarning in kpss.test(taux_change_diff, null = \"Trend\"): p-value greater than\nprinted p-value\n\n\n\n    KPSS Test for Trend Stationarity\n\ndata:  taux_change_diff\nKPSS Trend = 0.070678, Truncation lag parameter = 5, p-value = 0.1\n\nkpss.test(taux_change_diff,  null = \"Level\")\n\nWarning in kpss.test(taux_change_diff, null = \"Level\"): p-value greater than\nprinted p-value\n\n\n\n    KPSS Test for Level Stationarity\n\ndata:  taux_change_diff\nKPSS Level = 0.17753, Truncation lag parameter = 5, p-value = 0.1\n\n# P√©trole\nadf.test(petrole_diff, alternative = \"stationary\")\n\nWarning in adf.test(petrole_diff, alternative = \"stationary\"): p-value smaller\nthan printed p-value\n\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  petrole_diff\nDickey-Fuller = -6.3498, Lag order = 6, p-value = 0.01\nalternative hypothesis: stationary\n\nkpss.test(petrole_diff,  null = \"Trend\")\n\nWarning in kpss.test(petrole_diff, null = \"Trend\"): p-value greater than\nprinted p-value\n\n\n\n    KPSS Test for Trend Stationarity\n\ndata:  petrole_diff\nKPSS Trend = 0.038075, Truncation lag parameter = 5, p-value = 0.1\n\nkpss.test(petrole_diff,  null = \"Level\")\n\nWarning in kpss.test(petrole_diff, null = \"Level\"): p-value greater than\nprinted p-value\n\n\n\n    KPSS Test for Level Stationarity\n\ndata:  petrole_diff\nKPSS Level = 0.055257, Truncation lag parameter = 5, p-value = 0.1\n\n# smic\nadf.test(ts_SMIC, alternative = \"stationary\")\n\nWarning in adf.test(ts_SMIC, alternative = \"stationary\"): p-value smaller than\nprinted p-value\n\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  ts_SMIC\nDickey-Fuller = -6.0839, Lag order = 6, p-value = 0.01\nalternative hypothesis: stationary\n\nkpss.test(ts_SMIC,  null = \"Trend\")\n\nWarning in kpss.test(ts_SMIC, null = \"Trend\"): p-value greater than printed\np-value\n\n\n\n    KPSS Test for Trend Stationarity\n\ndata:  ts_SMIC\nKPSS Trend = 0.018996, Truncation lag parameter = 5, p-value = 0.1\n\nkpss.test(ts_SMIC,  null = \"Level\")\n\nWarning in kpss.test(ts_SMIC, null = \"Level\"): p-value greater than printed\np-value\n\n\n\n    KPSS Test for Level Stationarity\n\ndata:  ts_SMIC\nKPSS Level = 0.020247, Truncation lag parameter = 5, p-value = 0.1\n\n\n\n\nData frame avec les variables stationnaires\nMaintenant que nos s√©ries ont √©t√© rendues stationnaires, nous allons cr√©er un nouveau dataframe avec ces variables. Cependant, du fait que la diff√©renciation entra√Æne la perte de la premi√®re observation, nous devrons √©galement supprimer la premi√®re observation des s√©ries qui √©taient d√©j√† stationnaires. Ainsi, nous ajusterons toutes les s√©ries pour aligner leurs longueurs.\n\n#|warning: false\n#|message: false\n# Suppression de la premi√®re observation des s√©ries non diff√©renci√©es\n\n#  dataframe avec des longueurs align√©es\nstationnaire_data &lt;- data.frame(\n  Date = data_adj$Date[-1],\n  IPA = ipa_diff,  \n  CDD = CDD_deseason[-1],  \n  importations = importation_diff,\n  exportations = exportations_deseason[-1],\n  petrole = petrole_diff, \n  taux_change = taux_change_diff,  \n  SMIC = ts_SMIC[-1],\n  precipitation = precipitations_deseason[-1],\n  temperature = temperature_deseason[-1]\n)\n\n\n#|warning: false\n#|message: false\n\n\n# Re v√©rification du test ADF \nlapply(stationnaire_data[variables], function(x) {\n  adf.test(x, alternative = \"stationary\")\n})\n\nWarning in adf.test(x, alternative = \"stationary\"): p-value smaller than\nprinted p-value\nWarning in adf.test(x, alternative = \"stationary\"): p-value smaller than\nprinted p-value\nWarning in adf.test(x, alternative = \"stationary\"): p-value smaller than\nprinted p-value\nWarning in adf.test(x, alternative = \"stationary\"): p-value smaller than\nprinted p-value\nWarning in adf.test(x, alternative = \"stationary\"): p-value smaller than\nprinted p-value\nWarning in adf.test(x, alternative = \"stationary\"): p-value smaller than\nprinted p-value\nWarning in adf.test(x, alternative = \"stationary\"): p-value smaller than\nprinted p-value\n\n\n$IPA\n\n    Augmented Dickey-Fuller Test\n\ndata:  x\nDickey-Fuller = -3.9389, Lag order = 6, p-value = 0.01251\nalternative hypothesis: stationary\n\n\n$CDD\n\n    Augmented Dickey-Fuller Test\n\ndata:  x\nDickey-Fuller = -6.4265, Lag order = 6, p-value = 0.01\nalternative hypothesis: stationary\n\n\n$precipitation\n\n    Augmented Dickey-Fuller Test\n\ndata:  x\nDickey-Fuller = -5.8847, Lag order = 6, p-value = 0.01\nalternative hypothesis: stationary\n\n\n$temperature\n\n    Augmented Dickey-Fuller Test\n\ndata:  x\nDickey-Fuller = -3.9132, Lag order = 6, p-value = 0.01379\nalternative hypothesis: stationary\n\n\n$exportations\n\n    Augmented Dickey-Fuller Test\n\ndata:  x\nDickey-Fuller = -6.2011, Lag order = 6, p-value = 0.01\nalternative hypothesis: stationary\n\n\n$importations\n\n    Augmented Dickey-Fuller Test\n\ndata:  x\nDickey-Fuller = -10.305, Lag order = 6, p-value = 0.01\nalternative hypothesis: stationary\n\n\n$taux_change\n\n    Augmented Dickey-Fuller Test\n\ndata:  x\nDickey-Fuller = -6.4556, Lag order = 6, p-value = 0.01\nalternative hypothesis: stationary\n\n\n$SMIC\n\n    Augmented Dickey-Fuller Test\n\ndata:  x\nDickey-Fuller = -6.0722, Lag order = 6, p-value = 0.01\nalternative hypothesis: stationary\n\n\n$petrole\n\n    Augmented Dickey-Fuller Test\n\ndata:  x\nDickey-Fuller = -6.3498, Lag order = 6, p-value = 0.01\nalternative hypothesis: stationary\n\n# test kpss \nlapply(stationnaire_data[variables], function(x) {\n  kpss.test(x, null = \"Trend\")\n})\n\nWarning in kpss.test(x, null = \"Trend\"): p-value greater than printed p-value\n\n\nWarning in kpss.test(x, null = \"Trend\"): p-value greater than printed p-value\nWarning in kpss.test(x, null = \"Trend\"): p-value greater than printed p-value\nWarning in kpss.test(x, null = \"Trend\"): p-value greater than printed p-value\nWarning in kpss.test(x, null = \"Trend\"): p-value greater than printed p-value\nWarning in kpss.test(x, null = \"Trend\"): p-value greater than printed p-value\nWarning in kpss.test(x, null = \"Trend\"): p-value greater than printed p-value\n\n\n$IPA\n\n    KPSS Test for Trend Stationarity\n\ndata:  x\nKPSS Trend = 0.12657, Truncation lag parameter = 5, p-value = 0.08599\n\n\n$CDD\n\n    KPSS Test for Trend Stationarity\n\ndata:  x\nKPSS Trend = 0.052585, Truncation lag parameter = 5, p-value = 0.1\n\n\n$precipitation\n\n    KPSS Test for Trend Stationarity\n\ndata:  x\nKPSS Trend = 0.081222, Truncation lag parameter = 5, p-value = 0.1\n\n\n$temperature\n\n    KPSS Test for Trend Stationarity\n\ndata:  x\nKPSS Trend = 0.14976, Truncation lag parameter = 5, p-value = 0.04686\n\n\n$exportations\n\n    KPSS Test for Trend Stationarity\n\ndata:  x\nKPSS Trend = 0.066037, Truncation lag parameter = 5, p-value = 0.1\n\n\n$importations\n\n    KPSS Test for Trend Stationarity\n\ndata:  x\nKPSS Trend = 0.014578, Truncation lag parameter = 5, p-value = 0.1\n\n\n$taux_change\n\n    KPSS Test for Trend Stationarity\n\ndata:  x\nKPSS Trend = 0.070678, Truncation lag parameter = 5, p-value = 0.1\n\n\n$SMIC\n\n    KPSS Test for Trend Stationarity\n\ndata:  x\nKPSS Trend = 0.019059, Truncation lag parameter = 5, p-value = 0.1\n\n\n$petrole\n\n    KPSS Test for Trend Stationarity\n\ndata:  x\nKPSS Trend = 0.038075, Truncation lag parameter = 5, p-value = 0.1\n\n# test kpss \nlapply(stationnaire_data[variables], function(x) {\n  kpss.test(x, null = \"Level\")\n})\n\nWarning in kpss.test(x, null = \"Level\"): p-value smaller than printed p-value\n\n\nWarning in kpss.test(x, null = \"Level\"): p-value greater than printed p-value\n\n\nWarning in kpss.test(x, null = \"Level\"): p-value smaller than printed p-value\nWarning in kpss.test(x, null = \"Level\"): p-value smaller than printed p-value\n\n\nWarning in kpss.test(x, null = \"Level\"): p-value greater than printed p-value\nWarning in kpss.test(x, null = \"Level\"): p-value greater than printed p-value\nWarning in kpss.test(x, null = \"Level\"): p-value greater than printed p-value\nWarning in kpss.test(x, null = \"Level\"): p-value greater than printed p-value\n\n\n$IPA\n\n    KPSS Test for Level Stationarity\n\ndata:  x\nKPSS Level = 0.58846, Truncation lag parameter = 5, p-value = 0.02369\n\n\n$CDD\n\n    KPSS Test for Level Stationarity\n\ndata:  x\nKPSS Level = 0.83849, Truncation lag parameter = 5, p-value = 0.01\n\n\n$precipitation\n\n    KPSS Test for Level Stationarity\n\ndata:  x\nKPSS Level = 0.21186, Truncation lag parameter = 5, p-value = 0.1\n\n\n$temperature\n\n    KPSS Test for Level Stationarity\n\ndata:  x\nKPSS Level = 1.7803, Truncation lag parameter = 5, p-value = 0.01\n\n\n$exportations\n\n    KPSS Test for Level Stationarity\n\ndata:  x\nKPSS Level = 3.7628, Truncation lag parameter = 5, p-value = 0.01\n\n\n$importations\n\n    KPSS Test for Level Stationarity\n\ndata:  x\nKPSS Level = 0.031579, Truncation lag parameter = 5, p-value = 0.1\n\n\n$taux_change\n\n    KPSS Test for Level Stationarity\n\ndata:  x\nKPSS Level = 0.17753, Truncation lag parameter = 5, p-value = 0.1\n\n\n$SMIC\n\n    KPSS Test for Level Stationarity\n\ndata:  x\nKPSS Level = 0.019994, Truncation lag parameter = 5, p-value = 0.1\n\n\n$petrole\n\n    KPSS Test for Level Stationarity\n\ndata:  x\nKPSS Level = 0.055257, Truncation lag parameter = 5, p-value = 0.1"
  },
  {
    "objectID": "posts/post-with-code/memoire/memoire_m1.html#s√©lection-des-variables",
    "href": "posts/post-with-code/memoire/memoire_m1.html#s√©lection-des-variables",
    "title": "M√©moire",
    "section": "S√©lection des variables",
    "text": "S√©lection des variables\n1er m√©thode\n\nleaps &lt;- regsubsets(IPA ~ CDD +  importations + exportations +  petrole +  taux_change + SMIC + precipitation + temperature, data=stationnaire_data, nbest=1, method=c(\"exhaustive\"))\n\nsummary(leaps)\n\nSubset selection object\nCall: regsubsets.formula(IPA ~ CDD + importations + exportations + \n    petrole + taux_change + SMIC + precipitation + temperature, \n    data = stationnaire_data, nbest = 1, method = c(\"exhaustive\"))\n8 Variables  (and intercept)\n              Forced in Forced out\nCDD               FALSE      FALSE\nimportations      FALSE      FALSE\nexportations      FALSE      FALSE\npetrole           FALSE      FALSE\ntaux_change       FALSE      FALSE\nSMIC              FALSE      FALSE\nprecipitation     FALSE      FALSE\ntemperature       FALSE      FALSE\n1 subsets of each size up to 8\nSelection Algorithm: exhaustive\n         CDD importations exportations petrole taux_change SMIC precipitation\n1  ( 1 ) \" \" \" \"          \"*\"          \" \"     \" \"         \" \"  \" \"          \n2  ( 1 ) \"*\" \" \"          \"*\"          \" \"     \" \"         \" \"  \" \"          \n3  ( 1 ) \" \" \" \"          \"*\"          \"*\"     \" \"         \" \"  \"*\"          \n4  ( 1 ) \" \" \" \"          \"*\"          \"*\"     \"*\"         \" \"  \"*\"          \n5  ( 1 ) \"*\" \" \"          \"*\"          \"*\"     \"*\"         \" \"  \"*\"          \n6  ( 1 ) \"*\" \"*\"          \"*\"          \"*\"     \"*\"         \" \"  \"*\"          \n7  ( 1 ) \"*\" \"*\"          \"*\"          \"*\"     \"*\"         \" \"  \"*\"          \n8  ( 1 ) \"*\" \"*\"          \"*\"          \"*\"     \"*\"         \"*\"  \"*\"          \n         temperature\n1  ( 1 ) \" \"        \n2  ( 1 ) \" \"        \n3  ( 1 ) \" \"        \n4  ( 1 ) \" \"        \n5  ( 1 ) \" \"        \n6  ( 1 ) \" \"        \n7  ( 1 ) \"*\"        \n8  ( 1 ) \"*\"        \n\n# R√©sum√© des crit√®res pour choisir le mod√®le optimal\nres.sum &lt;- summary(leaps)\noptimal_model &lt;- data.frame(\n  Adj.R2 = which.max(res.sum$adjr2),\n  CP = which.min(res.sum$cp),\n  BIC = which.min(res.sum$bic)\n)\n\n# Affichage des r√©sultats\nprint(optimal_model)\n\n  Adj.R2 CP BIC\n1      5  5   3\n\nprint(res.sum)\n\nSubset selection object\nCall: regsubsets.formula(IPA ~ CDD + importations + exportations + \n    petrole + taux_change + SMIC + precipitation + temperature, \n    data = stationnaire_data, nbest = 1, method = c(\"exhaustive\"))\n8 Variables  (and intercept)\n              Forced in Forced out\nCDD               FALSE      FALSE\nimportations      FALSE      FALSE\nexportations      FALSE      FALSE\npetrole           FALSE      FALSE\ntaux_change       FALSE      FALSE\nSMIC              FALSE      FALSE\nprecipitation     FALSE      FALSE\ntemperature       FALSE      FALSE\n1 subsets of each size up to 8\nSelection Algorithm: exhaustive\n         CDD importations exportations petrole taux_change SMIC precipitation\n1  ( 1 ) \" \" \" \"          \"*\"          \" \"     \" \"         \" \"  \" \"          \n2  ( 1 ) \"*\" \" \"          \"*\"          \" \"     \" \"         \" \"  \" \"          \n3  ( 1 ) \" \" \" \"          \"*\"          \"*\"     \" \"         \" \"  \"*\"          \n4  ( 1 ) \" \" \" \"          \"*\"          \"*\"     \"*\"         \" \"  \"*\"          \n5  ( 1 ) \"*\" \" \"          \"*\"          \"*\"     \"*\"         \" \"  \"*\"          \n6  ( 1 ) \"*\" \"*\"          \"*\"          \"*\"     \"*\"         \" \"  \"*\"          \n7  ( 1 ) \"*\" \"*\"          \"*\"          \"*\"     \"*\"         \" \"  \"*\"          \n8  ( 1 ) \"*\" \"*\"          \"*\"          \"*\"     \"*\"         \"*\"  \"*\"          \n         temperature\n1  ( 1 ) \" \"        \n2  ( 1 ) \" \"        \n3  ( 1 ) \" \"        \n4  ( 1 ) \" \"        \n5  ( 1 ) \" \"        \n6  ( 1 ) \" \"        \n7  ( 1 ) \"*\"        \n8  ( 1 ) \"*\"        \n\n# plot a table of models showing variables in each model.\n# models are ordered by the selection statistic\n# Other options for plot( ) are bic, Cp, and adjr2\npar(mfrow=c(1,1))\n\nplot(leaps, scale=\"adjr2\", main = \"Adjusted R^2\")\n\n\n\n\n\n\n\nplot(leaps, scale=\"Cp\", main = \"Mallow's Cp\")\n\n\n\n\n\n\n\nplot(leaps, scale=\"bic\", main = \"BIC\")"
  },
  {
    "objectID": "posts/post-with-code/memoire/memoire_m1.html#deuxi√®me-approche-de-s√©lection",
    "href": "posts/post-with-code/memoire/memoire_m1.html#deuxi√®me-approche-de-s√©lection",
    "title": "M√©moire",
    "section": "Deuxi√®me approche de s√©lection",
    "text": "Deuxi√®me approche de s√©lection\n\n# Modele avec toutes les variables, ne sera pas utilis√© dans notre analyse - voir m√©thode STEP\n\nmodele1 &lt;- lm(IPA ~  CDD +  importations + exportations +  petrole +  taux_change + SMIC + precipitation + temperature, data=stationnaire_data)\n\nsummary(modele1)\n\n\nCall:\nlm(formula = IPA ~ CDD + importations + exportations + petrole + \n    taux_change + SMIC + precipitation + temperature, data = stationnaire_data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-63.082  -9.647  -1.660   7.512 114.297 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)    3.50014   21.25705   0.165 0.869338    \nCDD            1.67054    0.95321   1.753 0.080834 .  \nimportations   0.04751    0.08371   0.568 0.570832    \nexportations   0.23078    0.05235   4.409 1.51e-05 ***\npetrole        0.75790    0.21168   3.580 0.000408 ***\ntaux_change   21.03398   10.31384   2.039 0.042399 *  \nSMIC           0.00493    0.05341   0.092 0.926529    \nprecipitation -0.16864    0.08630  -1.954 0.051731 .  \ntemperature   -1.30279    3.41350  -0.382 0.703021    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 20.1 on 266 degrees of freedom\nMultiple R-squared:  0.1708,    Adjusted R-squared:  0.1458 \nF-statistic: 6.847 on 8 and 266 DF,  p-value: 3.489e-08\n\n# Step : SeÃÅlection des variables explicatives significatives (modeÃÄle lineÃÅaire = modele1 )\n\nmodele0 &lt;- lm(IPA~1,data=stationnaire_data)\nsummary(modele0)\n\n\nCall:\nlm(formula = IPA ~ 1, data = stationnaire_data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-60.985 -10.203  -3.965   5.489 132.912 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)    7.146      1.311   5.449 1.13e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 21.75 on 274 degrees of freedom\n\n### M√©thode ascendante\nstep1 &lt;- step(modele0, scope=list(lower=modele0, upper=modele1), data=stationnaire_data, direction=\"forward\")\n\nStart:  AIC=1694.75\nIPA ~ 1\n\n                Df Sum of Sq    RSS    AIC\n+ exportations   1   10514.2 119087 1673.5\n+ CDD            1    7482.6 122118 1680.4\n+ precipitation  1    5178.7 124422 1685.5\n+ petrole        1    3258.2 126343 1689.8\n+ temperature    1    2522.9 127078 1691.3\n&lt;none&gt;                       129601 1694.8\n+ taux_change    1     396.9 129204 1695.9\n+ importations   1     388.0 129213 1695.9\n+ SMIC           1       4.3 129597 1696.7\n\nStep:  AIC=1673.48\nIPA ~ exportations\n\n                Df Sum of Sq    RSS    AIC\n+ CDD            1    4509.8 114577 1664.9\n+ precipitation  1    4286.2 114801 1665.4\n+ petrole        1    3708.8 115378 1666.8\n&lt;none&gt;                       119087 1673.5\n+ temperature    1     526.8 118560 1674.3\n+ taux_change    1     294.5 118792 1674.8\n+ importations   1     277.5 118809 1674.8\n+ SMIC           1      36.9 119050 1675.4\n\nStep:  AIC=1664.86\nIPA ~ exportations + CDD\n\n                Df Sum of Sq    RSS    AIC\n+ petrole        1    3654.2 110923 1658.0\n+ precipitation  1    1121.9 113455 1664.2\n&lt;none&gt;                       114577 1664.9\n+ taux_change    1     394.5 114182 1665.9\n+ importations   1     341.6 114235 1666.0\n+ SMIC           1      13.6 114563 1666.8\n+ temperature    1       0.1 114577 1666.9\n\nStep:  AIC=1657.95\nIPA ~ exportations + CDD + petrole\n\n                Df Sum of Sq    RSS    AIC\n+ taux_change    1   1630.73 109292 1655.9\n+ precipitation  1   1545.06 109378 1656.1\n&lt;none&gt;                       110923 1658.0\n+ importations   1    220.08 110703 1659.4\n+ temperature    1     33.87 110889 1659.9\n+ SMIC           1     27.01 110896 1659.9\n\nStep:  AIC=1655.88\nIPA ~ exportations + CDD + petrole + taux_change\n\n                Df Sum of Sq    RSS    AIC\n+ precipitation  1   1608.85 107683 1653.8\n&lt;none&gt;                       109292 1655.9\n+ importations   1    239.66 109052 1657.3\n+ temperature    1     26.53 109265 1657.8\n+ SMIC           1      0.14 109292 1657.9\n\nStep:  AIC=1653.8\nIPA ~ exportations + CDD + petrole + taux_change + precipitation\n\n               Df Sum of Sq    RSS    AIC\n&lt;none&gt;                      107683 1653.8\n+ importations  1   150.885 107532 1655.4\n+ temperature   1    77.809 107605 1655.6\n+ SMIC          1     3.351 107680 1655.8\n\n### M√©thode descendante\nstep2 &lt;- step(modele1,data=stationnaire_data,direction=\"backward\")\n\nStart:  AIC=1659.26\nIPA ~ CDD + importations + exportations + petrole + taux_change + \n    SMIC + precipitation + temperature\n\n                Df Sum of Sq    RSS    AIC\n- SMIC           1       3.4 107474 1657.3\n- temperature    1      58.9 107530 1657.4\n- importations   1     130.1 107601 1657.6\n&lt;none&gt;                       107471 1659.3\n- CDD            1    1240.9 108712 1660.4\n- precipitation  1    1542.9 109014 1661.2\n- taux_change    1    1680.4 109151 1661.5\n- petrole        1    5179.2 112650 1670.2\n- exportations   1    7852.3 115323 1676.7\n\nStep:  AIC=1657.26\nIPA ~ CDD + importations + exportations + petrole + taux_change + \n    precipitation + temperature\n\n                Df Sum of Sq    RSS    AIC\n- temperature    1      58.0 107532 1655.4\n- importations   1     131.1 107605 1655.6\n&lt;none&gt;                       107474 1657.3\n- CDD            1    1240.1 108714 1658.4\n- precipitation  1    1539.4 109014 1659.2\n- taux_change    1    1722.5 109197 1659.6\n- petrole        1    5182.5 112657 1668.2\n- exportations   1    7890.1 115364 1674.8\n\nStep:  AIC=1655.41\nIPA ~ CDD + importations + exportations + petrole + taux_change + \n    precipitation\n\n                Df Sum of Sq    RSS    AIC\n- importations   1     150.9 107683 1653.8\n&lt;none&gt;                       107532 1655.4\n- CDD            1    1194.3 108727 1656.5\n- precipitation  1    1520.1 109052 1657.3\n- taux_change    1    1708.8 109241 1657.8\n- petrole        1    5262.3 112795 1666.5\n- exportations   1    8068.0 115600 1673.3\n\nStep:  AIC=1653.8\nIPA ~ CDD + exportations + petrole + taux_change + precipitation\n\n                Df Sum of Sq    RSS    AIC\n&lt;none&gt;                       107683 1653.8\n- CDD            1    1142.0 108825 1654.7\n- precipitation  1    1608.9 109292 1655.9\n- taux_change    1    1694.5 109378 1656.1\n- petrole        1    5390.6 113074 1665.2\n- exportations   1    8176.7 115860 1671.9\n\n### M√©thode double\n#m√©thode dans les 2 sens\nstep3 &lt;- step(modele0,scope=list(upper=modele1),data=stationnaire_data,direction=\"both\")\n\nStart:  AIC=1694.75\nIPA ~ 1\n\n                Df Sum of Sq    RSS    AIC\n+ exportations   1   10514.2 119087 1673.5\n+ CDD            1    7482.6 122118 1680.4\n+ precipitation  1    5178.7 124422 1685.5\n+ petrole        1    3258.2 126343 1689.8\n+ temperature    1    2522.9 127078 1691.3\n&lt;none&gt;                       129601 1694.8\n+ taux_change    1     396.9 129204 1695.9\n+ importations   1     388.0 129213 1695.9\n+ SMIC           1       4.3 129597 1696.7\n\nStep:  AIC=1673.48\nIPA ~ exportations\n\n                Df Sum of Sq    RSS    AIC\n+ CDD            1    4509.8 114577 1664.9\n+ precipitation  1    4286.2 114801 1665.4\n+ petrole        1    3708.8 115378 1666.8\n&lt;none&gt;                       119087 1673.5\n+ temperature    1     526.8 118560 1674.3\n+ taux_change    1     294.5 118792 1674.8\n+ importations   1     277.5 118809 1674.8\n+ SMIC           1      36.9 119050 1675.4\n- exportations   1   10514.2 129601 1694.8\n\nStep:  AIC=1664.86\nIPA ~ exportations + CDD\n\n                Df Sum of Sq    RSS    AIC\n+ petrole        1    3654.2 110923 1658.0\n+ precipitation  1    1121.9 113455 1664.2\n&lt;none&gt;                       114577 1664.9\n+ taux_change    1     394.5 114182 1665.9\n+ importations   1     341.6 114235 1666.0\n+ SMIC           1      13.6 114563 1666.8\n+ temperature    1       0.1 114577 1666.9\n- CDD            1    4509.8 119087 1673.5\n- exportations   1    7541.5 122118 1680.4\n\nStep:  AIC=1657.95\nIPA ~ exportations + CDD + petrole\n\n                Df Sum of Sq    RSS    AIC\n+ taux_change    1    1630.7 109292 1655.9\n+ precipitation  1    1545.1 109378 1656.1\n&lt;none&gt;                       110923 1658.0\n+ importations   1     220.1 110703 1659.4\n+ temperature    1      33.9 110889 1659.9\n+ SMIC           1      27.0 110896 1659.9\n- petrole        1    3654.2 114577 1664.9\n- CDD            1    4455.3 115378 1666.8\n- exportations   1    7928.8 118852 1674.9\n\nStep:  AIC=1655.88\nIPA ~ exportations + CDD + petrole + taux_change\n\n                Df Sum of Sq    RSS    AIC\n+ precipitation  1    1608.9 107683 1653.8\n&lt;none&gt;                       109292 1655.9\n+ importations   1     239.7 109052 1657.3\n+ temperature    1      26.5 109265 1657.8\n+ SMIC           1       0.1 109292 1657.9\n- taux_change    1    1630.7 110923 1658.0\n- CDD            1    4665.5 113958 1665.4\n- petrole        1    4890.5 114182 1665.9\n- exportations   1    7751.2 117043 1672.7\n\nStep:  AIC=1653.8\nIPA ~ exportations + CDD + petrole + taux_change + precipitation\n\n                Df Sum of Sq    RSS    AIC\n&lt;none&gt;                       107683 1653.8\n- CDD            1    1142.0 108825 1654.7\n+ importations   1     150.9 107532 1655.4\n+ temperature    1      77.8 107605 1655.6\n+ SMIC           1       3.4 107680 1655.8\n- precipitation  1    1608.9 109292 1655.9\n- taux_change    1    1694.5 109378 1656.1\n- petrole        1    5390.6 113074 1665.2\n- exportations   1    8176.7 115860 1671.9"
  },
  {
    "objectID": "posts/post-with-code/memoire/memoire_m1.html#mod√®le",
    "href": "posts/post-with-code/memoire/memoire_m1.html#mod√®le",
    "title": "M√©moire",
    "section": "1. Mod√®le",
    "text": "1. Mod√®le\n1 retenue\n\nlm_model1 &lt;- lm(IPA ~ exportations + CDD + petrole + taux_change + precipitation, data=stationnaire_data)\n\nsummary(lm_model1)\n\n\nCall:\nlm(formula = IPA ~ exportations + CDD + petrole + taux_change + \n    precipitation, data = stationnaire_data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-62.049  -9.874  -1.524   7.272 114.365 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)    2.78407   18.61192   0.150 0.881204    \nexportations   0.22733    0.05030   4.520 9.29e-06 ***\nCDD            1.57990    0.93540   1.689 0.092376 .  \npetrole        0.77049    0.20997   3.670 0.000293 ***\ntaux_change   20.96618   10.19045   2.057 0.040608 *  \nprecipitation -0.16106    0.08034  -2.005 0.045992 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 20.01 on 269 degrees of freedom\nMultiple R-squared:  0.1691,    Adjusted R-squared:  0.1537 \nF-statistic: 10.95 on 5 and 269 DF,  p-value: 1.316e-09\n\n\n\nHypoth√®ses\nTest de normalit√© des r√©sidus\n\n# R√©sidus\n# Test de normalit√© des r√©sidus\nresidus &lt;- residuals(lm_model1)\n# Test de normalit√© des r√©sidus\nks.test(residus, \"pnorm\", mean = mean(residus), sd = sd(residus))\n\n\n    Asymptotic one-sample Kolmogorov-Smirnov test\n\ndata:  residus\nD = 0.11327, p-value = 0.001723\nalternative hypothesis: two-sided\n\n\np-value = 0.001723, Refus de l‚Äôhypoth√®se de normalit√© des r√©sidus au seuil de risque de 5%\nTest d‚Äôhomosc√©dasticit√© des r√©sidus\n\n# Test de Breusch-Pagan pour l'h√©t√©rosc√©dasticit√©\nbptest(lm_model1)\n\n\n    studentized Breusch-Pagan test\n\ndata:  lm_model1\nBP = 26.02, df = 5, p-value = 8.844e-05\n\n\np-value = 8.844e-05, Refus de l‚Äôhypoth√®se d‚Äôhomosc√©dacticit√© des r√©sidus au seuil de risque de 5%\nForme fonctionnelle\n\n# Test RESET\nreset(lm_model1)\n\n\n    RESET test\n\ndata:  lm_model1\nRESET = 6.6669, df1 = 2, df2 = 267, p-value = 0.001495\n\n\np-value = 0.001495; Forme fonctionnelle lin√©aire du mod√®le sp√©cifi√© accept√©e au seuil de 5%\nAnalyse des observations influen√ßant l‚Äôestimation\n\n# Distance de Cook pour identifier les points influents\nplot(cooks.distance(lm_model1), type = \"h\", main = \"Distance de Cook\")\n\n\n\n\n\n\n\n\nmulticollin√©arit√©\n\nvif(lm_model1)\n\n exportations           CDD       petrole   taux_change precipitation \n     1.048992      1.531173      1.115762      1.107182      1.482521 \n\n\nAutocorrelation de r√©sidus\n\ncheckresiduals(lm_model1)\n\n\n\n\n\n\n\n\n\n    Breusch-Godfrey test for serial correlation of order up to 10\n\ndata:  Residuals\nLM test = 109.93, df = 10, p-value &lt; 2.2e-16\n\n\np-value &lt; 2.2e-16. il existe des preuves significatives d‚Äôauto-corr√©lation r√©siduelle dans les donn√©es."
  },
  {
    "objectID": "posts/post-with-code/memoire/memoire_m1.html#mod√®le-2-diff√©renci√©---logarithmique",
    "href": "posts/post-with-code/memoire/memoire_m1.html#mod√®le-2-diff√©renci√©---logarithmique",
    "title": "M√©moire",
    "section": "2. Mod√®le 2: diff√©renci√© - logarithmique",
    "text": "2. Mod√®le 2: diff√©renci√© - logarithmique\nDans ce model nous appliquons le logarithme avant la diff√©renciation p\n\nd_l_IPA &lt;- diff(log(data_adj$IPA), differences = 1)\nplot(ts(d_l_IPA))\n\n\n\n\n\n\n\nadf.test(d_l_IPA) # on verifie stationnarit√© \n\nWarning in adf.test(d_l_IPA): p-value smaller than printed p-value\n\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  d_l_IPA\nDickey-Fuller = -5.2389, Lag order = 6, p-value = 0.01\nalternative hypothesis: stationary\n\n# creation df avec la dif du log de ipa\nst2_data &lt;- data.frame(\n  Date = data_adj$Date[-1],\n  IPA = d_l_IPA,  \n  CDD = CDD_deseason[-1],  \n  importations = importation_diff,\n  exportations = exportations_deseason[-1],\n  petrole = petrole_diff, \n  taux_change = taux_change_diff,  \n  SMIC = ts_SMIC[-1],\n  precipitation = precipitations_deseason[-1],\n  temperature = temperature_deseason[-1]\n)\n\n# estimation modele avec ipa differenci√© et log\nmodele1_2 &lt;- lm(IPA ~ CDD +  importations + exportations +  petrole +  taux_change + SMIC + precipitation + temperature, data=st2_data)\nsummary(modele1_2)\n\n\nCall:\nlm(formula = IPA ~ CDD + importations + exportations + petrole + \n    taux_change + SMIC + precipitation + temperature, data = st2_data)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.053209 -0.013832 -0.001854  0.010430  0.074676 \n\nCoefficients:\n                Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)    4.582e-02  2.275e-02   2.014 0.045005 *  \nCDD            7.037e-05  1.020e-03   0.069 0.945062    \nimportations   5.464e-05  8.959e-05   0.610 0.542481    \nexportations   1.068e-04  5.603e-05   1.907 0.057611 .  \npetrole        8.162e-04  2.266e-04   3.602 0.000376 ***\ntaux_change    4.257e-02  1.104e-02   3.856 0.000144 ***\nSMIC          -3.741e-05  5.717e-05  -0.654 0.513451    \nprecipitation -2.346e-04  9.237e-05  -2.540 0.011646 *  \ntemperature   -3.939e-03  3.654e-03  -1.078 0.281995    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.02151 on 266 degrees of freedom\nMultiple R-squared:  0.1119,    Adjusted R-squared:  0.08523 \nF-statistic: 4.191 on 8 and 266 DF,  p-value: 9.593e-05\n\n# Step : SeÃÅlection des variables explicatives significatives (modeÃÄle lineÃÅaire = modele1 )\n\nmodele0_2 &lt;- (lm(IPA~1,data=st2_data))\nsummary(modele0_2)\n\n\nCall:\nlm(formula = IPA ~ 1, data = st2_data)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.060967 -0.014968 -0.002519  0.011062  0.082152 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 0.008686   0.001356   6.403 6.58e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.02249 on 274 degrees of freedom\n\n### M√©thode ascendante\nstep(modele0_2, scope=list(lower=modele0_2, upper=modele1_2), data=st2_data, direction=\"forward\")\n\nStart:  AIC=-2085.99\nIPA ~ 1\n\n                Df Sum of Sq     RSS     AIC\n+ taux_change    1 0.0035569 0.13508 -2091.1\n+ precipitation  1 0.0032765 0.13536 -2090.6\n+ petrole        1 0.0027049 0.13593 -2089.4\n+ exportations   1 0.0016087 0.13703 -2087.2\n+ CDD            1 0.0015048 0.13713 -2087.0\n&lt;none&gt;                       0.13864 -2086.0\n+ importations   1 0.0004699 0.13817 -2084.9\n+ temperature    1 0.0001474 0.13849 -2084.3\n+ SMIC           1 0.0001195 0.13852 -2084.2\n\nStep:  AIC=-2091.13\nIPA ~ taux_change\n\n                Df Sum of Sq     RSS     AIC\n+ petrole        1 0.0054703 0.12961 -2100.5\n+ precipitation  1 0.0033626 0.13172 -2096.1\n+ CDD            1 0.0016667 0.13341 -2092.6\n+ exportations   1 0.0014833 0.13359 -2092.2\n&lt;none&gt;                       0.13508 -2091.1\n+ importations   1 0.0005565 0.13452 -2090.3\n+ SMIC           1 0.0003469 0.13473 -2089.8\n+ temperature    1 0.0000998 0.13498 -2089.3\n\nStep:  AIC=-2100.5\nIPA ~ taux_change + petrole\n\n                Df Sum of Sq     RSS     AIC\n+ precipitation  1 0.0041454 0.12546 -2107.4\n+ CDD            1 0.0017392 0.12787 -2102.2\n+ exportations   1 0.0016606 0.12795 -2102.1\n&lt;none&gt;                       0.12961 -2100.5\n+ importations   1 0.0003904 0.12922 -2099.3\n+ SMIC           1 0.0003829 0.12923 -2099.3\n+ temperature    1 0.0002855 0.12932 -2099.1\n\nStep:  AIC=-2107.44\nIPA ~ taux_change + petrole + precipitation\n\n               Df  Sum of Sq     RSS     AIC\n+ exportations  1 0.00135287 0.12411 -2108.4\n&lt;none&gt;                       0.12546 -2107.4\n+ importations  1 0.00026866 0.12519 -2106.0\n+ temperature   1 0.00019464 0.12527 -2105.9\n+ SMIC          1 0.00016345 0.12530 -2105.8\n+ CDD           1 0.00004282 0.12542 -2105.5\n\nStep:  AIC=-2108.42\nIPA ~ taux_change + petrole + precipitation + exportations\n\n               Df  Sum of Sq     RSS     AIC\n&lt;none&gt;                       0.12411 -2108.4\n+ temperature   1 0.00062530 0.12348 -2107.8\n+ importations  1 0.00023504 0.12387 -2106.9\n+ SMIC          1 0.00020702 0.12390 -2106.9\n+ CDD           1 0.00000092 0.12411 -2106.4\n\n\n\nCall:\nlm(formula = IPA ~ taux_change + petrole + precipitation + exportations, \n    data = st2_data)\n\nCoefficients:\n  (Intercept)    taux_change        petrole  precipitation   exportations  \n    3.342e-02      4.133e-02      8.381e-04     -2.054e-04      9.054e-05  \n\n### M√©thode descendante\nstep(modele1_2,data=st2_data,direction=\"backward\")\n\nStart:  AIC=-2102.63\nIPA ~ CDD + importations + exportations + petrole + taux_change + \n    SMIC + precipitation + temperature\n\n                Df Sum of Sq     RSS     AIC\n- CDD            1 0.0000022 0.12312 -2104.6\n- importations   1 0.0001721 0.12329 -2104.2\n- SMIC           1 0.0001982 0.12331 -2104.2\n- temperature    1 0.0005379 0.12366 -2103.4\n&lt;none&gt;                       0.12312 -2102.6\n- exportations   1 0.0016830 0.12480 -2100.9\n- precipitation  1 0.0029868 0.12610 -2098.0\n- petrole        1 0.0060068 0.12912 -2091.5\n- taux_change    1 0.0068828 0.13000 -2089.7\n\nStep:  AIC=-2104.63\nIPA ~ importations + exportations + petrole + taux_change + SMIC + \n    precipitation + temperature\n\n                Df Sum of Sq     RSS     AIC\n- importations   1 0.0001705 0.12329 -2106.2\n- SMIC           1 0.0002043 0.12332 -2106.2\n- temperature    1 0.0005374 0.12366 -2105.4\n&lt;none&gt;                       0.12312 -2104.6\n- exportations   1 0.0017558 0.12487 -2102.7\n- precipitation  1 0.0039845 0.12710 -2097.9\n- petrole        1 0.0060420 0.12916 -2093.4\n- taux_change    1 0.0068808 0.13000 -2091.7\n\nStep:  AIC=-2106.25\nIPA ~ exportations + petrole + taux_change + SMIC + precipitation + \n    temperature\n\n                Df Sum of Sq     RSS     AIC\n- SMIC           1 0.0001947 0.12348 -2107.8\n- temperature    1 0.0006130 0.12390 -2106.9\n&lt;none&gt;                       0.12329 -2106.2\n- exportations   1 0.0018247 0.12512 -2104.2\n- precipitation  1 0.0041861 0.12748 -2099.1\n- petrole        1 0.0061623 0.12945 -2094.8\n- taux_change    1 0.0068525 0.13014 -2093.4\n\nStep:  AIC=-2107.81\nIPA ~ exportations + petrole + taux_change + precipitation + \n    temperature\n\n                Df Sum of Sq     RSS     AIC\n- temperature    1 0.0006253 0.12411 -2108.4\n&lt;none&gt;                       0.12348 -2107.8\n- exportations   1 0.0017835 0.12527 -2105.9\n- precipitation  1 0.0044267 0.12791 -2100.1\n- petrole        1 0.0061497 0.12963 -2096.4\n- taux_change    1 0.0066743 0.13016 -2095.3\n\nStep:  AIC=-2108.42\nIPA ~ exportations + petrole + taux_change + precipitation\n\n                Df Sum of Sq     RSS     AIC\n&lt;none&gt;                       0.12411 -2108.4\n- exportations   1 0.0013529 0.12546 -2107.4\n- precipitation  1 0.0038376 0.12795 -2102.1\n- petrole        1 0.0063937 0.13050 -2096.6\n- taux_change    1 0.0065890 0.13070 -2096.2\n\n\n\nCall:\nlm(formula = IPA ~ exportations + petrole + taux_change + precipitation, \n    data = st2_data)\n\nCoefficients:\n  (Intercept)   exportations        petrole    taux_change  precipitation  \n    3.342e-02      9.054e-05      8.381e-04      4.133e-02     -2.054e-04  \n\n### M√©thode double\n#m√©thode dans les 2 sens\nstep(modele0_2,scope=list(upper=modele1_2),data=st2_data,direction=\"both\")\n\nStart:  AIC=-2085.99\nIPA ~ 1\n\n                Df Sum of Sq     RSS     AIC\n+ taux_change    1 0.0035569 0.13508 -2091.1\n+ precipitation  1 0.0032765 0.13536 -2090.6\n+ petrole        1 0.0027049 0.13593 -2089.4\n+ exportations   1 0.0016087 0.13703 -2087.2\n+ CDD            1 0.0015048 0.13713 -2087.0\n&lt;none&gt;                       0.13864 -2086.0\n+ importations   1 0.0004699 0.13817 -2084.9\n+ temperature    1 0.0001474 0.13849 -2084.3\n+ SMIC           1 0.0001195 0.13852 -2084.2\n\nStep:  AIC=-2091.13\nIPA ~ taux_change\n\n                Df Sum of Sq     RSS     AIC\n+ petrole        1 0.0054703 0.12961 -2100.5\n+ precipitation  1 0.0033626 0.13172 -2096.1\n+ CDD            1 0.0016667 0.13341 -2092.6\n+ exportations   1 0.0014833 0.13359 -2092.2\n&lt;none&gt;                       0.13508 -2091.1\n+ importations   1 0.0005565 0.13452 -2090.3\n+ SMIC           1 0.0003469 0.13473 -2089.8\n+ temperature    1 0.0000998 0.13498 -2089.3\n- taux_change    1 0.0035569 0.13864 -2086.0\n\nStep:  AIC=-2100.5\nIPA ~ taux_change + petrole\n\n                Df Sum of Sq     RSS     AIC\n+ precipitation  1 0.0041454 0.12546 -2107.4\n+ CDD            1 0.0017392 0.12787 -2102.2\n+ exportations   1 0.0016606 0.12795 -2102.1\n&lt;none&gt;                       0.12961 -2100.5\n+ importations   1 0.0003904 0.12922 -2099.3\n+ SMIC           1 0.0003829 0.12923 -2099.3\n+ temperature    1 0.0002855 0.12932 -2099.1\n- petrole        1 0.0054703 0.13508 -2091.1\n- taux_change    1 0.0063223 0.13593 -2089.4\n\nStep:  AIC=-2107.44\nIPA ~ taux_change + petrole + precipitation\n\n                Df Sum of Sq     RSS     AIC\n+ exportations   1 0.0013529 0.12411 -2108.4\n&lt;none&gt;                       0.12546 -2107.4\n+ importations   1 0.0002687 0.12519 -2106.0\n+ temperature    1 0.0001946 0.12527 -2105.9\n+ SMIC           1 0.0001635 0.12530 -2105.8\n+ CDD            1 0.0000428 0.12542 -2105.5\n- precipitation  1 0.0041454 0.12961 -2100.5\n- petrole        1 0.0062530 0.13172 -2096.1\n- taux_change    1 0.0067044 0.13217 -2095.1\n\nStep:  AIC=-2108.42\nIPA ~ taux_change + petrole + precipitation + exportations\n\n                Df Sum of Sq     RSS     AIC\n&lt;none&gt;                       0.12411 -2108.4\n+ temperature    1 0.0006253 0.12348 -2107.8\n- exportations   1 0.0013529 0.12546 -2107.4\n+ importations   1 0.0002350 0.12387 -2106.9\n+ SMIC           1 0.0002070 0.12390 -2106.9\n+ CDD            1 0.0000009 0.12411 -2106.4\n- precipitation  1 0.0038376 0.12795 -2102.1\n- petrole        1 0.0063937 0.13050 -2096.6\n- taux_change    1 0.0065890 0.13070 -2096.2\n\n\n\nCall:\nlm(formula = IPA ~ taux_change + petrole + precipitation + exportations, \n    data = st2_data)\n\nCoefficients:\n  (Intercept)    taux_change        petrole  precipitation   exportations  \n    3.342e-02      4.133e-02      8.381e-04     -2.054e-04      9.054e-05  \n\n# MODELO 3 RETENUE\nlm_model2 &lt;- lm(IPA ~ taux_change + petrole + precipitation + exportations, \n    data = st2_data)\nsummary(lm_model2)\n\n\nCall:\nlm(formula = IPA ~ taux_change + petrole + precipitation + exportations, \n    data = st2_data)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.053072 -0.013313 -0.002177  0.009744  0.072178 \n\nCoefficients:\n                Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)    3.342e-02  1.095e-02   3.053 0.002494 ** \ntaux_change    4.133e-02  1.092e-02   3.786 0.000189 ***\npetrole        8.381e-04  2.247e-04   3.730 0.000234 ***\nprecipitation -2.054e-04  7.110e-05  -2.889 0.004173 ** \nexportations   9.054e-05  5.277e-05   1.716 0.087389 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.02144 on 270 degrees of freedom\nMultiple R-squared:  0.1048,    Adjusted R-squared:  0.09151 \nF-statistic:   7.9 on 4 and 270 DF,  p-value: 4.911e-06\n\n## TESTS \nresidus2 &lt;- residuals(lm_model2)\n# Test de normalit√© des r√©sidus\nks.test(residus2, \"pnorm\", mean = mean(residus2), sd = sd(residus2))\n\n\n    Asymptotic one-sample Kolmogorov-Smirnov test\n\ndata:  residus2\nD = 0.075036, p-value = 0.09039\nalternative hypothesis: two-sided\n\nbptest(lm_model2)\n\n\n    studentized Breusch-Pagan test\n\ndata:  lm_model2\nBP = 3.7142, df = 4, p-value = 0.4461\n\nreset(lm_model2)\n\n\n    RESET test\n\ndata:  lm_model2\nRESET = 0.21788, df1 = 2, df2 = 268, p-value = 0.8044\n\nvif(lm_model2)\n\n  taux_change       petrole precipitation  exportations \n     1.106656      1.113121      1.011154      1.005594 \n\ncheckresiduals(lm_model2)\n\n\n\n\n\n\n\n\n\n    Breusch-Godfrey test for serial correlation of order up to 10\n\ndata:  Residuals\nLM test = 85.459, df = 10, p-value = 4.237e-14\n\n\nLe mod√®le 3 inclut une variable de temps pour capturer la tendance d√©terministe. Cela permet de mod√©liser explicitement les effets de la tendance dans les donn√©es et peut aider √† r√©duire l‚Äôautocorr√©lation dans les r√©sidus."
  },
  {
    "objectID": "posts/post-with-code/memoire/memoire_m1.html#mod√®le-3-index-temporel",
    "href": "posts/post-with-code/memoire/memoire_m1.html#mod√®le-3-index-temporel",
    "title": "M√©moire",
    "section": "3. Mod√®le 3 index temporel",
    "text": "3. Mod√®le 3 index temporel\n\n# Ajout d'un index temporel\nst3_data &lt;- st2_data\nst3_data$time &lt;- 1:nrow(st3_data)\n\n# Mod√®le de r√©gression avec la variable de temps\nmodele1_3 &lt;- lm(IPA ~ CDD +  importations + exportations +  petrole +  taux_change + SMIC + precipitation + temperature+ time, data = st3_data)\nsummary(modele1_3)\n\n\nCall:\nlm(formula = IPA ~ CDD + importations + exportations + petrole + \n    taux_change + SMIC + precipitation + temperature + time, \n    data = st3_data)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.051688 -0.013833 -0.002295  0.010354  0.074510 \n\nCoefficients:\n                Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)    3.707e-02  2.287e-02   1.621 0.106247    \nCDD            3.555e-04  1.019e-03   0.349 0.727494    \nimportations   4.968e-05  8.887e-05   0.559 0.576620    \nexportations   2.756e-04  9.090e-05   3.032 0.002672 ** \npetrole        8.462e-04  2.250e-04   3.760 0.000209 ***\ntaux_change    4.474e-02  1.099e-02   4.073 6.14e-05 ***\nSMIC          -4.162e-05  5.672e-05  -0.734 0.463764    \nprecipitation -2.047e-04  9.248e-05  -2.214 0.027695 *  \ntemperature   -9.079e-04  3.847e-03  -0.236 0.813582    \ntime          -7.058e-05  3.009e-05  -2.346 0.019739 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.02133 on 265 degrees of freedom\nMultiple R-squared:   0.13, Adjusted R-squared:  0.1004 \nF-statistic:   4.4 on 9 and 265 DF,  p-value: 2.248e-05\n\nmodele0_3 &lt;- (lm((IPA)~1,data=st3_data))\nsummary(modele0_3)\n\n\nCall:\nlm(formula = (IPA) ~ 1, data = st3_data)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.060967 -0.014968 -0.002519  0.011062  0.082152 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 0.008686   0.001356   6.403 6.58e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.02249 on 274 degrees of freedom\n\n### M√©thode ascendante\nstep(modele0_3, scope=list(lower=modele0_3, upper=modele1_3), data=st3_data, direction=\"forward\")\n\nStart:  AIC=-2085.99\n(IPA) ~ 1\n\n                Df Sum of Sq     RSS     AIC\n+ taux_change    1 0.0035569 0.13508 -2091.1\n+ precipitation  1 0.0032765 0.13536 -2090.6\n+ petrole        1 0.0027049 0.13593 -2089.4\n+ exportations   1 0.0016087 0.13703 -2087.2\n+ CDD            1 0.0015048 0.13713 -2087.0\n&lt;none&gt;                       0.13864 -2086.0\n+ importations   1 0.0004699 0.13817 -2084.9\n+ temperature    1 0.0001474 0.13849 -2084.3\n+ SMIC           1 0.0001195 0.13852 -2084.2\n+ time           1 0.0000569 0.13858 -2084.1\n\nStep:  AIC=-2091.13\n(IPA) ~ taux_change\n\n                Df Sum of Sq     RSS     AIC\n+ petrole        1 0.0054703 0.12961 -2100.5\n+ precipitation  1 0.0033626 0.13172 -2096.1\n+ CDD            1 0.0016667 0.13341 -2092.6\n+ exportations   1 0.0014833 0.13359 -2092.2\n&lt;none&gt;                       0.13508 -2091.1\n+ importations   1 0.0005565 0.13452 -2090.3\n+ SMIC           1 0.0003469 0.13473 -2089.8\n+ temperature    1 0.0000998 0.13498 -2089.3\n+ time           1 0.0000143 0.13506 -2089.2\n\nStep:  AIC=-2100.5\n(IPA) ~ taux_change + petrole\n\n                Df Sum of Sq     RSS     AIC\n+ precipitation  1 0.0041454 0.12546 -2107.4\n+ CDD            1 0.0017392 0.12787 -2102.2\n+ exportations   1 0.0016606 0.12795 -2102.1\n&lt;none&gt;                       0.12961 -2100.5\n+ importations   1 0.0003904 0.12922 -2099.3\n+ SMIC           1 0.0003829 0.12923 -2099.3\n+ temperature    1 0.0002855 0.12932 -2099.1\n+ time           1 0.0000179 0.12959 -2098.5\n\nStep:  AIC=-2107.44\n(IPA) ~ taux_change + petrole + precipitation\n\n               Df  Sum of Sq     RSS     AIC\n+ exportations  1 0.00135287 0.12411 -2108.4\n&lt;none&gt;                       0.12546 -2107.4\n+ importations  1 0.00026866 0.12519 -2106.0\n+ temperature   1 0.00019464 0.12527 -2105.9\n+ SMIC          1 0.00016345 0.12530 -2105.8\n+ CDD           1 0.00004282 0.12542 -2105.5\n+ time          1 0.00000487 0.12546 -2105.4\n\nStep:  AIC=-2108.42\n(IPA) ~ taux_change + petrole + precipitation + exportations\n\n               Df  Sum of Sq     RSS     AIC\n+ time          1 0.00300963 0.12110 -2113.2\n&lt;none&gt;                       0.12411 -2108.4\n+ temperature   1 0.00062530 0.12348 -2107.8\n+ importations  1 0.00023504 0.12387 -2106.9\n+ SMIC          1 0.00020702 0.12390 -2106.9\n+ CDD           1 0.00000092 0.12411 -2106.4\n\nStep:  AIC=-2113.17\n(IPA) ~ taux_change + petrole + precipitation + exportations + \n    time\n\n               Df  Sum of Sq     RSS     AIC\n&lt;none&gt;                       0.12110 -2113.2\n+ SMIC          1 2.6657e-04 0.12083 -2111.8\n+ importations  1 1.3613e-04 0.12096 -2111.5\n+ CDD           1 6.2070e-05 0.12104 -2111.3\n+ temperature   1 3.7371e-05 0.12106 -2111.3\n\n\n\nCall:\nlm(formula = (IPA) ~ taux_change + petrole + precipitation + \n    exportations + time, data = st3_data)\n\nCoefficients:\n  (Intercept)    taux_change        petrole  precipitation   exportations  \n    3.606e-02      4.359e-02      8.601e-04     -2.207e-04      2.781e-04  \n         time  \n   -7.182e-05  \n\n### M√©thode descendante\nstep(modele1_3,data=st3_data,direction=\"backward\")\n\nStart:  AIC=-2106.28\nIPA ~ CDD + importations + exportations + petrole + taux_change + \n    SMIC + precipitation + temperature + time\n\n                Df Sum of Sq     RSS     AIC\n- temperature    1 0.0000254 0.12064 -2108.2\n- CDD            1 0.0000554 0.12067 -2108.2\n- importations   1 0.0001422 0.12076 -2108.0\n- SMIC           1 0.0002450 0.12086 -2107.7\n&lt;none&gt;                       0.12061 -2106.3\n- precipitation  1 0.0022306 0.12284 -2103.2\n- time           1 0.0025039 0.12312 -2102.6\n- exportations   1 0.0041834 0.12480 -2098.9\n- petrole        1 0.0064351 0.12705 -2094.0\n- taux_change    1 0.0075490 0.12816 -2091.6\n\nStep:  AIC=-2108.22\nIPA ~ CDD + importations + exportations + petrole + taux_change + \n    SMIC + precipitation + time\n\n                Df Sum of Sq     RSS     AIC\n- CDD            1 0.0000503 0.12069 -2110.1\n- importations   1 0.0001542 0.12079 -2109.9\n- SMIC           1 0.0002519 0.12089 -2109.7\n&lt;none&gt;                       0.12064 -2108.2\n- precipitation  1 0.0023802 0.12302 -2104.8\n- time           1 0.0030165 0.12366 -2103.4\n- exportations   1 0.0043266 0.12497 -2100.5\n- petrole        1 0.0065290 0.12717 -2095.7\n- taux_change    1 0.0075587 0.12820 -2093.5\n\nStep:  AIC=-2110.11\nIPA ~ importations + exportations + petrole + taux_change + SMIC + \n    precipitation + time\n\n                Df Sum of Sq     RSS     AIC\n- importations   1 0.0001447 0.12083 -2111.8\n- SMIC           1 0.0002752 0.12096 -2111.5\n&lt;none&gt;                       0.12069 -2110.1\n- time           1 0.0029679 0.12366 -2105.4\n- precipitation  1 0.0040219 0.12471 -2103.1\n- exportations   1 0.0043276 0.12502 -2102.4\n- petrole        1 0.0065981 0.12729 -2097.5\n- taux_change    1 0.0075334 0.12822 -2095.5\n\nStep:  AIC=-2111.78\nIPA ~ exportations + petrole + taux_change + SMIC + precipitation + \n    time\n\n                Df Sum of Sq     RSS     AIC\n- SMIC           1 0.0002666 0.12110 -2113.2\n&lt;none&gt;                       0.12083 -2111.8\n- time           1 0.0030692 0.12390 -2106.9\n- precipitation  1 0.0041255 0.12496 -2104.6\n- exportations   1 0.0044615 0.12529 -2103.8\n- petrole        1 0.0067392 0.12757 -2098.9\n- taux_change    1 0.0075131 0.12835 -2097.2\n\nStep:  AIC=-2113.17\nIPA ~ exportations + petrole + taux_change + precipitation + \n    time\n\n                Df Sum of Sq     RSS     AIC\n&lt;none&gt;                       0.12110 -2113.2\n- time           1 0.0030096 0.12411 -2108.4\n- exportations   1 0.0043576 0.12546 -2105.4\n- precipitation  1 0.0043997 0.12550 -2105.4\n- petrole        1 0.0067228 0.12782 -2100.3\n- taux_change    1 0.0072794 0.12838 -2099.1\n\n\n\nCall:\nlm(formula = IPA ~ exportations + petrole + taux_change + precipitation + \n    time, data = st3_data)\n\nCoefficients:\n  (Intercept)   exportations        petrole    taux_change  precipitation  \n    3.606e-02      2.781e-04      8.601e-04      4.359e-02     -2.207e-04  \n         time  \n   -7.182e-05  \n\n### M√©thode double\n#m√©thode dans les 2 sens\nstep(modele0_3,scope=list(upper=modele1_3),data=st3_data,direction=\"both\")\n\nStart:  AIC=-2085.99\n(IPA) ~ 1\n\n                Df Sum of Sq     RSS     AIC\n+ taux_change    1 0.0035569 0.13508 -2091.1\n+ precipitation  1 0.0032765 0.13536 -2090.6\n+ petrole        1 0.0027049 0.13593 -2089.4\n+ exportations   1 0.0016087 0.13703 -2087.2\n+ CDD            1 0.0015048 0.13713 -2087.0\n&lt;none&gt;                       0.13864 -2086.0\n+ importations   1 0.0004699 0.13817 -2084.9\n+ temperature    1 0.0001474 0.13849 -2084.3\n+ SMIC           1 0.0001195 0.13852 -2084.2\n+ time           1 0.0000569 0.13858 -2084.1\n\nStep:  AIC=-2091.13\n(IPA) ~ taux_change\n\n                Df Sum of Sq     RSS     AIC\n+ petrole        1 0.0054703 0.12961 -2100.5\n+ precipitation  1 0.0033626 0.13172 -2096.1\n+ CDD            1 0.0016667 0.13341 -2092.6\n+ exportations   1 0.0014833 0.13359 -2092.2\n&lt;none&gt;                       0.13508 -2091.1\n+ importations   1 0.0005565 0.13452 -2090.3\n+ SMIC           1 0.0003469 0.13473 -2089.8\n+ temperature    1 0.0000998 0.13498 -2089.3\n+ time           1 0.0000143 0.13506 -2089.2\n- taux_change    1 0.0035569 0.13864 -2086.0\n\nStep:  AIC=-2100.5\n(IPA) ~ taux_change + petrole\n\n                Df Sum of Sq     RSS     AIC\n+ precipitation  1 0.0041454 0.12546 -2107.4\n+ CDD            1 0.0017392 0.12787 -2102.2\n+ exportations   1 0.0016606 0.12795 -2102.1\n&lt;none&gt;                       0.12961 -2100.5\n+ importations   1 0.0003904 0.12922 -2099.3\n+ SMIC           1 0.0003829 0.12923 -2099.3\n+ temperature    1 0.0002855 0.12932 -2099.1\n+ time           1 0.0000179 0.12959 -2098.5\n- petrole        1 0.0054703 0.13508 -2091.1\n- taux_change    1 0.0063223 0.13593 -2089.4\n\nStep:  AIC=-2107.44\n(IPA) ~ taux_change + petrole + precipitation\n\n                Df Sum of Sq     RSS     AIC\n+ exportations   1 0.0013529 0.12411 -2108.4\n&lt;none&gt;                       0.12546 -2107.4\n+ importations   1 0.0002687 0.12519 -2106.0\n+ temperature    1 0.0001946 0.12527 -2105.9\n+ SMIC           1 0.0001635 0.12530 -2105.8\n+ CDD            1 0.0000428 0.12542 -2105.5\n+ time           1 0.0000049 0.12546 -2105.4\n- precipitation  1 0.0041454 0.12961 -2100.5\n- petrole        1 0.0062530 0.13172 -2096.1\n- taux_change    1 0.0067044 0.13217 -2095.1\n\nStep:  AIC=-2108.42\n(IPA) ~ taux_change + petrole + precipitation + exportations\n\n                Df Sum of Sq     RSS     AIC\n+ time           1 0.0030096 0.12110 -2113.2\n&lt;none&gt;                       0.12411 -2108.4\n+ temperature    1 0.0006253 0.12348 -2107.8\n- exportations   1 0.0013529 0.12546 -2107.4\n+ importations   1 0.0002350 0.12387 -2106.9\n+ SMIC           1 0.0002070 0.12390 -2106.9\n+ CDD            1 0.0000009 0.12411 -2106.4\n- precipitation  1 0.0038376 0.12795 -2102.1\n- petrole        1 0.0063937 0.13050 -2096.6\n- taux_change    1 0.0065890 0.13070 -2096.2\n\nStep:  AIC=-2113.17\n(IPA) ~ taux_change + petrole + precipitation + exportations + \n    time\n\n                Df Sum of Sq     RSS     AIC\n&lt;none&gt;                       0.12110 -2113.2\n+ SMIC           1 0.0002666 0.12083 -2111.8\n+ importations   1 0.0001361 0.12096 -2111.5\n+ CDD            1 0.0000621 0.12104 -2111.3\n+ temperature    1 0.0000374 0.12106 -2111.3\n- time           1 0.0030096 0.12411 -2108.4\n- exportations   1 0.0043576 0.12546 -2105.4\n- precipitation  1 0.0043997 0.12550 -2105.4\n- petrole        1 0.0067228 0.12782 -2100.3\n- taux_change    1 0.0072794 0.12838 -2099.1\n\n\n\nCall:\nlm(formula = (IPA) ~ taux_change + petrole + precipitation + \n    exportations + time, data = st3_data)\n\nCoefficients:\n  (Intercept)    taux_change        petrole  precipitation   exportations  \n    3.606e-02      4.359e-02      8.601e-04     -2.207e-04      2.781e-04  \n         time  \n   -7.182e-05  \n\n# modele 3 \nlm_model3 &lt;- lm(formula = (IPA) ~ taux_change + petrole + precipitation + \n    exportations + time, data = st3_data)\n\nsummary(lm_model3)\n\n\nCall:\nlm(formula = (IPA) ~ taux_change + petrole + precipitation + \n    exportations + time, data = st3_data)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.052038 -0.013781 -0.002281  0.010896  0.074264 \n\nCoefficients:\n                Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)    3.606e-02  1.088e-02   3.313  0.00105 ** \ntaux_change    4.359e-02  1.084e-02   4.021 7.53e-05 ***\npetrole        8.601e-04  2.226e-04   3.864  0.00014 ***\nprecipitation -2.207e-04  7.061e-05  -3.126  0.00197 ** \nexportations   2.781e-04  8.938e-05   3.111  0.00206 ** \ntime          -7.182e-05  2.778e-05  -2.586  0.01025 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.02122 on 269 degrees of freedom\nMultiple R-squared:  0.1265,    Adjusted R-squared:  0.1102 \nF-statistic:  7.79 on 5 and 269 DF,  p-value: 7.282e-07\n\n## TESTS \nresidus3 &lt;- residuals(lm_model3)\n# Test de normalit√© des r√©sidus\nks.test(residus3, \"pnorm\", mean = mean(residus3), sd = sd(residus3))\n\n\n    Asymptotic one-sample Kolmogorov-Smirnov test\n\ndata:  residus3\nD = 0.066946, p-value = 0.1699\nalternative hypothesis: two-sided\n\nreset(lm_model3)\n\n\n    RESET test\n\ndata:  lm_model3\nRESET = 0.67732, df1 = 2, df2 = 267, p-value = 0.5088\n\nbptest(lm_model3)\n\n\n    studentized Breusch-Pagan test\n\ndata:  lm_model3\nBP = 4.4605, df = 5, p-value = 0.4852\n\nvif(lm_model3)\n\n  taux_change       petrole precipitation  exportations          time \n     1.113852      1.114739      1.018312      2.945289      2.970363 \n\ncheckresiduals(lm_model3)\n\n\n\n\n\n\n\n\n\n    Breusch-Godfrey test for serial correlation of order up to 10\n\ndata:  Residuals\nLM test = 80.408, df = 10, p-value = 4.177e-13"
  },
  {
    "objectID": "posts/post-with-code/memoire/memoire_m1.html#mod√®le-4-tendance-d√©terministe-corrig√©e",
    "href": "posts/post-with-code/memoire/memoire_m1.html#mod√®le-4-tendance-d√©terministe-corrig√©e",
    "title": "M√©moire",
    "section": "4. Mod√®le 4 tendance d√©terministe corrig√©e",
    "text": "4. Mod√®le 4 tendance d√©terministe corrig√©e\n\n# Fonction pour corriger la tendance d√©terministe par r√©gression\ncorrect_trend &lt;- function(series) {\n  model &lt;- lm(series ~ time(series))\n  residuals(model)\n}\n# Appliquer la correction √† chaque variable explicative\nfor (var in variables) {\n  # Corriger la tendance d√©terministe\n  corrected_series &lt;- correct_trend(stationnaire_data[[var]])\n  # Ajouter les s√©ries corrig√©es au data frame\n  stationnaire_data[[paste(var, \"detrended\", sep = \"_\")]] &lt;- corrected_series\n}\n\n# Affiche la structure du data frame pour v√©rifier les changements\nstr(stationnaire_data)\n\n'data.frame':   275 obs. of  19 variables:\n $ Date                   : Date, format: \"2000-02-01\" \"2000-03-01\" ...\n $ IPA                    : Time-Series  from 2000 to 2023: -2.23 -3.11 -1.59 1.21 6.55 ...\n $ CDD                    : num  8.96 9.14 8.56 11.97 9.15 ...\n $ importations           : Time-Series  from 2000 to 2023: 33.3 -11.7 11.7 14.4 -14 ...\n $ exportations           : num  28.264 -0.125 -2.771 -2.666 7.89 ...\n $ petrole                : Time-Series  from 2000 to 2023: 2.26 -0.29 -4.72 4.97 2.06 ...\n $ taux_change            : Time-Series  from 2000 to 2023: -0.0284 -0.0333 0.0262 0.0597 -0.0196 ...\n $ SMIC                   : num  136 136 151 151 151 151 151 151 151 151 ...\n $ precipitation          : num  163 156 166 135 149 ...\n $ temperature            : num  0.447 0.32 0.527 0.686 0.978 ...\n $ IPA_detrended          : num  -0.267 -1.206 0.25 2.974 8.256 ...\n $ CDD_detrended          : num  -0.426 -0.249 -0.837 2.571 -0.256 ...\n $ precipitation_detrended: num  14.137 6.864 16.623 -13.624 -0.338 ...\n $ temperature_detrended  : num  -0.337 -0.466 -0.261 -0.104 0.185 ...\n $ exportations_detrended : num  12.15 -16.49 -19.39 -19.53 -9.23 ...\n $ importations_detrended : num  32.9 -12.1 11.2 14 -14.5 ...\n $ taux_change_detrended  : num  -0.0273 -0.0323 0.0271 0.0605 -0.0189 ...\n $ SMIC_detrended         : num  -8.06 -8.06 6.94 6.93 6.93 ...\n $ petrole_detrended      : num  1.798 -0.754 -5.185 4.512 1.599 ...\n\n# Modele avec toutes les variables, ne sera pas utilis√© dans notre analyse - voir m√©thode STEP\nmodele1_4 &lt;- lm(IPA_detrended ~  CDD_detrended +  importations_detrended + exportations_detrended +  petrole_detrended +    taux_change_detrended + SMIC_detrended + precipitation_detrended + temperature_detrended, data=stationnaire_data)\n\nsummary(modele1_4)\n\n\nCall:\nlm(formula = IPA_detrended ~ CDD_detrended + importations_detrended + \n    exportations_detrended + petrole_detrended + taux_change_detrended + \n    SMIC_detrended + precipitation_detrended + temperature_detrended, \n    data = stationnaire_data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-62.864  -9.706  -1.702   7.561 114.563 \n\nCoefficients:\n                          Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)             -1.012e-15  1.212e+00   0.000 1.000000    \nCDD_detrended            1.695e+00  9.600e-01   1.766 0.078523 .  \nimportations_detrended   4.707e-02  8.372e-02   0.562 0.574421    \nexportations_detrended   2.455e-01  8.563e-02   2.867 0.004473 ** \npetrole_detrended        7.605e-01  2.120e-01   3.587 0.000398 ***\ntaux_change_detrended    2.122e+01  1.035e+01   2.051 0.041281 *  \nSMIC_detrended           4.563e-03  5.344e-02   0.085 0.932022    \nprecipitation_detrended -1.660e-01  8.712e-02  -1.906 0.057771 .  \ntemperature_detrended   -1.038e+00  3.624e+00  -0.286 0.774761    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 20.1 on 266 degrees of freedom\nMultiple R-squared:  0.1187,    Adjusted R-squared:  0.09224 \nF-statistic:  4.48 on 8 and 266 DF,  p-value: 4.064e-05\n\n# Step : SeÃÅlection des variables explicatives significatives (modeÃÄle lineÃÅaire = modele1_4 )\n\nmodele0_4 &lt;- (lm(IPA_detrended~1,data=stationnaire_data))\nsummary(modele0_4)\n\n\nCall:\nlm(formula = IPA_detrended ~ 1, data = stationnaire_data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-69.567  -8.942  -0.549   6.833 125.527 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept) -7.465e-16  1.272e+00       0        1\n\nResidual standard error: 21.1 on 274 degrees of freedom\n\n### M√©thode ascendante\n step(modele0_4, scope=list(lower=modele0_4, upper=modele1_4), data=stationnaire_data, direction=\"forward\")\n\nStart:  AIC=1677.97\nIPA_detrended ~ 1\n\n                          Df Sum of Sq    RSS    AIC\n+ CDD_detrended            1    4317.9 117613 1670.0\n+ precipitation_detrended  1    4045.9 117885 1670.7\n+ petrole_detrended        1    3518.3 118412 1671.9\n+ exportations_detrended   1    2899.2 119031 1673.3\n&lt;none&gt;                                 121931 1678.0\n+ importations_detrended   1     433.1 121497 1679.0\n+ temperature_detrended    1     225.7 121705 1679.5\n+ taux_change_detrended    1     207.7 121723 1679.5\n+ SMIC_detrended           1       9.6 121921 1680.0\n\nStep:  AIC=1670.05\nIPA_detrended ~ CDD_detrended\n\n                          Df Sum of Sq    RSS    AIC\n+ petrole_detrended        1    3471.6 114141 1663.8\n+ exportations_detrended   1    3054.7 114558 1664.8\n+ precipitation_detrended  1    1049.9 116563 1669.6\n&lt;none&gt;                                 117613 1670.0\n+ importations_detrended   1     483.1 117130 1670.9\n+ taux_change_detrended    1     319.6 117293 1671.3\n+ SMIC_detrended           1      39.6 117573 1672.0\n+ temperature_detrended    1      31.3 117581 1672.0\n\nStep:  AIC=1663.82\nIPA_detrended ~ CDD_detrended + petrole_detrended\n\n                          Df Sum of Sq    RSS    AIC\n+ exportations_detrended   1    3241.0 110900 1657.9\n+ precipitation_detrended  1    1445.8 112695 1662.3\n+ taux_change_detrended    1    1428.6 112712 1662.3\n&lt;none&gt;                                 114141 1663.8\n+ importations_detrended   1     343.1 113798 1665.0\n+ SMIC_detrended           1      61.4 114080 1665.7\n+ temperature_detrended    1       0.3 114141 1665.8\n\nStep:  AIC=1657.89\nIPA_detrended ~ CDD_detrended + petrole_detrended + exportations_detrended\n\n                          Df Sum of Sq    RSS    AIC\n+ taux_change_detrended    1   1675.90 109224 1655.7\n+ precipitation_detrended  1   1537.52 109362 1656.0\n&lt;none&gt;                                 110900 1657.9\n+ importations_detrended   1    212.47 110688 1659.4\n+ temperature_detrended    1     59.16 110841 1659.8\n+ SMIC_detrended           1     26.57 110873 1659.8\n\nStep:  AIC=1655.71\nIPA_detrended ~ CDD_detrended + petrole_detrended + exportations_detrended + \n    taux_change_detrended\n\n                          Df Sum of Sq    RSS    AIC\n+ precipitation_detrended  1   1595.97 107628 1653.7\n&lt;none&gt;                                 109224 1655.7\n+ importations_detrended   1    225.71 108998 1657.1\n+ temperature_detrended    1     66.05 109158 1657.5\n+ SMIC_detrended           1      0.05 109224 1657.7\n\nStep:  AIC=1653.66\nIPA_detrended ~ CDD_detrended + petrole_detrended + exportations_detrended + \n    taux_change_detrended + precipitation_detrended\n\n                         Df Sum of Sq    RSS    AIC\n&lt;none&gt;                                107628 1653.7\n+ importations_detrended  1   141.110 107487 1655.3\n+ temperature_detrended   1    44.973 107583 1655.5\n+ SMIC_detrended          1     2.829 107625 1655.7\n\n\n\nCall:\nlm(formula = IPA_detrended ~ CDD_detrended + petrole_detrended + \n    exportations_detrended + taux_change_detrended + precipitation_detrended, \n    data = stationnaire_data)\n\nCoefficients:\n            (Intercept)            CDD_detrended        petrole_detrended  \n             -1.146e-15                1.636e+00                7.729e-01  \n exportations_detrended    taux_change_detrended  precipitation_detrended  \n              2.524e-01                2.129e+01               -1.605e-01  \n\n### M√©thode descendante\nstep(modele1_4,data=stationnaire_data,direction=\"backward\")\n\nStart:  AIC=1659.21\nIPA_detrended ~ CDD_detrended + importations_detrended + exportations_detrended + \n    petrole_detrended + taux_change_detrended + SMIC_detrended + \n    precipitation_detrended + temperature_detrended\n\n                          Df Sum of Sq    RSS    AIC\n- SMIC_detrended           1       2.9 107455 1657.2\n- temperature_detrended    1      33.1 107485 1657.3\n- importations_detrended   1     127.7 107579 1657.5\n&lt;none&gt;                                 107452 1659.2\n- CDD_detrended            1    1260.0 108712 1660.4\n- precipitation_detrended  1    1467.0 108919 1660.9\n- taux_change_detrended    1    1698.7 109150 1661.5\n- exportations_detrended   1    3320.8 110772 1665.6\n- petrole_detrended        1    5198.2 112650 1670.2\n\nStep:  AIC=1657.21\nIPA_detrended ~ CDD_detrended + importations_detrended + exportations_detrended + \n    petrole_detrended + taux_change_detrended + precipitation_detrended + \n    temperature_detrended\n\n                          Df Sum of Sq    RSS    AIC\n- temperature_detrended    1      32.4 107487 1655.3\n- importations_detrended   1     128.5 107583 1655.5\n&lt;none&gt;                                 107455 1657.2\n- CDD_detrended            1    1259.7 108714 1658.4\n- precipitation_detrended  1    1464.1 108919 1658.9\n- taux_change_detrended    1    1741.0 109196 1659.6\n- exportations_detrended   1    3342.6 110797 1663.6\n- petrole_detrended        1    5202.0 112657 1668.2\n\nStep:  AIC=1655.3\nIPA_detrended ~ CDD_detrended + importations_detrended + exportations_detrended + \n    petrole_detrended + taux_change_detrended + precipitation_detrended\n\n                          Df Sum of Sq    RSS    AIC\n- importations_detrended   1     141.1 107628 1653.7\n&lt;none&gt;                                 107487 1655.3\n- CDD_detrended            1    1237.9 108725 1656.5\n- precipitation_detrended  1    1511.4 108998 1657.1\n- taux_change_detrended    1    1743.6 109231 1657.7\n- exportations_detrended   1    3471.1 110958 1662.0\n- petrole_detrended        1    5289.5 112777 1666.5\n\nStep:  AIC=1653.66\nIPA_detrended ~ CDD_detrended + exportations_detrended + petrole_detrended + \n    taux_change_detrended + precipitation_detrended\n\n                          Df Sum of Sq    RSS    AIC\n&lt;none&gt;                                 107628 1653.7\n- CDD_detrended            1    1193.2 108821 1654.7\n- precipitation_detrended  1    1596.0 109224 1655.7\n- taux_change_detrended    1    1734.3 109362 1656.0\n- exportations_detrended   1    3589.6 111218 1660.7\n- petrole_detrended        1    5419.0 113047 1665.2\n\n\n\nCall:\nlm(formula = IPA_detrended ~ CDD_detrended + exportations_detrended + \n    petrole_detrended + taux_change_detrended + precipitation_detrended, \n    data = stationnaire_data)\n\nCoefficients:\n            (Intercept)            CDD_detrended   exportations_detrended  \n             -1.146e-15                1.636e+00                2.524e-01  \n      petrole_detrended    taux_change_detrended  precipitation_detrended  \n              7.729e-01                2.129e+01               -1.605e-01  \n\n### M√©thode double\n#m√©thode dans les 2 sens\nstep(modele0_4,scope=list(upper=modele1_4),data=stationnaire_data,direction=\"both\")\n\nStart:  AIC=1677.97\nIPA_detrended ~ 1\n\n                          Df Sum of Sq    RSS    AIC\n+ CDD_detrended            1    4317.9 117613 1670.0\n+ precipitation_detrended  1    4045.9 117885 1670.7\n+ petrole_detrended        1    3518.3 118412 1671.9\n+ exportations_detrended   1    2899.2 119031 1673.3\n&lt;none&gt;                                 121931 1678.0\n+ importations_detrended   1     433.1 121497 1679.0\n+ temperature_detrended    1     225.7 121705 1679.5\n+ taux_change_detrended    1     207.7 121723 1679.5\n+ SMIC_detrended           1       9.6 121921 1680.0\n\nStep:  AIC=1670.05\nIPA_detrended ~ CDD_detrended\n\n                          Df Sum of Sq    RSS    AIC\n+ petrole_detrended        1    3471.6 114141 1663.8\n+ exportations_detrended   1    3054.7 114558 1664.8\n+ precipitation_detrended  1    1049.9 116563 1669.6\n&lt;none&gt;                                 117613 1670.0\n+ importations_detrended   1     483.1 117130 1670.9\n+ taux_change_detrended    1     319.6 117293 1671.3\n+ SMIC_detrended           1      39.6 117573 1672.0\n+ temperature_detrended    1      31.3 117581 1672.0\n- CDD_detrended            1    4317.9 121931 1678.0\n\nStep:  AIC=1663.82\nIPA_detrended ~ CDD_detrended + petrole_detrended\n\n                          Df Sum of Sq    RSS    AIC\n+ exportations_detrended   1    3241.0 110900 1657.9\n+ precipitation_detrended  1    1445.8 112695 1662.3\n+ taux_change_detrended    1    1428.6 112712 1662.3\n&lt;none&gt;                                 114141 1663.8\n+ importations_detrended   1     343.1 113798 1665.0\n+ SMIC_detrended           1      61.4 114080 1665.7\n+ temperature_detrended    1       0.3 114141 1665.8\n- petrole_detrended        1    3471.6 117613 1670.0\n- CDD_detrended            1    4271.3 118412 1671.9\n\nStep:  AIC=1657.89\nIPA_detrended ~ CDD_detrended + petrole_detrended + exportations_detrended\n\n                          Df Sum of Sq    RSS    AIC\n+ taux_change_detrended    1    1675.9 109224 1655.7\n+ precipitation_detrended  1    1537.5 109362 1656.0\n&lt;none&gt;                                 110900 1657.9\n+ importations_detrended   1     212.5 110688 1659.4\n+ temperature_detrended    1      59.2 110841 1659.8\n+ SMIC_detrended           1      26.6 110873 1659.8\n- exportations_detrended   1    3241.0 114141 1663.8\n- petrole_detrended        1    3658.0 114558 1664.8\n- CDD_detrended            1    4429.5 115330 1666.7\n\nStep:  AIC=1655.71\nIPA_detrended ~ CDD_detrended + petrole_detrended + exportations_detrended + \n    taux_change_detrended\n\n                          Df Sum of Sq    RSS    AIC\n+ precipitation_detrended  1    1596.0 107628 1653.7\n&lt;none&gt;                                 109224 1655.7\n+ importations_detrended   1     225.7 108998 1657.1\n+ temperature_detrended    1      66.0 109158 1657.5\n+ SMIC_detrended           1       0.0 109224 1657.7\n- taux_change_detrended    1    1675.9 110900 1657.9\n- exportations_detrended   1    3488.4 112712 1662.3\n- CDD_detrended            1    4716.8 113941 1665.3\n- petrole_detrended        1    4923.0 114147 1665.8\n\nStep:  AIC=1653.66\nIPA_detrended ~ CDD_detrended + petrole_detrended + exportations_detrended + \n    taux_change_detrended + precipitation_detrended\n\n                          Df Sum of Sq    RSS    AIC\n&lt;none&gt;                                 107628 1653.7\n- CDD_detrended            1    1193.2 108821 1654.7\n+ importations_detrended   1     141.1 107487 1655.3\n+ temperature_detrended    1      45.0 107583 1655.5\n+ SMIC_detrended           1       2.8 107625 1655.7\n- precipitation_detrended  1    1596.0 109224 1655.7\n- taux_change_detrended    1    1734.3 109362 1656.0\n- exportations_detrended   1    3589.6 111218 1660.7\n- petrole_detrended        1    5419.0 113047 1665.2\n\n\n\nCall:\nlm(formula = IPA_detrended ~ CDD_detrended + petrole_detrended + \n    exportations_detrended + taux_change_detrended + precipitation_detrended, \n    data = stationnaire_data)\n\nCoefficients:\n            (Intercept)            CDD_detrended        petrole_detrended  \n             -1.146e-15                1.636e+00                7.729e-01  \n exportations_detrended    taux_change_detrended  precipitation_detrended  \n              2.524e-01                2.129e+01               -1.605e-01  \n\n# 1. MCO modele retenue\nlm_model4&lt;-  lm(formula = IPA_detrended ~ CDD_detrended + petrole_detrended + \n    exportations_detrended + taux_change_detrended + precipitation_detrended, \n    data = stationnaire_data)\nsummary(lm_model4)\n\n\nCall:\nlm(formula = IPA_detrended ~ CDD_detrended + petrole_detrended + \n    exportations_detrended + taux_change_detrended + precipitation_detrended, \n    data = stationnaire_data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-61.876  -9.716  -1.679   7.230 114.837 \n\nCoefficients:\n                          Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)             -1.146e-15  1.206e+00   0.000 1.000000    \nCDD_detrended            1.636e+00  9.472e-01   1.727 0.085330 .  \npetrole_detrended        7.729e-01  2.100e-01   3.680 0.000282 ***\nexportations_detrended   2.524e-01  8.427e-02   2.995 0.002998 ** \ntaux_change_detrended    2.129e+01  1.022e+01   2.082 0.038288 *  \nprecipitation_detrended -1.605e-01  8.034e-02  -1.997 0.046809 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 20 on 269 degrees of freedom\nMultiple R-squared:  0.1173,    Adjusted R-squared:  0.1009 \nF-statistic: 7.149 on 5 and 269 DF,  p-value: 2.673e-06\n\n## Hypotheses\n#### Test de normalit√© des r√©sidus\n# R√©sidus\nresidus4 &lt;- residuals(lm_model4)\n# Test de normalit√© des r√©sidus\nks.test(residus4, \"pnorm\", mean = mean(residus4), sd = sd(residus4))\n\n\n    Asymptotic one-sample Kolmogorov-Smirnov test\n\ndata:  residus4\nD = 0.10967, p-value = 0.002679\nalternative hypothesis: two-sided\n\n# Test de Breusch-Pagan pour l'h√©t√©rosc√©dasticit√©\nbptest(lm_model4)\n\n\n    studentized Breusch-Pagan test\n\ndata:  lm_model4\nBP = 8.9646, df = 5, p-value = 0.1105\n\n# Test RESET\nreset(lm_model4)\n\n\n    RESET test\n\ndata:  lm_model4\nRESET = 0.58521, df1 = 2, df2 = 267, p-value = 0.5577\n\n#### multicollin√©arit√©\nvif(lm_model4)\n\n          CDD_detrended       petrole_detrended  exportations_detrended \n               1.461501                1.116101                1.004650 \n  taux_change_detrended precipitation_detrended \n               1.110756                1.468620 \n\n#### Autocorrelation de r√©sidus\ncheckresiduals(lm_model4)\n\n\n\n\n\n\n\n\n\n    Breusch-Godfrey test for serial correlation of order up to 10\n\ndata:  Residuals\nLM test = 109.32, df = 10, p-value &lt; 2.2e-16"
  },
  {
    "objectID": "posts/post-with-code/memoire/memoire_m1.html#mod√®le-5-avec-lag",
    "href": "posts/post-with-code/memoire/memoire_m1.html#mod√®le-5-avec-lag",
    "title": "M√©moire",
    "section": "5. Mod√®le 5 avec lag",
    "text": "5. Mod√®le 5 avec lag\n\n# Cr√©ation du lag \nst3_data$IPA_lag1 &lt;- stats::lag(st3_data$IPA, 1) \nst3_data$IPA_lag2 &lt;- stats::lag(st3_data$IPA, 2) \n\nst3_data &lt;- na.omit(st3_data)\n\n\n# Mod√®le de r√©gression avec Lag 1 , toutes les variables\nmodele1_5 &lt;- lm(IPA ~ CDD +  importations + exportations +  petrole +  taux_change + SMIC + precipitation + temperature+ IPA_lag1 + IPA_lag2, data = st3_data)\nsummary(modele1_5)\n\nWarning in summary.lm(modele1_5): essentially perfect fit: summary may be\nunreliable\n\n\n\nCall:\nlm(formula = IPA ~ CDD + importations + exportations + petrole + \n    taux_change + SMIC + precipitation + temperature + IPA_lag1 + \n    IPA_lag2, data = st3_data)\n\nResiduals:\n       Min         1Q     Median         3Q        Max \n-1.009e-16 -7.630e-19  3.920e-19  1.385e-18  8.567e-18 \n\nCoefficients: (1 not defined because of singularities)\n                Estimate Std. Error    t value Pr(&gt;|t|)    \n(Intercept)   -1.241e-17  6.989e-18 -1.776e+00  0.07685 .  \nCDD            1.373e-19  3.110e-19  4.410e-01  0.65935    \nimportations  -4.797e-21  2.733e-20 -1.760e-01  0.86081    \nexportations  -2.301e-20  1.720e-20 -1.338e+00  0.18217    \npetrole       -1.954e-19  7.074e-20 -2.762e+00  0.00614 ** \ntaux_change   -7.414e-18  3.458e-18 -2.144e+00  0.03296 *  \nSMIC           7.534e-21  1.744e-20  4.320e-01  0.66615    \nprecipitation  6.107e-20  2.850e-20  2.143e+00  0.03303 *  \ntemperature    5.892e-19  1.116e-18  5.280e-01  0.59807    \nIPA_lag1       1.000e+00  1.869e-17  5.350e+16  &lt; 2e-16 ***\nIPA_lag2              NA         NA         NA       NA    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.559e-18 on 265 degrees of freedom\nMultiple R-squared:      1, Adjusted R-squared:      1 \nF-statistic: 3.581e+32 on 9 and 265 DF,  p-value: &lt; 2.2e-16\n\nmodele0_5 &lt;- (lm((IPA)~1,data=st3_data))\nsummary(modele0_5)\n\n\nCall:\nlm(formula = (IPA) ~ 1, data = st3_data)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.060967 -0.014968 -0.002519  0.011062  0.082152 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 0.008686   0.001356   6.403 6.58e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.02249 on 274 degrees of freedom\n\n### M√©thode ascendante\nstep(modele0_5, scope=list(lower=modele0_5, upper=modele1_5), data=st3_data, direction=\"forward\")\n\nStart:  AIC=-2085.99\n(IPA) ~ 1\n\n                Df Sum of Sq     RSS      AIC\n+ IPA_lag1       1  0.138635 0.00000 -21080.7\n+ IPA_lag2       1  0.138635 0.00000 -21080.7\n+ taux_change    1  0.003557 0.13508  -2091.1\n+ precipitation  1  0.003276 0.13536  -2090.6\n+ petrole        1  0.002705 0.13593  -2089.4\n+ exportations   1  0.001609 0.13703  -2087.2\n+ CDD            1  0.001505 0.13713  -2087.0\n&lt;none&gt;                       0.13864  -2086.0\n+ importations   1  0.000470 0.13817  -2084.9\n+ temperature    1  0.000147 0.13849  -2084.3\n+ SMIC           1  0.000120 0.13852  -2084.2\n\nStep:  AIC=-21080.67\n(IPA) ~ IPA_lag1\n\n\nWarning: attempting model selection on an essentially perfect fit is nonsense\n\n\n                Df  Sum of Sq        RSS    AIC\n+ exportations   1 1.8869e-33 1.3657e-31 -21082\n+ temperature    1 1.3833e-33 1.3707e-31 -21081\n&lt;none&gt;                        1.3845e-31 -21081\n+ importations   1 3.9347e-34 1.3806e-31 -21080\n+ SMIC           1 8.2170e-35 1.3837e-31 -21079\n+ CDD            1 5.1420e-35 1.3840e-31 -21079\n+ precipitation  1 2.0090e-35 1.3844e-31 -21079\n+ taux_change    1 8.1400e-36 1.3845e-31 -21079\n+ petrole        1 2.5000e-36 1.3845e-31 -21079\n\nStep:  AIC=-21082.45\n(IPA) ~ IPA_lag1 + exportations\n\n\nWarning: attempting model selection on an essentially perfect fit is nonsense\n\n\n                Df  Sum of Sq        RSS    AIC\n&lt;none&gt;                        1.3657e-31 -21082\n+ temperature    1 6.9380e-34 1.3587e-31 -21082\n+ importations   1 3.5406e-34 1.3621e-31 -21081\n+ SMIC           1 5.2300e-35 1.3652e-31 -21081\n+ taux_change    1 5.8700e-36 1.3656e-31 -21080\n+ precipitation  1 5.5600e-36 1.3656e-31 -21080\n+ CDD            1 1.5500e-36 1.3657e-31 -21080\n+ petrole        1 5.0000e-37 1.3657e-31 -21080\n\n\n\nCall:\nlm(formula = (IPA) ~ IPA_lag1 + exportations, data = st3_data)\n\nCoefficients:\n (Intercept)      IPA_lag1  exportations  \n  -1.506e-17     1.000e+00     1.072e-19  \n\n### M√©thode descendante\nstep(modele1_5,data=st3_data,direction=\"backward\")\n\nStart:  AIC=-21751.32\nIPA ~ CDD + importations + exportations + petrole + taux_change + \n    SMIC + precipitation + temperature + IPA_lag1 + IPA_lag2\n\n\nWarning: attempting model selection on an essentially perfect fit is nonsense\n\n\n\nStep:  AIC=-21751.32\nIPA ~ CDD + importations + exportations + petrole + taux_change + \n    SMIC + precipitation + temperature + IPA_lag1\n\n\nWarning: attempting model selection on an essentially perfect fit is nonsense\n\n\n                Df Sum of Sq     RSS      AIC\n- temperature    1   0.00000 0.00000 -22202.5\n&lt;none&gt;                       0.00000 -21751.3\n- exportations   1   0.00000 0.00000 -21503.4\n- SMIC           1   0.00000 0.00000 -21332.8\n- taux_change    1   0.00000 0.00000 -21299.5\n- precipitation  1   0.00000 0.00000 -21291.9\n- importations   1   0.00000 0.00000 -21253.2\n- petrole        1   0.00000 0.00000 -21175.4\n- CDD            1   0.00000 0.00000 -21087.1\n- IPA_lag1       1   0.12312 0.12312  -2102.6\n\nStep:  AIC=-22202.49\nIPA ~ CDD + importations + exportations + petrole + taux_change + \n    SMIC + precipitation + IPA_lag1\n\n\nWarning: attempting model selection on an essentially perfect fit is nonsense\n\n\n                Df Sum of Sq     RSS      AIC\n&lt;none&gt;                       0.00000 -22202.5\n- precipitation  1   0.00000 0.00000 -22111.0\n- SMIC           1   0.00000 0.00000 -21726.0\n- CDD            1   0.00000 0.00000 -21712.0\n- taux_change    1   0.00000 0.00000 -21535.4\n- importations   1   0.00000 0.00000 -21210.2\n- petrole        1   0.00000 0.00000 -21164.7\n- exportations   1   0.00000 0.00000 -20815.4\n- IPA_lag1       1   0.12366 0.12366  -2103.4\n\n\n\nCall:\nlm(formula = IPA ~ CDD + importations + exportations + petrole + \n    taux_change + SMIC + precipitation + IPA_lag1, data = st3_data)\n\nCoefficients:\n  (Intercept)            CDD   importations   exportations        petrole  \n    5.633e-18      2.800e-20      1.035e-20      1.892e-20      1.212e-19  \n  taux_change           SMIC  precipitation       IPA_lag1  \n    7.330e-18     -8.519e-21     -2.797e-20      1.000e+00  \n\n### M√©thode double\n#m√©thode dans les 2 sens\nstep(modele0_5,scope=list(upper=modele1_5),data=st3_data,direction=\"both\")\n\nStart:  AIC=-2085.99\n(IPA) ~ 1\n\n                Df Sum of Sq     RSS      AIC\n+ IPA_lag1       1  0.138635 0.00000 -21080.7\n+ IPA_lag2       1  0.138635 0.00000 -21080.7\n+ taux_change    1  0.003557 0.13508  -2091.1\n+ precipitation  1  0.003276 0.13536  -2090.6\n+ petrole        1  0.002705 0.13593  -2089.4\n+ exportations   1  0.001609 0.13703  -2087.2\n+ CDD            1  0.001505 0.13713  -2087.0\n&lt;none&gt;                       0.13864  -2086.0\n+ importations   1  0.000470 0.13817  -2084.9\n+ temperature    1  0.000147 0.13849  -2084.3\n+ SMIC           1  0.000120 0.13852  -2084.2\n\nStep:  AIC=-21080.67\n(IPA) ~ IPA_lag1\n\n\nWarning: attempting model selection on an essentially perfect fit is nonsense\n\n\nWarning: attempting model selection on an essentially perfect fit is nonsense\n\n\n                Df Sum of Sq     RSS    AIC\n+ exportations   1   0.00000 0.00000 -21082\n+ temperature    1   0.00000 0.00000 -21081\n&lt;none&gt;                       0.00000 -21081\n+ importations   1   0.00000 0.00000 -21080\n+ SMIC           1   0.00000 0.00000 -21079\n+ CDD            1   0.00000 0.00000 -21079\n+ precipitation  1   0.00000 0.00000 -21079\n+ taux_change    1   0.00000 0.00000 -21079\n+ petrole        1   0.00000 0.00000 -21079\n- IPA_lag1       1   0.13864 0.13864  -2086\n\nStep:  AIC=-21082.45\n(IPA) ~ IPA_lag1 + exportations\n\n\nWarning: attempting model selection on an essentially perfect fit is nonsense\nWarning: attempting model selection on an essentially perfect fit is nonsense\n\n\n                Df Sum of Sq     RSS      AIC\n&lt;none&gt;                       0.00000 -21082.4\n+ temperature    1   0.00000 0.00000 -21081.8\n+ importations   1   0.00000 0.00000 -21081.2\n- exportations   1   0.00000 0.00000 -21080.7\n+ SMIC           1   0.00000 0.00000 -21080.6\n+ taux_change    1   0.00000 0.00000 -21080.5\n+ precipitation  1   0.00000 0.00000 -21080.5\n+ CDD            1   0.00000 0.00000 -21080.4\n+ petrole        1   0.00000 0.00000 -21080.4\n- IPA_lag1       1   0.13703 0.13703  -2087.2\n\n\n\nCall:\nlm(formula = (IPA) ~ IPA_lag1 + exportations, data = st3_data)\n\nCoefficients:\n (Intercept)      IPA_lag1  exportations  \n  -1.506e-17     1.000e+00     1.072e-19  \n\n# modele 7 \nmodel5 &lt;- lm(formula = (IPA) ~ IPA_lag1 + taux_change + petrole + precipitation,   data = st3_data)\nsummary(model5)\n\nWarning in summary.lm(model5): essentially perfect fit: summary may be\nunreliable\n\n\n\nCall:\nlm(formula = (IPA) ~ IPA_lag1 + taux_change + petrole + precipitation, \n    data = st3_data)\n\nResiduals:\n       Min         1Q     Median         3Q        Max \n-3.690e-16  5.900e-19  1.390e-18  2.150e-18  2.202e-17 \n\nCoefficients:\n                Estimate Std. Error    t value Pr(&gt;|t|)    \n(Intercept)   -8.369e-18  1.130e-17 -7.410e-01    0.460    \nIPA_lag1       1.000e+00  6.392e-17  1.564e+16   &lt;2e-16 ***\ntaux_change    1.465e-18  1.183e-17  1.240e-01    0.902    \npetrole       -1.174e-21  2.431e-19 -5.000e-03    0.996    \nprecipitation -1.530e-20  7.617e-20 -2.010e-01    0.841    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.264e-17 on 270 degrees of freedom\nMultiple R-squared:      1, Adjusted R-squared:      1 \nF-statistic: 6.76e+31 on 4 and 270 DF,  p-value: &lt; 2.2e-16\n\n## TESTS \nresidus7 &lt;- residuals(model5)\n# Test de normalit√© des r√©sidus\nks.test(residus7, \"pnorm\", mean = mean(residus7), sd = sd(residus7))\n\n\n    Asymptotic one-sample Kolmogorov-Smirnov test\n\ndata:  residus7\nD = 0.41462, p-value &lt; 2.2e-16\nalternative hypothesis: two-sided\n\nbptest(model5)\n\n\n    studentized Breusch-Pagan test\n\ndata:  model5\nBP = 1.407, df = 4, p-value = 0.843\n\nreset(model5)\n\n\n    RESET test\n\ndata:  model5\nRESET = 34.971, df1 = 2, df2 = 268, p-value = 3.2e-14\n\nvif(model5)\n\nWarning in summary.lm(object, ...): essentially perfect fit: summary may be\nunreliable\n\n\n     IPA_lag1   taux_change       petrole precipitation \n     1.104992      1.165378      1.167885      1.040446 \n\ncheckresiduals(model5)\n\n\n\n\n\n\n\n\n\n    Breusch-Godfrey test for serial correlation of order up to 10\n\ndata:  Residuals\nLM test = 1.1638, df = 10, p-value = 0.9997\n\n\n\nLa pr√©sence d‚Äôh√©t√©rosc√©dasticit√© signifie que la variance des r√©sidus n‚Äôest pas constante. Cela peut affecter la validit√© des tests de significativit√© des coefficients.\nLe test RESET sugg√®re que le mod√®le pourrait √™tre mal sp√©cifi√©, indiquant que la relation entre les variables n‚Äôest pas correctement captur√©e par le mod√®le lin√©aire.\nOn ne peut donc pas utiliser la m√©thode des MCO pour estimer le mod√®le : les coefficients MCO ne sont pas biais√©s mais la variance de l‚Äôestimateur est non minimale"
  },
  {
    "objectID": "posts/post-with-code/memoire/memoire_m1.html#test-mod√®le-armax-avec-toutes-les-variables-stationnaires",
    "href": "posts/post-with-code/memoire/memoire_m1.html#test-mod√®le-armax-avec-toutes-les-variables-stationnaires",
    "title": "M√©moire",
    "section": "1. Test Mod√®le ARMAX avec toutes les variables stationnaires",
    "text": "1. Test Mod√®le ARMAX avec toutes les variables stationnaires\nInclut toutes les variables (stationnaires)\n\n# Pr√©paration des s√©ries temporelles pour ARMAX\ny1 &lt;- ts(stationnaire_data[,2], start = c(2000, 2), frequency = 12)\nvars1 &lt;- as.matrix(stationnaire_data[, 3:10]) \n# Estimation du mod√®le ARMAX avec toutes les variables\narmax_model1 &lt;- auto.arima(y1, xreg = vars1, stationary=TRUE)\n# R√©sum√© du mod√®le ARMAX\nsummary(armax_model1)\n\nSeries: y1 \nRegression with ARIMA(1,0,0) errors \n\nCoefficients:\n         ar1     CDD  importations  exportations  petrole  taux_change     SMIC\n      0.6287  1.1559        0.0637        0.1804   0.4564      17.5248  -0.0450\ns.e.  0.0481  0.6013        0.0484        0.0761   0.1631       7.6201   0.0614\n      precipitation  temperature\n            -0.0359      -2.1677\ns.e.         0.0467       2.7029\n\nsigma^2 = 252.9:  log likelihood = -1146.68\nAIC=2313.35   AICc=2314.19   BIC=2349.52\n\nTraining set error measures:\n                    ME     RMSE      MAE       MPE     MAPE      MASE\nTraining set 0.0270672 15.64079 10.78681 -29.08853 267.4824 0.5550402\n                    ACF1\nTraining set 0.007601316\n\ncoeftest(armax_model1)\n\n\nz test of coefficients:\n\n               Estimate Std. Error z value  Pr(&gt;|z|)    \nar1            0.628669   0.048053 13.0827 &lt; 2.2e-16 ***\nCDD            1.155934   0.601305  1.9224  0.054558 .  \nimportations   0.063678   0.048399  1.3157  0.188280    \nexportations   0.180353   0.076142  2.3686  0.017854 *  \npetrole        0.456407   0.163119  2.7980  0.005142 ** \ntaux_change   17.524841   7.620106  2.2998  0.021459 *  \nSMIC          -0.045022   0.061439 -0.7328  0.463685    \nprecipitation -0.035863   0.046699 -0.7680  0.442514    \ntemperature   -2.167712   2.702941 -0.8020  0.422563    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n# Test hypotheses \n# R√©sidus du mod√®le ARMAX\n# Test de Ljung-Box pour l'autocorr√©lation des r√©sidus\ncheckresiduals(armax_model1)\n\n\n\n\n\n\n\n\n\n    Ljung-Box test\n\ndata:  Residuals from Regression with ARIMA(1,0,0) errors\nQ* = 29.046, df = 23, p-value = 0.1788\n\nModel df: 1.   Total lags used: 24\n\nresiduals_armax1 &lt;- residuals(armax_model1)\n# Test de normalit√© des r√©sidus\nks.test(residuals_armax1, \"pnorm\", mean = mean(residuals_armax1), sd = sd(residuals_armax1))\n\n\n    Asymptotic one-sample Kolmogorov-Smirnov test\n\ndata:  residuals_armax1\nD = 0.10094, p-value = 0.007368\nalternative hypothesis: two-sided\n\n# Test de Breusch-Pagan pour l'h√©t√©rosc√©dasticit√©\nbptest(residuals_armax1 ~ vars1)\n\n\n    studentized Breusch-Pagan test\n\ndata:  residuals_armax1 ~ vars1\nBP = 43.638, df = 8, p-value = 6.66e-07"
  },
  {
    "objectID": "posts/post-with-code/memoire/memoire_m1.html#armax-avec-variables-s√©lectionnes-par-stepwise-et-best-sub",
    "href": "posts/post-with-code/memoire/memoire_m1.html#armax-avec-variables-s√©lectionnes-par-stepwise-et-best-sub",
    "title": "M√©moire",
    "section": "2. ARMAX Avec variables s√©lectionnes par stepwise et best sub",
    "text": "2. ARMAX Avec variables s√©lectionnes par stepwise et best sub\n\ny2 &lt;- ts(stationnaire_data[,2], start = c(2000, 2), frequency = 12)\nvars2 &lt;- as.matrix(stationnaire_data[, c(\"exportations\", \"petrole\", \"precipitation\", \"taux_change\", \"CDD\")])\n# Estimation du mod√®le ARMAX\narmax_model2 &lt;- auto.arima(y2, xreg = vars2, stationary=TRUE)\n# R√©sum√© du mod√®le ARMAX\nsummary(armax_model2)\n\nSeries: y2 \nRegression with ARIMA(1,0,0) errors \n\nCoefficients:\n         ar1  exportations  petrole  precipitation  taux_change     CDD\n      0.6213        0.1782   0.4950        -0.0589      17.5920  0.6530\ns.e.  0.0483        0.0743   0.1629         0.0335       7.6554  0.4628\n\nsigma^2 = 253.1:  log likelihood = -1148.31\nAIC=2310.62   AICc=2311.04   BIC=2335.94\n\nTraining set error measures:\n                      ME     RMSE      MAE       MPE     MAPE     MASE\nTraining set -0.08807324 15.73433 10.71464 -49.22505 311.8129 0.551327\n                   ACF1\nTraining set 0.00296305\n\ncoeftest(armax_model2)\n\n\nz test of coefficients:\n\n               Estimate Std. Error z value  Pr(&gt;|z|)    \nar1            0.621273   0.048281 12.8680 &lt; 2.2e-16 ***\nexportations   0.178229   0.074289  2.3991  0.016434 *  \npetrole        0.495043   0.162892  3.0391  0.002373 ** \nprecipitation -0.058927   0.033472 -1.7605  0.078325 .  \ntaux_change   17.591999   7.655369  2.2980  0.021562 *  \nCDD            0.653047   0.462793  1.4111  0.158215    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n# Test hypoth√®ses \n# R√©sidus du mod√®le ARMAX\nresiduals_armax2 &lt;- residuals(armax_model2)\n# Test de Ljung-Box pour l'autocorr√©lation des r√©sidus\ncheckresiduals(armax_model2)\n\n\n\n\n\n\n\n\n\n    Ljung-Box test\n\ndata:  Residuals from Regression with ARIMA(1,0,0) errors\nQ* = 29.109, df = 23, p-value = 0.1767\n\nModel df: 1.   Total lags used: 24\n\n# Test de normalit√© des r√©sidus\nks.test(residuals_armax2, \"pnorm\", mean = mean(residuals_armax2), sd = sd(residuals_armax2))\n\n\n    Asymptotic one-sample Kolmogorov-Smirnov test\n\ndata:  residuals_armax2\nD = 0.094687, p-value = 0.01444\nalternative hypothesis: two-sided\n\n# Test de Breusch-Pagan pour l'h√©t√©rosc√©dasticit√©\nbptest(residuals_armax2 ~ vars2)\n\n\n    studentized Breusch-Pagan test\n\ndata:  residuals_armax2 ~ vars2\nBP = 40.625, df = 5, p-value = 1.117e-07"
  },
  {
    "objectID": "posts/post-with-code/memoire/memoire_m1.html#mod√®le-armax-st2_data-utilise-le-diff_log_ipa",
    "href": "posts/post-with-code/memoire/memoire_m1.html#mod√®le-armax-st2_data-utilise-le-diff_log_ipa",
    "title": "M√©moire",
    "section": "3. Mod√®le ARMAX (st2_data utilise le diff_log_IPA)",
    "text": "3. Mod√®le ARMAX (st2_data utilise le diff_log_IPA)\n\ny3 &lt;- ts(st2_data[,2], start = c(2000, 2), frequency = 12)\nvars3 &lt;- as.matrix(stationnaire_data[, 3:10]) \n# Estimation du mod√®le ARMAX\narmax_model3 &lt;- auto.arima(y3, xreg = vars3, stationary=TRUE)\n# R√©sum√© du mod√®le ARMAX\nsummary(armax_model3)\n\nSeries: y3 \nRegression with ARIMA(1,0,0) errors \n\nCoefficients:\n         ar1    CDD  importations  exportations  petrole  taux_change   SMIC\n      0.5779  1e-03         1e-04         1e-04    5e-04       0.0235  0e+00\ns.e.  0.0497  7e-04         1e-04         1e-04    2e-04       0.0087  1e-04\n      precipitation  temperature\n              0e+00      -0.0022\ns.e.          1e-04       0.0031\n\nsigma^2 = 0.000318:  log likelihood = 721.5\nAIC=-1423.01   AICc=-1422.18   BIC=-1386.84\n\nTraining set error measures:\n                       ME       RMSE        MAE      MPE     MAPE      MASE\nTraining set 0.0001684718 0.01753895 0.01381429 25.05035 248.0198 0.5412742\n                   ACF1\nTraining set 0.03623777\n\ncoeftest(armax_model3)\n\n\nz test of coefficients:\n\n                 Estimate  Std. Error z value Pr(&gt;|z|)    \nar1            5.7793e-01  4.9748e-02 11.6172  &lt; 2e-16 ***\nCDD            9.8542e-04  6.8656e-04  1.4353  0.15120    \nimportations   8.0666e-05  8.2173e-05  0.9817  0.32627    \nexportations   1.2371e-04  1.0106e-04  1.2241  0.22090    \npetrole        4.6616e-04  1.9498e-04  2.3908  0.01681 *  \ntaux_change    2.3475e-02  8.7243e-03  2.6907  0.00713 ** \nSMIC           1.4973e-06  9.4345e-05  0.0159  0.98734    \nprecipitation -4.1973e-05  7.6820e-05 -0.5464  0.58480    \ntemperature   -2.2270e-03  3.0740e-03 -0.7244  0.46879    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n# Test hypotheses \n# R√©sidus du mod√®le ARMAX\nresiduals_armax3 &lt;- residuals(armax_model3)\n# Test de Ljung-Box pour l'autocorr√©lation des r√©sidus\ncheckresiduals(residuals_armax3)\n\n\n\n\n\n\n\n\n\n    Ljung-Box test\n\ndata:  Residuals\nQ* = 14.905, df = 24, p-value = 0.9235\n\nModel df: 0.   Total lags used: 24\n\n# Test de normalit√© des r√©sidus\nks.test(residuals_armax3, \"pnorm\", mean = mean(residuals_armax3), sd = sd(residuals_armax3))\n\n\n    Asymptotic one-sample Kolmogorov-Smirnov test\n\ndata:  residuals_armax3\nD = 0.045432, p-value = 0.6214\nalternative hypothesis: two-sided\n\n# Test de Breusch-Pagan pour l'h√©t√©rosc√©dasticit√©\nbptest(residuals_armax3 ~ vars3)\n\n\n    studentized Breusch-Pagan test\n\ndata:  residuals_armax3 ~ vars3\nBP = 12.266, df = 8, p-value = 0.1397"
  },
  {
    "objectID": "posts/post-with-code/memoire/memoire_m1.html#mod√®le-armax2---variables-s√©lectionn√©s-st2_data-utilise-le-diff_log_ipa",
    "href": "posts/post-with-code/memoire/memoire_m1.html#mod√®le-armax2---variables-s√©lectionn√©s-st2_data-utilise-le-diff_log_ipa",
    "title": "M√©moire",
    "section": "4. Mod√®le ARMAX2 - Variables s√©lectionn√©s (st2_data utilise le diff_log_IPA)",
    "text": "4. Mod√®le ARMAX2 - Variables s√©lectionn√©s (st2_data utilise le diff_log_IPA)\n\ny4 &lt;- ts(st2_data[,2], start = c(2000, 2), frequency = 12)\nvars4 &lt;- as.matrix(stationnaire_data[, c(\"exportations\", \"petrole\", \"precipitation\", \"taux_change\")])\n\n# Estimation du mod√®le ARMAX\narmax_model4 &lt;- auto.arima(y4, xreg = vars4, stationary=TRUE, seasonal = FALSE, stepwise=FALSE, approximation=FALSE)\n# R√©sum√© du mod√®le ARMAX\nsummary(armax_model4)\n\nSeries: y4 \nRegression with ARIMA(1,0,0) errors \n\nCoefficients:\n         ar1  intercept  exportations  petrole  precipitation  taux_change\n      0.5706     0.0146         1e-04    5e-04         -1e-04       0.0238\ns.e.  0.0501     0.0108         1e-04    2e-04          1e-04       0.0088\n\nsigma^2 = 0.0003175:  log likelihood = 720.18\nAIC=-1426.35   AICc=-1425.94   BIC=-1401.04\n\nTraining set error measures:\n                       ME       RMSE        MAE      MPE     MAPE      MASE\nTraining set 4.259534e-05 0.01762421 0.01372311 13.16189 288.5038 0.5377013\n                   ACF1\nTraining set 0.03113072\n\ncoeftest(armax_model4)\n\n\nz test of coefficients:\n\n                 Estimate  Std. Error z value  Pr(&gt;|z|)    \nar1            5.7057e-01  5.0115e-02 11.3853 &lt; 2.2e-16 ***\nintercept      1.4609e-02  1.0759e-02  1.3578  0.174539    \nexportations   1.2270e-04  1.0064e-04  1.2193  0.222748    \npetrole        5.1753e-04  1.9494e-04  2.6549  0.007934 ** \nprecipitation -8.6525e-05  7.1846e-05 -1.2043  0.228467    \ntaux_change    2.3816e-02  8.7529e-03  2.7209  0.006510 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n# Test hypotheses \n# R√©sidus du mod√®le ARMAX\nresiduals_armax &lt;- residuals(armax_model4)\n# Test de normalit√© des r√©sidus\nks.test(residuals_armax, \"pnorm\", mean = mean(residuals_armax), sd = sd(residuals_armax))\n\n\n    Asymptotic one-sample Kolmogorov-Smirnov test\n\ndata:  residuals_armax\nD = 0.059652, p-value = 0.2818\nalternative hypothesis: two-sided\n\n# Test de Ljung-Box pour l'autocorr√©lation des r√©sidus\n\ncheckresiduals(armax_model4)\n\n\n\n\n\n\n\n\n\n    Ljung-Box test\n\ndata:  Residuals from Regression with ARIMA(1,0,0) errors\nQ* = 14.994, df = 23, p-value = 0.8948\n\nModel df: 1.   Total lags used: 24\n\n# Test de Breusch-Pagan pour l'h√©t√©rosc√©dasticit√©\nbptest(residuals_armax ~ vars4)\n\n\n    studentized Breusch-Pagan test\n\ndata:  residuals_armax ~ vars4\nBP = 4.8771, df = 4, p-value = 0.3001\n\n\n\nTest de Kolmogorov-Smirnov Une p-value de 0.4388 indique qu‚Äôil n‚Äôy a pas de preuve statistique pour rejeter l‚Äôhypoth√®se nulle selon laquelle les r√©sidus suivent une distribution normale. Cela signifie que les r√©sidus peuvent √™tre consid√©r√©s comme normalement distribu√©s\nTest de Ljung-Box (Box-Ljung Test) Une p-value de 0.593 indique que on ne rejete pas l‚Äôhypoth√®se nulle d‚Äôind√©pendance des r√©sidus et donc pas d‚Äôautocorr√©lation significative dans les r√©sidus du mod√®le\nTest de Breusch-Pagan Hypoth√®se nulle: les variances des r√©sidus sont homog√®nes, c‚Äôest-√†-dire qu‚Äôil n‚Äôy a pas d‚Äôh√©t√©rosc√©dasticit√© dans les r√©sidus de votre mod√®le. Avec une p-value de 0.3751, on ne rejet pas l‚Äôhypoth√®se nulle car il n‚Äôy a pas de preuves statistiquement significatives d‚Äôh√©t√©rosc√©dasticit√© dans les r√©sidus du mod√®le ARMAX\n\n\n# √©cart pour la bande de pr√©diction √† 80%\nec80 &lt;- sqrt(armax_model4$sigma2) * qnorm(0.90)\n\n# Valeurs ajust√©es (pr√©dictions)\nvajust &lt;- fitted(armax_model4)\n\n# Matrice avec les valeurs observ√©es, les valeurs ajust√©es, et les bandes de pr√©diction\nmatri &lt;- as.ts(cbind(y4, vajust - ec80, vajust + ec80), start = start(y4), frequency = frequency(y4))\n\n# Graphique\nplot(matri, plot.type = 'single', lty = c(1, 2, 2), xlab = \"Temps\", ylab = 'Valeur', main = \"\", cex.main = 0.8)\nlegend(\"topright\", legend = c(\"Valeur observ√©e\", \"Bande de pr√©diction 80%\"), lwd = 1, lty = c(1, 2), cex = 0.8)\n\n\n\n\n\n\n\n# Proportion \nindi &lt;- (y4-(vajust-ec80))&gt;0&(vajust+ec80-y4)&gt;0\nprop &lt;- 100*sum(indi)/length(indi)\n\nprop\n\n[1] 80.36364\n\n\nMontre les valeurs observ√©es de notre s√©rie temporelle, ainsi que les valeurs ajust√©es par le mod√®le ARMAX avec une bande de pr√©diction √† 80%.\nLa proportion observ√©e vaut 81%, elle est un peu sup√©rieure √† la valeur th√©orique de 80%. On consid√©rera que l‚Äôajustement est satisfaisant."
  },
  {
    "objectID": "posts/post-with-code/memoire/memoire_m1.html#acf---pacf",
    "href": "posts/post-with-code/memoire/memoire_m1.html#acf---pacf",
    "title": "M√©moire",
    "section": "ACF - PACF",
    "text": "ACF - PACF\nOn reprend le mod√®le avec diff log, les variables s√©lectionn√©s et\n\nacf(residuals(lm_model2),lag.max=30,numer=FALSE)\n\nWarning in plot.window(...): \"numer\" is not a graphical parameter\n\n\nWarning in plot.xy(xy, type, ...): \"numer\" is not a graphical parameter\n\n\nWarning in axis(side = side, at = at, labels = labels, ...): \"numer\" is not a\ngraphical parameter\nWarning in axis(side = side, at = at, labels = labels, ...): \"numer\" is not a\ngraphical parameter\n\n\nWarning in box(...): \"numer\" is not a graphical parameter\n\n\nWarning in title(...): \"numer\" is not a graphical parameter\n\n\n\n\n\n\n\n\npacf(residuals(lm_model2),lag.max=30,numer=FALSE)\n\nWarning in plot.window(...): \"numer\" is not a graphical parameter\n\n\nWarning in plot.xy(xy, type, ...): \"numer\" is not a graphical parameter\n\n\nWarning in axis(side = side, at = at, labels = labels, ...): \"numer\" is not a\ngraphical parameter\nWarning in axis(side = side, at = at, labels = labels, ...): \"numer\" is not a\ngraphical parameter\n\n\nWarning in box(...): \"numer\" is not a graphical parameter\n\n\nWarning in title(...): \"numer\" is not a graphical parameter"
  },
  {
    "objectID": "posts/post-with-code/memoire/memoire_m1.html#mod√®le-mco-avec-les-r√©sidus-ajust√©s-avec-un-mod√®le-ar1",
    "href": "posts/post-with-code/memoire/memoire_m1.html#mod√®le-mco-avec-les-r√©sidus-ajust√©s-avec-un-mod√®le-ar1",
    "title": "M√©moire",
    "section": "Mod√®le MCO avec les r√©sidus ajust√©s avec un mod√®le AR(1)",
    "text": "Mod√®le MCO avec les r√©sidus ajust√©s avec un mod√®le AR(1)\n\n# On ajuste le mod√®le avec base st2 (qui utilise diff_log_IPA) pour obtenir les r√©sidus\nlm_base &lt;- lm(IPA ~ taux_change + petrole + precipitation + exportations, data = st2_data)\nresiduals_base &lt;- residuals(lm_base)\n\n#  mod√®le AR(1) sur les r√©sidus\nar1_residuals &lt;- arima(residuals_base, order = c(1, 0, 0))\nar1_fitted &lt;- fitted(ar1_residuals)\n\n#  les valeurs ajust√©es de l'AR(1) comme une nouvelle variable\nst2_data$ar1_fitted &lt;- ar1_fitted\n\n# On reajuste le mod√®le lin√©aire en incluant la nouvelle variable\nlm_corrected &lt;- lm(IPA ~ taux_change + petrole + precipitation + exportations + ar1_fitted, data = st2_data)\n\n# R√©sum√© du nouveau mod√®le\nsummary(lm_corrected)\n\n\nCall:\nlm(formula = IPA ~ taux_change + petrole + precipitation + exportations + \n    ar1_fitted, data = st2_data)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.048087 -0.011929 -0.001883  0.012298  0.046143 \n\nCoefficients:\n                Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)    2.689e-02  9.236e-03   2.912  0.00390 ** \ntaux_change    3.888e-02  9.192e-03   4.229 3.22e-05 ***\npetrole        5.884e-04  1.906e-04   3.087  0.00224 ** \nprecipitation -1.603e-04  6.000e-05  -2.671  0.00802 ** \nexportations   9.157e-05  4.442e-05   2.062  0.04020 *  \nar1_fitted     1.022e+00  9.654e-02  10.589  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.01805 on 269 degrees of freedom\nMultiple R-squared:  0.3681,    Adjusted R-squared:  0.3564 \nF-statistic: 31.35 on 5 and 269 DF,  p-value: &lt; 2.2e-16\n\n# V√©rification des r√©sidus du mod√®le corrig√©\nresiduals_corrected &lt;- residuals(lm_corrected)\npar(mfrow = c(1, 2))\nacf(residuals_corrected, main = \"ACF des r√©sidus du mod√®le corrig√©\")\npacf(residuals_corrected, main = \"PACF des r√©sidus du mod√®le corrig√©\")\n\n\n\n\n\n\n\ncheckresiduals(residuals_corrected)\n\n\n\n\n\n\n\n\n\n    Ljung-Box test\n\ndata:  Residuals\nQ* = 6.4074, df = 10, p-value = 0.78\n\nModel df: 0.   Total lags used: 10\n\n# Tests\nks.test(residuals_corrected, \"pnorm\", mean = mean(residuals_corrected), sd = sd(residuals_corrected))\n\n\n    Asymptotic one-sample Kolmogorov-Smirnov test\n\ndata:  residuals_corrected\nD = 0.060107, p-value = 0.2735\nalternative hypothesis: two-sided\n\nbptest(lm_corrected)\n\n\n    studentized Breusch-Pagan test\n\ndata:  lm_corrected\nBP = 17.395, df = 5, p-value = 0.003808\n\nreset(lm_corrected)\n\n\n    RESET test\n\ndata:  lm_corrected\nRESET = 5.2333, df1 = 2, df2 = 267, p-value = 0.005897\n\nvif(lm_corrected)\n\n  taux_change       petrole precipitation  exportations    ar1_fitted \n     1.107362      1.130431      1.016294      1.005598      1.019534"
  },
  {
    "objectID": "posts/post-with-code/techniques_previsions/prevision_conjoncture.html",
    "href": "posts/post-with-code/techniques_previsions/prevision_conjoncture.html",
    "title": "Techniques de pr√©vision et conjoncture",
    "section": "",
    "text": "√âvolution de l‚Äôindice des prix d‚Äôachat des moyens de production agricole en France\nJanvier 2005 ‚Äì D√©cembre 2023"
  },
  {
    "objectID": "posts/post-with-code/techniques_previsions/prevision_conjoncture.html#cr√©ation-de-la-s√©rie-temporelle",
    "href": "posts/post-with-code/techniques_previsions/prevision_conjoncture.html#cr√©ation-de-la-s√©rie-temporelle",
    "title": "Techniques de pr√©vision et conjoncture",
    "section": "Cr√©ation de la s√©rie temporelle",
    "text": "Cr√©ation de la s√©rie temporelle\n\nipampa &lt;- ts(data = ipampa, start = c(2005, 01), frequency=12)"
  },
  {
    "objectID": "posts/post-with-code/techniques_previsions/prevision_conjoncture.html#visualisation",
    "href": "posts/post-with-code/techniques_previsions/prevision_conjoncture.html#visualisation",
    "title": "Techniques de pr√©vision et conjoncture",
    "section": "Visualisation",
    "text": "Visualisation\n\nshow(ipampa)\n\n       Jan   Feb   Mar   Apr   May   Jun   Jul   Aug   Sep   Oct   Nov   Dec\n2005  78.2  78.5  79.1  79.3  78.9  79.4  79.8  80.0  80.5  80.7  80.3  80.4\n2006  80.8  81.1  81.3  81.8  81.8  81.8  81.9  82.1  81.9  82.1  82.3  82.5\n2007  82.6  83.1  83.8  84.5  84.8  85.1  85.8  86.6  88.1  89.5  91.1  91.9\n2008  93.2  94.4  95.7  96.9  98.8 100.2 101.3 100.6 100.6  99.5  97.7  95.8\n2009  95.4  94.8  93.9  93.5  92.7  92.2  90.8  90.7  90.1  89.7  89.4  89.3\n2010  89.5  89.8  90.4  91.0  91.2  91.4  91.3  92.1  93.7  95.0  95.6  96.6\n2011  98.0  99.4 100.6 101.0 100.4 100.6 101.0 100.9 101.3 101.3 101.2 101.0\n2012 100.6 101.2 101.9 102.3 102.3 101.8 103.1 105.1 106.0 106.5 106.4 106.3\n2013 106.4 106.8 106.4 105.7 105.4 105.0 104.6 104.2 103.7 103.0 102.7 102.7\n2014 102.9 103.0 103.1 103.3 103.3 103.1 102.5 102.1 101.6 101.0 100.4  99.5\n2015  99.1 100.5 100.7 101.1 101.3 100.6 100.2  99.7  99.6  99.5  99.3  98.3\n2016  97.8  97.5  97.6  97.4  97.9  97.8  97.3  96.9  97.0  97.4  97.2  98.3\n2017  98.6  99.0  98.9  99.1  98.7  98.1  97.9  98.0  98.4  98.9  99.2  99.3\n2018 100.1 100.1 100.4 101.1 102.0 101.9 102.2 102.7 103.6 104.6 104.5 103.8\n2019 103.6 104.1 104.4 104.6 104.4 103.8 103.7 103.3 103.7 103.6 103.3 103.5\n2020 103.6 103.4 102.3 101.7 101.7 101.8 101.8 101.8 101.5 102.1 102.6 103.1\n2021 104.5 106.4 107.6 107.9 108.5 109.6 110.9 111.6 113.2 117.5 119.5 120.5\n2022 123.1 124.9 133.2 134.6 136.1 138.6 138.2 138.9 139.5 142.0 141.3 139.6\n\nplot(ipampa, xlab = \"Ann√©es\", ylab =\"indice 'IPAMPA'\", main= \"S√©rie brute\")\n\n\n\n\n\n\n\n\nGraphique avec ggplot\n\nts_df &lt;- data.frame(Date = time(ipampa), Value = as.numeric(ipampa))\n\n# graphique ggplot\nggplot(data = ts_df, aes(x = Date, y = Value)) + \n  geom_line(aes(color = Value)) +  \n  scale_color_gradient(low = \"darkgreen\", high = \"red\") +  \n  labs(title = \"\nIndice mensuel des prix d'achat \ndes moyens de production agricole (IPAMPA)\",\n       x = \"P√©riode\\n(01/2005 - 12/2022)\", y = \"Indice\") +\n  theme_minimal() +\n  theme(legend.position = \"right\",\n        plot.title = element_text(size = 8),\n        axis.title.x = element_text(size = 8),\n        axis.title.y = element_text(size = 8),\n        legend.title = element_text(size = 7))  \n\nDon't know how to automatically pick scale for object of type &lt;ts&gt;. Defaulting\nto continuous."
  },
  {
    "objectID": "posts/post-with-code/techniques_previsions/prevision_conjoncture.html#d√©tection-outliers",
    "href": "posts/post-with-code/techniques_previsions/prevision_conjoncture.html#d√©tection-outliers",
    "title": "Techniques de pr√©vision et conjoncture",
    "section": "D√©tection outliers",
    "text": "D√©tection outliers\n\n# Automatic Procedure for Detection of Outliers\ntso(ipampa)\n\nSeries: ipampa \nRegression with ARIMA(1,1,1) errors \n\nCoefficients:\n         ar1      ma1   LS122   LS202   LS207   TC214\n      0.8434  -0.2691  1.5395  2.7421  6.6747  2.4083\ns.e.  0.0531   0.1062  0.4497  0.4520  0.4505  0.3936\n\nsigma^2 = 0.2814:  log likelihood = -166.1\nAIC=346.2   AICc=346.74   BIC=369.79\n\nOutliers:\n  type ind    time coefhat  tstat\n1   LS 122 2015:02   1.539  3.423\n2   LS 202 2021:10   2.742  6.067\n3   LS 207 2022:03   6.675 14.817\n4   TC 214 2022:10   2.408  6.119\n\nfit &lt;- tso(ipampa)\nplot(fit)\n\n\n\n\n\n\n\nshow(fit)\n\nSeries: ipampa \nRegression with ARIMA(1,1,1) errors \n\nCoefficients:\n         ar1      ma1   LS122   LS202   LS207   TC214\n      0.8434  -0.2691  1.5395  2.7421  6.6747  2.4083\ns.e.  0.0531   0.1062  0.4497  0.4520  0.4505  0.3936\n\nsigma^2 = 0.2814:  log likelihood = -166.1\nAIC=346.2   AICc=346.74   BIC=369.79\n\nOutliers:\n  type ind    time coefhat  tstat\n1   LS 122 2015:02   1.539  3.423\n2   LS 202 2021:10   2.742  6.067\n3   LS 207 2022:03   6.675 14.817\n4   TC 214 2022:10   2.408  6.119"
  },
  {
    "objectID": "posts/post-with-code/techniques_previsions/prevision_conjoncture.html#s√©rie-corrig√©e",
    "href": "posts/post-with-code/techniques_previsions/prevision_conjoncture.html#s√©rie-corrig√©e",
    "title": "Techniques de pr√©vision et conjoncture",
    "section": "S√©rie corrig√©e",
    "text": "S√©rie corrig√©e\n\npar(mfrow=c(1,1))\n\n# outlier-adjusted series\nipampa &lt;- fit$yadj\nplot(ipampa, main= \"S√©rie adjust√©e\", xlab= \"Ann√©es\", ylab =\"indice 'IPAMPA\")\n\n\n\n\n\n\n\n\nExistence de 4 outliers 3 type LS et un type TC"
  },
  {
    "objectID": "posts/post-with-code/techniques_previsions/prevision_conjoncture.html#tests-de-saisonnalit√©",
    "href": "posts/post-with-code/techniques_previsions/prevision_conjoncture.html#tests-de-saisonnalit√©",
    "title": "Techniques de pr√©vision et conjoncture",
    "section": "Tests de saisonnalit√©",
    "text": "Tests de saisonnalit√©\n\n# Friedman test\nft &lt;- fried(ipampa)\nshow(ft)\n\nTest used:  Friedman rank \n \nTest statistic:  15.81 \nP-value:  0.1485093\n\n# Testing the seasonality of series\n#  a boolean value is returned : TRUE or FALSE\nis &lt;- isSeasonal(ipampa, test=\"wo\")\nshow(is)\n\n[1] FALSE\n\n# Kruskal-Wallis test\nkwt &lt;- kw(ipampa)\nshow(kwt)\n\nTest used:  Kruskall Wallis \n \nTest statistic:  10.94 \nP-value:  0.4482418\n\n# Seasonal dummies\n# impotant \nsd &lt;- seasdum(ipampa)\nshow(sd)\n\nTest used:  SeasonalDummies \n \nTest statistic:  0.86 \nP-value:  0.5759353\n\n# Webel-Ollech test\n# Webel-Ollech test - new version of seastests (2021-09)\n# impotant \n\nwot &lt;- combined_test(ipampa)\nshow(wot)\n\nTest used:  WO \n \nTest statistic:  0 \nP-value:  1 1 0.03397038\n\n\nLes tests confirment la non saisonnalit√© de la s√©rie IPAMPA\n\nGraphique\n\n# Trace une s√©rie chronologique avec son acf et soit son pacf, son nuage de points d√©cal√© ou son spectre\nggtsdisplay(ipampa, plot.type=\"histogram\")\n\n\n\n\n\n\n\n# Trace un graphique saisonnier o√π les donn√©es sont compar√©es aux saisons d'ann√©es distinctes\n# ggseasonplot(ipampa_ts, col=rainbow(12), year.labels=TRUE)"
  },
  {
    "objectID": "posts/post-with-code/techniques_previsions/prevision_conjoncture.html#v√©rification-de-la-stationnarit√©",
    "href": "posts/post-with-code/techniques_previsions/prevision_conjoncture.html#v√©rification-de-la-stationnarit√©",
    "title": "Techniques de pr√©vision et conjoncture",
    "section": "V√©rification de la stationnarit√©",
    "text": "V√©rification de la stationnarit√©\n\nstationnarit√© de ipampa\n\nadf.test(ipampa)\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  ipampa\nDickey-Fuller = -3.1388, Lag order = 5, p-value = 0.09931\nalternative hypothesis: stationary\n\n\nLa s√©rie n‚Äôest pas stationnaire car le test ADF &gt; 0.05\nVu que notre s√©rie ne presente pas de saisonalit√©, nous allons faire un analyse sur la tendance\n\ndecomp &lt;- decompose(ipampa)\nplot(decomp)"
  },
  {
    "objectID": "posts/post-with-code/techniques_previsions/prevision_conjoncture.html#tendance",
    "href": "posts/post-with-code/techniques_previsions/prevision_conjoncture.html#tendance",
    "title": "Techniques de pr√©vision et conjoncture",
    "section": "Tendance",
    "text": "Tendance\n\n# test de tendence serie niveau\nMannKendall(ipampa)\n\ntau = 0.568, 2-sided pvalue =&lt; 2.22e-16\n\n\nDans notre cas, œÑ = 0.568 sugg√®re une tendance croissante mod√©r√©ment forte dans la s√©rie temporelle √† niveau, avec un p_value inf√©rieur √† 0,05 on peut dire que la s√©rie initial presente bien une tendance\n\ndifferentiation de la s√©rie\n\nd_ipampa &lt;- diff(ipampa, differences = 1)\n\n\n# graphique ggplot\ndf &lt;- data.frame(Date = time(d_ipampa), Value = as.numeric(d_ipampa))\n\n# graphique ggplot\nggplot(data = df, aes(x = Date, y = Value)) + \n  geom_line(aes(color = Value)) +  \n  scale_color_gradient(low = \"darkgreen\", high = \"red\") +  \n  labs(title = \"S√©rie differenci√©e\",\n       x = \"Dates\", y = \"Indice\") +\n  theme_minimal() +\n  theme(legend.position = \"right\",\n        plot.title = element_text(size = 8),\n        axis.title.x = element_text(size = 8),\n        axis.title.y = element_text(size = 8),\n        legend.title = element_text(size = 7))  \n\nDon't know how to automatically pick scale for object of type &lt;ts&gt;. Defaulting\nto continuous.\n\n\n\n\n\n\n\n\n\n\n\nCorrelogramme s√©rie brute et s√©rie differenci√©\n\npar(mfrow=c(1,2))\nacf(ipampa, main=\"Correlogramme sur la s√©rie en niveau\")\nacf(d_ipampa, main=\"Correlogramme sur la s√©rie en diff√©rence premi√®re\")\n\n\n\n\n\n\n\n\n\n\nPeriodogramme\n\n# Periodogramme\npar(mfrow=c(1,2))\nperiodogram(ipampa, main=\"Periodogramme sur la s√©rie en niveau\")\nperiodogram(d_ipampa, main=\"Periodogramme sur la s√©rie en diff√©rence premi√®re\")"
  },
  {
    "objectID": "posts/post-with-code/techniques_previsions/prevision_conjoncture.html#test-de-stationnarit√©-de-la-s√©rie-diff√©renci√©-ipampa",
    "href": "posts/post-with-code/techniques_previsions/prevision_conjoncture.html#test-de-stationnarit√©-de-la-s√©rie-diff√©renci√©-ipampa",
    "title": "Techniques de pr√©vision et conjoncture",
    "section": "Test de stationnarit√© de la s√©rie diff√©renci√© ipampa",
    "text": "Test de stationnarit√© de la s√©rie diff√©renci√© ipampa\n\nadf.test(d_ipampa)\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  d_ipampa\nDickey-Fuller = -3.564, Lag order = 5, p-value = 0.0378\nalternative hypothesis: stationary\n\n\nApres la diff√©rentiation la s√©rie devient bien stationnaire\n\ndecomp &lt;- decompose(ipampa)\ndecomp_d &lt;- decompose(d_ipampa)\n\ngraph1 &lt;- plot(decomp)\n\n\n\n\n\n\n\ngraph2 &lt;- plot(decomp_d)"
  },
  {
    "objectID": "posts/post-with-code/techniques_previsions/prevision_conjoncture.html#statistiques-descriptives",
    "href": "posts/post-with-code/techniques_previsions/prevision_conjoncture.html#statistiques-descriptives",
    "title": "Techniques de pr√©vision et conjoncture",
    "section": "Statistiques descriptives",
    "text": "Statistiques descriptives\n\nsummary(d_ipampa)\n\n       y          \n Min.   :-1.9000  \n 1st Qu.:-0.2500  \n Median : 0.2000  \n Mean   : 0.2291  \n 3rd Qu.: 0.6000  \n Max.   : 2.6000  \n\n#histogramme\nhist(d_ipampa, main= \"Histogramme s√©rie corrig√©\", ylab=\" Fr√©quence\", xlab=\"indice\")\n\n\n\n\n\n\n\n#skewness \nPerformanceAnalytics::skewness(d_ipampa)\n\n[1] 0.4496658\n\n#kurtosis \nPerformanceAnalytics::kurtosis(d_ipampa)\n\n[1] 0.6254732\n\ne1071::kurtosis(d_ipampa)\n\n[1] 0.5918263\n\n#normalit√©\nstats::shapiro.test(d_ipampa)\n\n\n    Shapiro-Wilk normality test\n\ndata:  d_ipampa\nW = 0.97467, p-value = 0.0006498\n\n#boxplot\nboxplot(d_ipampa, main=\"Boxplot\")\n\n\n\n\n\n\n\n#test outliers\nrosnerTest(d_ipampa, k=10)\n\n\nResults of Outlier Test\n-------------------------\n\nTest Method:                     Rosner's Test for Outliers\n\nHypothesized Distribution:       Normal\n\nData:                            d_ipampa\n\nSample Size:                     215\n\nTest Statistics:                 R.1  = 3.233268\n                                 R.2  = 3.183835\n                                 R.3  = 3.006058\n                                 R.4  = 2.934315\n                                 R.5  = 2.627525\n                                 R.6  = 2.678351\n                                 R.7  = 2.579619\n                                 R.8  = 2.628374\n                                 R.9  = 2.522953\n                                 R.10 = 2.523867\n\nTest Statistic Parameter:        k = 10\n\nAlternative Hypothesis:          Up to 10 observations are not\n                                 from the same Distribution.\n\nType I Error:                    5%\n\nNumber of Outliers Detected:     0\n\n   i    Mean.i      SD.i Value Obs.Num    R.i+1 lambda.i+1 Outlier\n1  0 0.2291333 0.7332725   2.6     204 3.233268   3.627118   FALSE\n2  1 0.2180544 0.7167286   2.5     209 3.183835   3.625734   FALSE\n3  2 0.2073411 0.7010315  -1.9      47 3.006058   3.624342   FALSE\n4  3 0.2172814 0.6874795  -1.8      46 2.934315   3.622942   FALSE\n5  4 0.2268419 0.6748397   2.0      91 2.627525   3.621535   FALSE\n6  5 0.2183983 0.6651861   2.0     202 2.678351   3.620120   FALSE\n7  6 0.2098739 0.6551844   1.9     193 2.579619   3.618697   FALSE\n8  7 0.2017483 0.6461226   1.9      40 2.628374   3.617266   FALSE\n9  8 0.1935442 0.6367363   1.8     205 2.522953   3.615828   FALSE\n10 9 0.1857459 0.6283000  -1.4      54 2.523867   3.614381   FALSE\n\n\nLe test de shapiro, indique que notre s√©rie ne suit pas une loi normal\nLe box plot nous indique des possibles outliers. La v√©rification avec le test de rosner nous indique que finalement il n‚Äôy pas"
  },
  {
    "objectID": "posts/post-with-code/techniques_previsions/prevision_conjoncture.html#r√©cup√©ration-des-points-forecastes-dans-un-seul-dataframe",
    "href": "posts/post-with-code/techniques_previsions/prevision_conjoncture.html#r√©cup√©ration-des-points-forecastes-dans-un-seul-dataframe",
    "title": "Techniques de pr√©vision et conjoncture",
    "section": "R√©cup√©ration des ‚Äúpoints forecastes‚Äù dans un seul dataframe",
    "text": "R√©cup√©ration des ‚Äúpoints forecastes‚Äù dans un seul dataframe\n\nstart_date &lt;- as.Date(\"2023-01-01\") # La date de d√©but des pr√©visions\nforecast_horizon &lt;- 12 # Le nombre de mois √† pr√©voir\n\n# s√©quence de dates pour les pr√©visions\nforecast_dates &lt;- seq(start_date, by = \"month\", length.out = forecast_horizon)\n\n#  data frames avec les dates et les previsions\ndf &lt;- data.frame(\n  Date = forecast_dates,\n  AR1 = as.numeric(ar1_forecast$mean),\n  ARP = as.numeric(arp_forecast$mean),\n  ARIMA =as.numeric(arima_forecast$mean),\n  HOLT = as.numeric(hw_forecast$mean),\n  ADAM_ETS = as.numeric(adam_ets_forecast$mean),\n  ADAM_ETS_SARIMA = as.numeric(adamES_forecast$mean),\n  SSARIMA =  as.numeric(ssarima_forecast$mean),\n  CES = as.numeric(ces_forecast$mean),\n  NAIVE = as.numeric(naive$mean)\n)\n\ndf\n\n         Date         AR1         ARP      ARIMA        HOLT   ADAM_ETS\n1  2023-01-01 -0.76672710 -0.73037881 -0.6694243 -0.11899046 -0.6523988\n2  2023-02-01 -0.46889491 -0.62651673 -0.5646122 -0.07826328 -0.6702396\n3  2023-03-01 -0.26141868 -0.49364745 -0.4762105 -0.28184860 -0.6865734\n4  2023-04-01 -0.11688633 -0.39655404 -0.4016499 -0.24232723 -0.7045631\n5  2023-05-01 -0.01620203 -0.31712205 -0.3387634 -0.42684394 -0.7220066\n6  2023-06-01  0.05393680 -0.25386675 -0.2857230 -0.34980408 -0.7396775\n7  2023-07-01  0.10279699 -0.20317926 -0.2409872 -0.45898101 -0.7560831\n8  2023-08-01  0.13683404 -0.16262133 -0.2032557 -0.40898321 -0.7739359\n9  2023-09-01  0.16054497 -0.13015772 -0.1714318 -0.06201067 -0.7904225\n10 2023-10-01  0.17706251 -0.10417504 -0.1445906 -0.30085375 -0.8077258\n11 2023-11-01  0.18856898 -0.08337908 -0.1219520 -0.54649791 -0.8249201\n12 2023-12-01  0.19658463 -0.06673454 -0.1028579 -0.65465763 -0.8423237\n   ADAM_ETS_SARIMA    SSARIMA         CES     NAIVE\n1      -0.62258914 -0.3992712 -0.24360607 -1.194265\n2      -0.35958468 -0.5418099  0.01295041 -1.194265\n3      -0.30092313 -0.3051800 -0.17555379 -1.194265\n4      -0.19125026 -0.2796120 -0.16331942 -1.194265\n5      -0.09602462 -0.3485568 -0.23342431 -1.194265\n6      -0.02789313 -0.2311090 -0.33789275 -1.194265\n7       0.02890327 -0.1982459 -0.28771617 -1.194265\n8       0.07602108 -0.2280172 -0.27307246 -1.194265\n9       0.11398312 -0.1685953 -0.05269430 -1.194265\n10      0.14484443 -0.1410267 -0.12204586 -1.194265\n11      0.17001336 -0.1514261 -0.34386009 -1.194265\n12      0.19048551 -0.1203632 -0.35952800 -1.194265"
  },
  {
    "objectID": "posts/post-with-code/techniques_previsions/prevision_conjoncture.html#recuperation-des-donn√©es-2023",
    "href": "posts/post-with-code/techniques_previsions/prevision_conjoncture.html#recuperation-des-donn√©es-2023",
    "title": "Techniques de pr√©vision et conjoncture",
    "section": "Recuperation des donn√©es 2023",
    "text": "Recuperation des donn√©es 2023\nLors du T√©l√©chargement de notre jeu de donn√©es nous nous sommes arr√™t√©s au mois de d√©cembre 2022 et mis de cot√© les donn√©es pour l‚Äôann√©e 2023, on r√©cup√®re les donn√©es pour les comparer aux mod√®les\n\nreal &lt;- read_excel(here(\"data\", \"serie_ipampa.xlsx\"), sheet = 'complete')\nreal &lt;- real[nrow(real):1,]\nreal &lt;- real[, 2]\nreal &lt;- ts(data = real, start = c(2005, 01), frequency=12) \n\n\nreal_2023 &lt;- window(real, start = c(2023, 1), end = c(2023, 12))\nreal_2023\n\n       Jan   Feb   Mar   Apr   May   Jun   Jul   Aug   Sep   Oct   Nov   Dec\n2023 140.1 138.6 137.5 135.5 133.5 132.0 130.8 132.1 132.4 131.9 130.9 129.5\n\nreal_d &lt;- diff(real, differences = 1)\n\nreal_d &lt;- window(real_d, start = c(2023, 1), end = c(2023, 12))\nplot(real_d)\n\n\n\n\n\n\n\nreal_d &lt;- as.numeric(real_d)\ndf$Real = real_d\ndf\n\n         Date         AR1         ARP      ARIMA        HOLT   ADAM_ETS\n1  2023-01-01 -0.76672710 -0.73037881 -0.6694243 -0.11899046 -0.6523988\n2  2023-02-01 -0.46889491 -0.62651673 -0.5646122 -0.07826328 -0.6702396\n3  2023-03-01 -0.26141868 -0.49364745 -0.4762105 -0.28184860 -0.6865734\n4  2023-04-01 -0.11688633 -0.39655404 -0.4016499 -0.24232723 -0.7045631\n5  2023-05-01 -0.01620203 -0.31712205 -0.3387634 -0.42684394 -0.7220066\n6  2023-06-01  0.05393680 -0.25386675 -0.2857230 -0.34980408 -0.7396775\n7  2023-07-01  0.10279699 -0.20317926 -0.2409872 -0.45898101 -0.7560831\n8  2023-08-01  0.13683404 -0.16262133 -0.2032557 -0.40898321 -0.7739359\n9  2023-09-01  0.16054497 -0.13015772 -0.1714318 -0.06201067 -0.7904225\n10 2023-10-01  0.17706251 -0.10417504 -0.1445906 -0.30085375 -0.8077258\n11 2023-11-01  0.18856898 -0.08337908 -0.1219520 -0.54649791 -0.8249201\n12 2023-12-01  0.19658463 -0.06673454 -0.1028579 -0.65465763 -0.8423237\n   ADAM_ETS_SARIMA    SSARIMA         CES     NAIVE Real\n1      -0.62258914 -0.3992712 -0.24360607 -1.194265  0.5\n2      -0.35958468 -0.5418099  0.01295041 -1.194265 -1.5\n3      -0.30092313 -0.3051800 -0.17555379 -1.194265 -1.1\n4      -0.19125026 -0.2796120 -0.16331942 -1.194265 -2.0\n5      -0.09602462 -0.3485568 -0.23342431 -1.194265 -2.0\n6      -0.02789313 -0.2311090 -0.33789275 -1.194265 -1.5\n7       0.02890327 -0.1982459 -0.28771617 -1.194265 -1.2\n8       0.07602108 -0.2280172 -0.27307246 -1.194265  1.3\n9       0.11398312 -0.1685953 -0.05269430 -1.194265  0.3\n10      0.14484443 -0.1410267 -0.12204586 -1.194265 -0.5\n11      0.17001336 -0.1514261 -0.34386009 -1.194265 -1.0\n12      0.19048551 -0.1203632 -0.35952800 -1.194265 -1.4\n\nnames (df) # on verifie que real fait bien partie du data frame \n\n [1] \"Date\"            \"AR1\"             \"ARP\"             \"ARIMA\"          \n [5] \"HOLT\"            \"ADAM_ETS\"        \"ADAM_ETS_SARIMA\" \"SSARIMA\"        \n [9] \"CES\"             \"NAIVE\"           \"Real\"           \n\n\nGraphique de comparaison\n\n# Transformer les donn√©es en format long\ndf_long &lt;- pivot_longer(df, cols = -Date, names_to = \"Model\", values_to = \"Value\")\n\n# graphique plotly\np &lt;- ggplot(df_long, aes(x = Date, y = Value, color = Model)) +\n  geom_line() +\n  theme_minimal() +\n  labs(title = \"Comparaison des pr√©visions des mod√®les avec les donn√©es r√©elles\n       Jan 2023 √† D√©c 2023 - s√©rie differenci√©\",\n       x = \"Date\",\n       y = \"Valeur\",\n       color = \"Mod√®le\") +\n  theme(legend.position = \"bottom\") \n\n\nggplotly(p)\n\n\n\n\n\n\nR√©int√©gration\nNous pouvons reintegrer les pr√©visions aux donn√©es pour avoir le graphique au niveau\n\ndec_2022 &lt;- 139.6\n\ndf_real &lt;- data.frame(\n    Date = forecast_dates,\n    AR1 = dec_2022 + cumsum(df$AR1),\n    ARP = dec_2022 + cumsum(df$ARP),\n    ARIMA = dec_2022 + cumsum(df$ARIMA),\n    HOLT = dec_2022 + cumsum(df$HOLT),\n    ADAM_ETS = dec_2022 + cumsum(df$ADAM_ETS),\n    ADAM_ETS_SARIMA = dec_2022 + cumsum(df$ADAM_ETS_SARIMA),\n    SSARIMA = dec_2022 + cumsum(df$SSARIMA),\n    CES = dec_2022 + cumsum(df$CES)\n    )\n\nreal_2023 &lt;- as.numeric(real_2023)\ndf_real$Real = real_2023\ndf_real\n\n         Date      AR1      ARP    ARIMA     HOLT ADAM_ETS ADAM_ETS_SARIMA\n1  2023-01-01 138.8333 138.8696 138.9306 139.4810 138.9476        138.9774\n2  2023-02-01 138.3644 138.2431 138.3660 139.4027 138.2774        138.6178\n3  2023-03-01 138.1030 137.7495 137.8898 139.1209 137.5908        138.3169\n4  2023-04-01 137.9861 137.3529 137.4881 138.8786 136.8862        138.1257\n5  2023-05-01 137.9699 137.0358 137.1493 138.4517 136.1642        138.0296\n6  2023-06-01 138.0238 136.7819 136.8636 138.1019 135.4245        138.0017\n7  2023-07-01 138.1266 136.5787 136.6226 137.6429 134.6685        138.0306\n8  2023-08-01 138.2634 136.4161 136.4194 137.2340 133.8945        138.1067\n9  2023-09-01 138.4240 136.2860 136.2479 137.1719 133.1041        138.2206\n10 2023-10-01 138.6010 136.1818 136.1034 136.8711 132.2964        138.3655\n11 2023-11-01 138.7896 136.0984 135.9814 136.3246 131.4715        138.5355\n12 2023-12-01 138.9862 136.0317 135.8785 135.6699 130.6291        138.7260\n    SSARIMA      CES  Real\n1  139.2007 139.3564 140.1\n2  138.6589 139.3693 138.6\n3  138.3537 139.1938 137.5\n4  138.0741 139.0305 135.5\n5  137.7256 138.7970 133.5\n6  137.4945 138.4592 132.0\n7  137.2962 138.1714 130.8\n8  137.0682 137.8984 132.1\n9  136.8996 137.8457 132.4\n10 136.7586 137.7236 131.9\n11 136.6072 137.3798 130.9\n12 136.4868 137.0202 129.5\n\n# Transformer les donn√©es en format long\ndf_real_long &lt;- pivot_longer(df_real, cols = -Date, names_to = \"Model\", values_to = \"Value\")\n\n# graphique plotly\nr &lt;- ggplot(df_real_long, aes(x = Date, y = Value, color = Model)) +\n  geom_line() +\n  theme_minimal() +\n  labs(title = \"Comparaison des pr√©visions des mod√®les avec les donn√©es r√©elles\n       Jan 2023 √† D√©c 2023\",\n       x = \"Date\",\n       y = \"Valeur\",\n       color = \"Mod√®le\") +\n  theme(legend.position = \"bottom\") \n\n\nggplotly(r)"
  },
  {
    "objectID": "posts/post-with-code/techniques_previsions/prevision_conjoncture.html#estimation-de-modeles-s√©rie-corrig√©-non-stationnaire",
    "href": "posts/post-with-code/techniques_previsions/prevision_conjoncture.html#estimation-de-modeles-s√©rie-corrig√©-non-stationnaire",
    "title": "Techniques de pr√©vision et conjoncture",
    "section": "Estimation de modeles s√©rie corrig√© (non stationnaire)",
    "text": "Estimation de modeles s√©rie corrig√© (non stationnaire)\n\n#lissage exponentiel double (Holt-Winters sans composante saisonni√®re)\nhw2 &lt;- HoltWinters(ipampa, gamma = FALSE)\nforecast_hw2 &lt;- forecast(hw2, h=12)\n\n\n# ADAM ETS\nae2 &lt;- auto.adam(ipampa, model=\"ZZN\", lags=c(1,12), select=TRUE)\nforecast_ae2 &lt;- forecast(ae2, h=12)\nforecast_ae2\n\n          Jan      Feb      Mar      Apr      May      Jun      Jul      Aug\n2023 126.7765 126.1885 125.7088 125.3099 124.9850 124.7247 124.5021 124.3216\n          Sep      Oct      Nov      Dec\n2023 124.1825 124.0705 123.9908 123.9301\n\n# ADAM ETS+ARIMA \naea2 &lt;- auto.adam(ipampa, model=\"ZZN\", lags=c(1,12), orders=list(ar=c(3,3), i=(2), ma=c(3,3), select=TRUE))\nforecast_aea2 &lt;- forecast(aea2 , h=12)\nforecast_aea2\n\n          Jan      Feb      Mar      Apr      May      Jun      Jul      Aug\n2023 126.7696 126.1926 125.7184 125.3222 124.9997 124.7338 124.5137 124.3542\n          Sep      Oct      Nov      Dec\n2023 124.2174 124.1099 124.0127 123.9390\n\n# SSARIMA\nssarima2 &lt;- auto.ssarima(ipampa, lags=c(1,12), orders=list(ar=c(3,3), i=(2), ma=c(3,3), select=TRUE))\nforecast_ssarima2 &lt;- forecast(ssarima2 , h=12)\nforecast_ssarima2\n\n         Point forecast Lower bound (2.5%) Upper bound (97.5%)\nJan 2023       126.8350           125.7776            127.8923\nFeb 2023       126.3923           124.3689            128.4157\nMar 2023       125.9496           122.9206            128.9786\nApr 2023       125.5069           121.3936            129.6203\nMay 2023       125.0643           119.7833            130.3452\nJun 2023       124.6216           118.0916            131.1516\nJul 2023       124.1789           116.3217            132.0361\nAug 2023       123.7362           114.4770            132.9955\nSep 2023       123.2935           112.5607            134.0264\nOct 2023       122.8508           110.5759            135.1258\nNov 2023       122.4082           108.5252            136.2912\nDec 2023       121.9655           106.4110            137.5199\n\n#ces\nces2 &lt;- auto.ces(ipampa, models=c(\"n\", \"s\", \"p\", \"f\"), ic=\"AICc\")\nforecast_ces2 &lt;- forecast(ces2 , h=12)\nforecast_ces2\n\n         Point forecast Lower bound (2.5%) Upper bound (97.5%)\nJan 2023       128.0169           126.6153            129.4185\nFeb 2023       128.4711           126.4840            130.4581\nMar 2023       128.9841           126.5364            131.4319\nApr 2023       129.2816           126.4542            132.1091\nMay 2023       129.6860           126.5145            132.8574\nJun 2023       129.7981           126.3225            133.2738\nJul 2023       129.9620           126.1984            133.7255\nAug 2023       130.1308           126.1051            134.1564\nSep 2023       130.6903           126.4112            134.9694\nOct 2023       130.9689           126.4554            135.4824\nNov 2023       131.2151           126.4719            135.9583\nDec 2023       131.2254           126.2677            136.1830\n\n# Naive model\nforecast_naive2 &lt;- naive(ipampa,h=12)\nforecast_naive2\n\n         Point Forecast    Lo 80    Hi 80    Lo 95    Hi 95\nJan 2023       127.4637 126.4812 128.4461 125.9611 128.9662\nFeb 2023       127.4637 126.0743 128.8530 125.3388 129.5885\nMar 2023       127.4637 125.7620 129.1653 124.8612 130.0661\nApr 2023       127.4637 125.4988 129.4285 124.4586 130.4687\nMay 2023       127.4637 125.2668 129.6605 124.1039 130.8234\nJun 2023       127.4637 125.0572 129.8702 123.7832 131.1441\nJul 2023       127.4637 124.8643 130.0630 123.4883 131.4390\nAug 2023       127.4637 124.6849 130.2424 123.2139 131.7134\nSep 2023       127.4637 124.5163 130.4110 122.9561 131.9712\nOct 2023       127.4637 124.3569 130.5704 122.7122 132.2151\nNov 2023       127.4637 124.2052 130.7221 122.4803 132.4470\nDec 2023       127.4637 124.0603 130.8670 122.2587 132.6686\n\nipampa\n\n          Jan      Feb      Mar      Apr      May      Jun      Jul      Aug\n2005  78.2000  78.5000  79.1000  79.3000  78.9000  79.4000  79.8000  80.0000\n2006  80.8000  81.1000  81.3000  81.8000  81.8000  81.8000  81.9000  82.1000\n2007  82.6000  83.1000  83.8000  84.5000  84.8000  85.1000  85.8000  86.6000\n2008  93.2000  94.4000  95.7000  96.9000  98.8000 100.2000 101.3000 100.6000\n2009  95.4000  94.8000  93.9000  93.5000  92.7000  92.2000  90.8000  90.7000\n2010  89.5000  89.8000  90.4000  91.0000  91.2000  91.4000  91.3000  92.1000\n2011  98.0000  99.4000 100.6000 101.0000 100.4000 100.6000 101.0000 100.9000\n2012 100.6000 101.2000 101.9000 102.3000 102.3000 101.8000 103.1000 105.1000\n2013 106.4000 106.8000 106.4000 105.7000 105.4000 105.0000 104.6000 104.2000\n2014 102.9000 103.0000 103.1000 103.3000 103.3000 103.1000 102.5000 102.1000\n2015  99.1000  98.9605  99.1605  99.5605  99.7605  99.0605  98.6605  98.1605\n2016  96.2605  95.9605  96.0605  95.8605  96.3605  96.2605  95.7605  95.3605\n2017  97.0605  97.4605  97.3605  97.5605  97.1605  96.5605  96.3605  96.4605\n2018  98.5605  98.5605  98.8605  99.5605 100.4605 100.3605 100.6605 101.1605\n2019 102.0605 102.5605 102.8605 103.0605 102.8605 102.2605 102.1605 101.7605\n2020 102.0605 101.8605 100.7605 100.1605 100.1605 100.2605 100.2605 100.2605\n2021 102.9605 104.8605 106.0605 106.3605 106.9605 108.0605 109.3605 110.0605\n2022 118.8184 120.6184 122.2437 123.6437 125.1437 127.6437 127.2437 127.9437\n          Sep      Oct      Nov      Dec\n2005  80.5000  80.7000  80.3000  80.4000\n2006  81.9000  82.1000  82.3000  82.5000\n2007  88.1000  89.5000  91.1000  91.9000\n2008 100.6000  99.5000  97.7000  95.8000\n2009  90.1000  89.7000  89.4000  89.3000\n2010  93.7000  95.0000  95.6000  96.6000\n2011 101.3000 101.3000 101.2000 101.0000\n2012 106.0000 106.5000 106.4000 106.3000\n2013 103.7000 103.0000 102.7000 102.7000\n2014 101.6000 101.0000 100.4000  99.5000\n2015  98.0605  97.9605  97.7605  96.7605\n2016  95.4605  95.8605  95.6605  96.7605\n2017  96.8605  97.3605  97.6605  97.7605\n2018 102.0605 103.0605 102.9605 102.2605\n2019 102.1605 102.0605 101.7605 101.9605\n2020  99.9605 100.5605 101.0605 101.5605\n2021 111.6605 113.2184 115.2184 116.2184\n2022 128.5437 128.6354 128.6579 127.4637\n\n\n\nR√©cuperation des previsions\n\n## R√©cup√©ration des \"points forecastes\" dans un seul dataframe\nstart_date &lt;- as.Date(\"2023-01-01\") # La date de d√©but des pr√©visions\nforecast_horizon &lt;- 12 # Le nombre de mois √† pr√©voir\n\n# s√©quence de dates pour les pr√©visions\nforecast_dates &lt;- seq(start_date, by = \"month\", length.out = forecast_horizon)\n\n#  data frames avec les dates et les previsions\ndf2 &lt;- data.frame(\n  Date = forecast_dates,\n  AR1 = dec_2022 + cumsum(df$AR1),\n  ARP = dec_2022 + cumsum(df$ARP),\n  ARIMA = dec_2022 + cumsum(df$ARIMA),\n  HOLT_WINTER = as.numeric(forecast_hw2$mean),\n ADAM_ETS = as.numeric(forecast_ae2$mean),\n ADAM_ETS_SARIMA = as.numeric(forecast_aea2$mean),\n SSARIMA =  as.numeric(forecast_ssarima2$mean),\n CES = as.numeric(forecast_ces2$mean),\n NAIVE = as.numeric(forecast_naive2$mean)\n)\n\ndf2$Real = real_2023\n\n\n# Transformer les donn√©es en format long\ndf_long2 &lt;- pivot_longer(df2, cols = -Date, names_to = \"Model\", values_to = \"Value\")\n\n# graphique plotly\np &lt;- ggplot(df_long2, aes(x = Date, y = Value, color = Model)) +\n  geom_line() +\n  theme_minimal() +\n  labs(title = \"Comparaison des pr√©visions des mod√®les avec les donn√©es r√©elles\n       Jan 2023 √† D√©c 2023 - s√©rie corrig√©e\",\n       x = \"Date\",\n       y = \"Valeur\",\n       color = \"Mod√®le\") +\n  theme(legend.position = \"bottom\") \n\nggplotly(p)\n\n\n\n\n\nR√©cup√©ration des donn√©es completes de janvier 2005 √† d√©cembre 2023\n\nip &lt;- ipampa1[nrow(ipampa1):1,]\nip &lt;- ip[, 2]\nip &lt;- ts(data = ip, start = c(2005, 01), frequency=12) \nip\n\n       Jan   Feb   Mar   Apr   May   Jun   Jul   Aug   Sep   Oct   Nov   Dec\n2005  78.2  78.5  79.1  79.3  78.9  79.4  79.8  80.0  80.5  80.7  80.3  80.4\n2006  80.8  81.1  81.3  81.8  81.8  81.8  81.9  82.1  81.9  82.1  82.3  82.5\n2007  82.6  83.1  83.8  84.5  84.8  85.1  85.8  86.6  88.1  89.5  91.1  91.9\n2008  93.2  94.4  95.7  96.9  98.8 100.2 101.3 100.6 100.6  99.5  97.7  95.8\n2009  95.4  94.8  93.9  93.5  92.7  92.2  90.8  90.7  90.1  89.7  89.4  89.3\n2010  89.5  89.8  90.4  91.0  91.2  91.4  91.3  92.1  93.7  95.0  95.6  96.6\n2011  98.0  99.4 100.6 101.0 100.4 100.6 101.0 100.9 101.3 101.3 101.2 101.0\n2012 100.6 101.2 101.9 102.3 102.3 101.8 103.1 105.1 106.0 106.5 106.4 106.3\n2013 106.4 106.8 106.4 105.7 105.4 105.0 104.6 104.2 103.7 103.0 102.7 102.7\n2014 102.9 103.0 103.1 103.3 103.3 103.1 102.5 102.1 101.6 101.0 100.4  99.5\n2015  99.1 100.5 100.7 101.1 101.3 100.6 100.2  99.7  99.6  99.5  99.3  98.3\n2016  97.8  97.5  97.6  97.4  97.9  97.8  97.3  96.9  97.0  97.4  97.2  98.3\n2017  98.6  99.0  98.9  99.1  98.7  98.1  97.9  98.0  98.4  98.9  99.2  99.3\n2018 100.1 100.1 100.4 101.1 102.0 101.9 102.2 102.7 103.6 104.6 104.5 103.8\n2019 103.6 104.1 104.4 104.6 104.4 103.8 103.7 103.3 103.7 103.6 103.3 103.5\n2020 103.6 103.4 102.3 101.7 101.7 101.8 101.8 101.8 101.5 102.1 102.6 103.1\n2021 104.5 106.4 107.6 107.9 108.5 109.6 110.9 111.6 113.2 117.5 119.5 120.5\n2022 123.1 124.9 133.2 134.6 136.1 138.6 138.2 138.9 139.5 142.0 141.3 139.6\n2023 140.1 138.6 137.5 135.5 133.5 132.0 130.8 132.1 132.4 131.9 130.9 129.5"
  },
  {
    "objectID": "posts/post-with-code/techniques_previsions/prevision_conjoncture.html#s√©rie-complete-corrig√©e",
    "href": "posts/post-with-code/techniques_previsions/prevision_conjoncture.html#s√©rie-complete-corrig√©e",
    "title": "Techniques de pr√©vision et conjoncture",
    "section": "S√©rie complete corrig√©e",
    "text": "S√©rie complete corrig√©e\n\n# Automatic Procedure for Detection of Outliers\ntso(ip)\n\nSeries: ip \nRegression with ARIMA(1,1,1) errors \n\nCoefficients:\n         ar1      ma1   LS202   LS207   TC214\n      0.8275  -0.2803  2.7628  6.6897  2.3709\ns.e.  0.0557   0.1008  0.5046  0.5038  0.4368\n\nsigma^2 = 0.3418:  log likelihood = -198.09\nAIC=408.17   AICc=408.56   BIC=428.72\n\nOutliers:\n  type ind    time coefhat  tstat\n1   LS 202 2021:10   2.763  5.475\n2   LS 207 2022:03   6.690 13.278\n3   TC 214 2022:10   2.371  5.429\n\nfit_ip &lt;- tso(ip)\n\n# outlier-adjusted series\nip_corrige &lt;- fit_ip$yadj\nip_corrige\n\n          Jan      Feb      Mar      Apr      May      Jun      Jul      Aug\n2005  78.2000  78.5000  79.1000  79.3000  78.9000  79.4000  79.8000  80.0000\n2006  80.8000  81.1000  81.3000  81.8000  81.8000  81.8000  81.9000  82.1000\n2007  82.6000  83.1000  83.8000  84.5000  84.8000  85.1000  85.8000  86.6000\n2008  93.2000  94.4000  95.7000  96.9000  98.8000 100.2000 101.3000 100.6000\n2009  95.4000  94.8000  93.9000  93.5000  92.7000  92.2000  90.8000  90.7000\n2010  89.5000  89.8000  90.4000  91.0000  91.2000  91.4000  91.3000  92.1000\n2011  98.0000  99.4000 100.6000 101.0000 100.4000 100.6000 101.0000 100.9000\n2012 100.6000 101.2000 101.9000 102.3000 102.3000 101.8000 103.1000 105.1000\n2013 106.4000 106.8000 106.4000 105.7000 105.4000 105.0000 104.6000 104.2000\n2014 102.9000 103.0000 103.1000 103.3000 103.3000 103.1000 102.5000 102.1000\n2015  99.1000 100.5000 100.7000 101.1000 101.3000 100.6000 100.2000  99.7000\n2016  97.8000  97.5000  97.6000  97.4000  97.9000  97.8000  97.3000  96.9000\n2017  98.6000  99.0000  98.9000  99.1000  98.7000  98.1000  97.9000  98.0000\n2018 100.1000 100.1000 100.4000 101.1000 102.0000 101.9000 102.2000 102.7000\n2019 103.6000 104.1000 104.4000 104.6000 104.4000 103.8000 103.7000 103.3000\n2020 103.6000 103.4000 102.3000 101.7000 101.7000 101.8000 101.8000 101.8000\n2021 104.5000 106.4000 107.6000 107.9000 108.5000 109.6000 110.9000 111.6000\n2022 120.3372 122.1372 123.7475 125.1475 126.6475 129.1475 128.7475 129.4475\n2023 129.8342 128.5782 127.6490 125.7685 123.8522 122.4108 121.2518 122.5805\n          Sep      Oct      Nov      Dec\n2005  80.5000  80.7000  80.3000  80.4000\n2006  81.9000  82.1000  82.3000  82.5000\n2007  88.1000  89.5000  91.1000  91.9000\n2008 100.6000  99.5000  97.7000  95.8000\n2009  90.1000  89.7000  89.4000  89.3000\n2010  93.7000  95.0000  95.6000  96.6000\n2011 101.3000 101.3000 101.2000 101.0000\n2012 106.0000 106.5000 106.4000 106.3000\n2013 103.7000 103.0000 102.7000 102.7000\n2014 101.6000 101.0000 100.4000  99.5000\n2015  99.6000  99.5000  99.3000  98.3000\n2016  97.0000  97.4000  97.2000  98.3000\n2017  98.4000  98.9000  99.2000  99.3000\n2018 103.6000 104.6000 104.5000 103.8000\n2019 103.7000 103.6000 103.3000 103.5000\n2020 101.5000 102.1000 102.6000 103.1000\n2021 113.2000 114.7372 116.7372 117.7372\n2022 130.0475 130.1765 130.1878 128.9857\n2023 122.9006 122.4146 121.4245 120.0314\n\nip_20023 &lt;-  window(ip_corrige, start = c(2023, 1), end = c(2023, 12))\nip_20023 # recuperation des donnes pour 2023 de la s√©rie corrig√© \n\n          Jan      Feb      Mar      Apr      May      Jun      Jul      Aug\n2023 129.8342 128.5782 127.6490 125.7685 123.8522 122.4108 121.2518 122.5805\n          Sep      Oct      Nov      Dec\n2023 122.9006 122.4146 121.4245 120.0314"
  },
  {
    "objectID": "posts/post-with-code/techniques_previsions/prevision_conjoncture.html#graphique-pr√©visions-de-modeles-compar√©s-au-donn√©es-corrig√©s",
    "href": "posts/post-with-code/techniques_previsions/prevision_conjoncture.html#graphique-pr√©visions-de-modeles-compar√©s-au-donn√©es-corrig√©s",
    "title": "Techniques de pr√©vision et conjoncture",
    "section": "Graphique Pr√©visions de modeles compar√©s au donn√©es corrig√©s",
    "text": "Graphique Pr√©visions de modeles compar√©s au donn√©es corrig√©s\n\ndec_2022 &lt;- 128.9857 # derniere valeur observ√©, pour la reintegration\n\n#  data frames avec les dates et les pr√©visions\ndf2 &lt;- data.frame(\n  Date = forecast_dates,\n  AR1 = dec_2022 + cumsum(df$AR1),\n  ARP = dec_2022 + cumsum(df$ARP),\n  ARIMA = dec_2022 + cumsum(df$ARIMA),\n  HOLT_WINTER = as.numeric(forecast_hw2$mean),\n ADAM_ETS = as.numeric(forecast_ae2$mean),\n ADAM_ETS_SARIMA = as.numeric(forecast_aea2$mean),\n SSARIMA =  as.numeric(forecast_ssarima2$mean),\n CES = as.numeric(forecast_ces2$mean),\n NAIVE = as.numeric(forecast_naive2$mean),\n corrige = as.numeric(ip_20023) # on integre les donn√©es corrig√©s\n)\n\ndf2\n\n         Date      AR1      ARP    ARIMA HOLT_WINTER ADAM_ETS ADAM_ETS_SARIMA\n1  2023-01-01 128.2190 128.2553 128.3163    126.8253 126.7765        126.7696\n2  2023-02-01 127.7501 127.6288 127.7517    126.1869 126.1885        126.1926\n3  2023-03-01 127.4887 127.1352 127.2755    125.5485 125.7088        125.7184\n4  2023-04-01 127.3718 126.7386 126.8738    124.9101 125.3099        125.3222\n5  2023-05-01 127.3556 126.4215 126.5350    124.2717 124.9850        124.9997\n6  2023-06-01 127.4095 126.1676 126.2493    123.6333 124.7247        124.7338\n7  2023-07-01 127.5123 125.9644 126.0083    122.9950 124.5021        124.5137\n8  2023-08-01 127.6491 125.8018 125.8051    122.3566 124.3216        124.3542\n9  2023-09-01 127.8097 125.6717 125.6336    121.7182 124.1825        124.2174\n10 2023-10-01 127.9867 125.5675 125.4891    121.0798 124.0705        124.1099\n11 2023-11-01 128.1753 125.4841 125.3671    120.4414 123.9908        124.0127\n12 2023-12-01 128.3719 125.4174 125.2642    119.8030 123.9301        123.9390\n    SSARIMA      CES    NAIVE  corrige\n1  126.8350 128.0169 127.4637 129.8342\n2  126.3923 128.4711 127.4637 128.5782\n3  125.9496 128.9841 127.4637 127.6490\n4  125.5069 129.2816 127.4637 125.7685\n5  125.0643 129.6860 127.4637 123.8522\n6  124.6216 129.7981 127.4637 122.4108\n7  124.1789 129.9620 127.4637 121.2518\n8  123.7362 130.1308 127.4637 122.5805\n9  123.2935 130.6903 127.4637 122.9006\n10 122.8508 130.9689 127.4637 122.4146\n11 122.4082 131.2151 127.4637 121.4245\n12 121.9655 131.2254 127.4637 120.0314\n\n# Transformer les donn√©es en format long\ndf_long2 &lt;- pivot_longer(df2, cols = -Date, names_to = \"Model\", values_to = \"Value\")\n\n# graphique plotly\np &lt;- ggplot(df_long2, aes(x = Date, y = Value, color = Model)) +\n  geom_line() +\n  theme_minimal() +\n  labs(title = \"Comparaison des pr√©visions  avec les donn√©es corrig√©es\n       Jan 2023 √† D√©c 2023 - s√©rie corrig√©e\",\n       x = \"Date\",\n       y = \"Valeur\",\n       color = \"Mod√®le\") +\n  theme(legend.position = \"bottom\") \n\nggplotly(p)"
  },
  {
    "objectID": "posts/post-with-code/techniques_previsions/prevision_conjoncture.html#pr√©vision-modele-holt-winter",
    "href": "posts/post-with-code/techniques_previsions/prevision_conjoncture.html#pr√©vision-modele-holt-winter",
    "title": "Techniques de pr√©vision et conjoncture",
    "section": "Pr√©vision modele Holt Winter",
    "text": "Pr√©vision modele Holt Winter\n\ncheckresiduals(forecast_hw2)\n\n\n\n\n\n\n\n\n\n    Ljung-Box test\n\ndata:  Residuals from HoltWinters\nQ* = 23.15, df = 24, p-value = 0.511\n\nModel df: 0.   Total lags used: 24\n\nforecast_hw2$mean\n\n          Jan      Feb      Mar      Apr      May      Jun      Jul      Aug\n2023 126.8253 126.1869 125.5485 124.9101 124.2717 123.6333 122.9950 122.3566\n          Sep      Oct      Nov      Dec\n2023 121.7182 121.0798 120.4414 119.8030\n\ndf2$corrige\n\n [1] 129.8342 128.5782 127.6490 125.7685 123.8522 122.4108 121.2518 122.5805\n [9] 122.9006 122.4146 121.4245 120.0314"
  },
  {
    "objectID": "posts/welcome/bienvenue.html",
    "href": "posts/welcome/bienvenue.html",
    "title": "Bienvenue sur mon blog!",
    "section": "",
    "text": "Ce blog a √©t√© cr√©√© pour vous pr√©senter quelques-uns des projets sur lesquels j‚Äôai eu l‚Äôoccasion de travailler au cours de mon Master en √âconom√©trie et Statistiques, parcours √âconom√©trie Appliqu√©e, √† l‚ÄôIAE de Nantes.\n\nPr√©sentation\nPour me pr√©senter rapidement, je suis en pleine reconversion professionnelle. Apr√®s plusieurs ann√©es d‚Äôexp√©rience en vente, j‚Äôai rejoint le groupe Iliad (Free). Cette exp√©rience, combinant innovation et gestion d‚Äô√©quipe, m‚Äôa permis de d√©velopper mes comp√©tences commerciales et manag√©riales. Bien que j‚Äôaie √©t√© √©panouie dans mon r√¥le de manager, responsable d‚Äôune surface de vente et d‚Äôune √©quipe, j‚Äôai ressenti le besoin de me sp√©cialiser davantage et d‚Äô√©largir mes horizons.\nC‚Äôest ainsi que j‚Äôai pris la d√©cision de reprendre mes √©tudes, en obtenant une rupture conventionnelle pour me lancer dans une nouvelle aventure acad√©mique. D√®s le mois d‚Äôavril, j‚Äôai int√©gr√© la formation DESU ‚ÄúData Science pour les professionnels‚Äù √† l‚ÄôUniversit√© d‚ÄôAix-Marseille, qui se poursuit jusqu‚Äôen juin. Fortement motiv√©e par l‚Äôenvie d‚Äôapprofondir mes connaissances en statistique et informatique, j‚Äôai ensuite choisi de poursuivre en Master √âconom√©trie et Statistiques.\n\n\nLe master\n\nCe parcours √† l‚ÄôIAE est particuli√®rement attractif en raison de son approche professionnalisante, qui allie √† la fois la th√©orique et la pratique. Il vise √† d√©velopper des comp√©tences solides dans des domaines tels que l‚Äô√©conomie, l‚Äô√©conom√©trie, la statistique et l‚Äôinformatique, des atouts indispensables pour √©voluer dans le domaine du data science et de l‚Äôanalyse quantitative. üì• T√©l√©charger ‚ÄúPr√©sentation du Master √©conometrie et statistiques, √©conometrie appliqu√©e M1 et M2‚Äù PDF\nActuellement, je suis √† la recherche d‚Äôun stage de fin d‚Äô√©tudes pour concr√©tiser ce parcours et mettre en pratique les comp√©tences acquises durant ma formation.\nCe blog vous permettra de d√©couvrir mes projets et travaux r√©alis√©s, au cours desquels j‚Äôai souhait√© explorer divers sujets qui me passionnent, tels que l‚Äôagriculture, l‚Äôenvironnement, ainsi que diff√©rentes techniques d‚Äôanalyse de donn√©es. Pour certains de ces projets, j‚Äôai voulu non seulement vous pr√©senter les r√©sultats de l‚Äôanalyse, mais aussi partager le code utilis√©. Mon objectif est de rendre la d√©marche plus transparente, tout en illustrant mon √©volution.\nJe vous souhaite une bonne visite et j‚Äôesp√®re que vous trouverez ici des √©l√©ments int√©ressants :) !"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Portfolio Isabel",
    "section": "",
    "text": "Bienvenue sur mon blog!\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nM√©moire\n\n\n\n\n\n\nS√©ries temporelles\n\n\nR\n\n\nMCO\n\n\nARMAX\n\n\n\n\n\n\n\n\n\nJun 12, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nPackage olympicsWeather\n\n\nPr√©visions m√©t√©orologiques des sites olympiques\n\n\n\nPackage\n\n\n\n\n\n\n\n\n\nJun 1, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nTechniques de pr√©vision et conjoncture\n\n\n\n\n\n\nS√©ries temporelles\n\n\nARIMA\n\n\nADAM\n\n\nARMAX\n\n\nCES\n\n\nLED\n\n\n\n\n\n\n\n\n\nApr 1, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nVariables latentes\n\n\nDiscrimination des saumons suivant leur provenance\n\n\n\nClassifaction\n\n\nACP\n\n\nPLS-DA\n\n\n\n\n\n\n\n\n\nMar 1, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nBiostatistiques\n\n\n\n\n\n\nImputation\n\n\nMICE\n\n\nR√©gression\n\n\nACP\n\n\n\n\n\n\n\n\n\nFeb 1, 2024\n\n\nC. ORHAN, Isabel PALACIO\n\n\n\n\n\n\n\n\n\n\n\n\n√âconom√©trie lin√©aire avanc√©e\n\n\n\n\n\n\nR√©gression\n\n\nMCO\n\n\nQuestionnaire\n\n\n\n\n\n\n\n\n\nJan 1, 2024\n\n\nJ. DUPAU, V. Trillaud, Isabel PALACIO\n\n\n\n\n\n\n\n\n\n\n\n\nECAP Master1\n\n\n\n\n\n\n\n\n\n\n\nJan 1, 2023\n\n\n\n\n\n\nNo matching items"
  }
]