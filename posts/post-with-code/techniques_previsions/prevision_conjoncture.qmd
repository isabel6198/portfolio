---
title: "Techniques de prÃ©vision et conjoncture"
author: "Isabel PALACIO"
date: "2024-04"
editor: visual
categories: [SÃ©ries temporelles,ARIMA, ADAM, ARMAX, CES, LED]
image: "agricole.jpg"
---

**Ã‰volution de l'indice des prix d'achat des moyens de production agricole en France**

**Janvier 2005 â€“ DÃ©cembre 2023**

### RÃ©sumÃ©

Lâ€™indice des Prix d'Achat des Moyens de Production Agricole (IPAMPA) joue un roÌ‚le treÌ€s important dans l'eÌconomie agricole en offrant un apercÌ§u des couÌ‚ts auxquels les agriculteurs sont confronteÌs. En 2023, les agriculteurs europeÌens en Pologne, Roumanie, Slovaquie, Hongrie, Bulgarie, ainsi qu'en France, ont eÌteÌ confronteÌs aÌ€ des deÌfis marqueÌs par des conditions climatiques extreÌ‚mes et une forte concurrence due aux importations aÌ€ bas prix en provenance de l'Ukraine, consideÌreÌes comme une Â« concurrence deÌloyale Â». Ces tensions surviennent apreÌ€s une anneÌe 2022 difficile, marqueÌe par des reÌserves en eau basses et des perturbations climatiques qui ont fortement impacteÌ les rendements agricoles.

Dans ce contexte, comprendre l'eÌvolution de l'IPAMPA ne concerne pas uniquement les acteurs du secteur agricole. En effet, les variations de cet indice ont eÌgalement des reÌpercussions sur les prix aÌ€ la consommation. Tout changement dans les couÌ‚ts de production se reÌpercute, apreÌ€s un certain deÌlai, sur les prix finaux, influencÌ§ant ainsi le couÌ‚t de la vie geÌneÌrale. Face aÌ€ cette complexiteÌ, notre projet s'est concentreÌ sur la preÌvision de l'IPAMPA aÌ€ l'aide de plusieurs modeÌ€les de preÌvision statistique. Nous avons exploreÌ diverses approches pour identifier le modeÌ€le le plus performant en fonction des speÌcificiteÌs de nos donneÌes.

L'objectif principal de notre eÌtude a eÌteÌ de confronter ces modeÌ€les aux donneÌes reÌelles afin d'eÌvaluer leur capaciteÌ aÌ€ preÌdire preÌciseÌment les fluctuations de l'IPAMPA. Ce processus nous permet non seulement de comprendre les deÌfis associeÌs aÌ€ la preÌvision de cet indice, mais aussi d'appreÌhender les difficulteÌs aÌ€ deÌvelopper un outil preÌdictif fiable.

::: {style="text-align: center;"}
<iframe src="/pdf/prevision.pdf" width="80%" height="500px">

</iframe>
:::

Vous avez la possibilitÃ© de tÃ©lÃ©charger le document ici :) [ğŸ“¥ TÃ©lÃ©charger le fichier PDF](/pdf/prevision.pdf)

**PrÃ©sentation du code**

Je vous prÃ©sente ci-dessous, le code utilisÃ© pour mener Ã  bien ce projet, avec les Ã©tapes et explications correspondantes.

# Analyse exploratoire

### Librairies

```{r}
suppressPackageStartupMessages({
library(readxl)
library(tsoutliers)
library(TSA)
library(seastests)
library(forecast)
library(seasonal)
library(RJDemetra)
library(ggplot2)
library(EnvStats)
library(tseries)
library(smooth)
library(timeSeries)
library(plotly)
library(dplyr)
library(tidyr)
library(Kendall) 
library(here)
})
```

### RÃ©cupÃ©ration des donnÃ©es

```{r}
ipampa1 <- read_excel(here("data", "serie_ipampa.xlsx"), sheet = 'complete')

ipampa <- read_excel(here("data", "serie_ipampa.xlsx"))
str(ipampa)
ipampa <- ipampa[nrow(ipampa):1,]
ipampa <- ipampa[, 2]
ipampa

```

## CrÃ©ation de la sÃ©rie temporelle

```{r}
ipampa <- ts(data = ipampa, start = c(2005, 01), frequency=12) 
```

## Visualisation

```{r}
show(ipampa)
plot(ipampa, xlab = "AnnÃ©es", ylab ="indice 'IPAMPA'", main= "SÃ©rie brute")

```

Graphique avec ggplot

```{r}

ts_df <- data.frame(Date = time(ipampa), Value = as.numeric(ipampa))

# graphique ggplot
ggplot(data = ts_df, aes(x = Date, y = Value)) + 
  geom_line(aes(color = Value)) +  
  scale_color_gradient(low = "darkgreen", high = "red") +  
  labs(title = "
Indice mensuel des prix d'achat 
des moyens de production agricole (IPAMPA)",
       x = "PÃ©riode\n(01/2005 - 12/2022)", y = "Indice") +
  theme_minimal() +
  theme(legend.position = "right",
        plot.title = element_text(size = 8),
        axis.title.x = element_text(size = 8),
        axis.title.y = element_text(size = 8),
        legend.title = element_text(size = 7))  


```

## DÃ©tection outliers

```{r}
# Automatic Procedure for Detection of Outliers
tso(ipampa)
fit <- tso(ipampa)
plot(fit)
show(fit)

```

## SÃ©rie corrigÃ©e

```{r}
par(mfrow=c(1,1))

# outlier-adjusted series
ipampa <- fit$yadj
plot(ipampa, main= "SÃ©rie adjustÃ©e", xlab= "AnnÃ©es", ylab ="indice 'IPAMPA")
```

Existence de 4 outliers 3 type LS et un type TC

## Tests de saisonnalitÃ©

```{r}
# Friedman test
ft <- fried(ipampa)
show(ft)

# Testing the seasonality of series
#  a boolean value is returned : TRUE or FALSE
is <- isSeasonal(ipampa, test="wo")
show(is)

# Kruskal-Wallis test
kwt <- kw(ipampa)
show(kwt)

# Seasonal dummies
# impotant 
sd <- seasdum(ipampa)
show(sd)


# Webel-Ollech test
# Webel-Ollech test - new version of seastests (2021-09)
# impotant 

wot <- combined_test(ipampa)
show(wot)
```

Les tests confirment la non saisonnalitÃ© de la sÃ©rie IPAMPA

### Graphique

```{r}
# Trace une sÃ©rie chronologique avec son acf et soit son pacf, son nuage de points dÃ©calÃ© ou son spectre
ggtsdisplay(ipampa, plot.type="histogram")

# Trace un graphique saisonnier oÃ¹ les donnÃ©es sont comparÃ©es aux saisons d'annÃ©es distinctes
# ggseasonplot(ipampa_ts, col=rainbow(12), year.labels=TRUE)
```

## VÃ©rification de la stationnaritÃ©

### stationnaritÃ© de ipampa

```{r}
adf.test(ipampa)
```

La sÃ©rie n'est pas stationnaire car le test ADF \> 0.05

Vu que notre sÃ©rie ne presente pas de saisonalitÃ©, nous allons faire un analyse sur la tendance

```{r}
decomp <- decompose(ipampa)
plot(decomp)
```

## Tendance

```{r}
# test de tendence serie niveau
MannKendall(ipampa)

```

Dans notre cas, Ï„ = 0.568 suggÃ¨re une tendance croissante modÃ©rÃ©ment forte dans la sÃ©rie temporelle Ã  niveau, avec un p_value infÃ©rieur Ã  0,05 on peut dire que la sÃ©rie initial presente bien une tendance

### differentiation de la sÃ©rie

```{r}
d_ipampa <- diff(ipampa, differences = 1)
```

```{r}
# graphique ggplot
df <- data.frame(Date = time(d_ipampa), Value = as.numeric(d_ipampa))

# graphique ggplot
ggplot(data = df, aes(x = Date, y = Value)) + 
  geom_line(aes(color = Value)) +  
  scale_color_gradient(low = "darkgreen", high = "red") +  
  labs(title = "SÃ©rie differenciÃ©e",
       x = "Dates", y = "Indice") +
  theme_minimal() +
  theme(legend.position = "right",
        plot.title = element_text(size = 8),
        axis.title.x = element_text(size = 8),
        axis.title.y = element_text(size = 8),
        legend.title = element_text(size = 7))  


```

### Correlogramme sÃ©rie brute et sÃ©rie differenciÃ©

```{r}
par(mfrow=c(1,2))
acf(ipampa, main="Correlogramme sur la sÃ©rie en niveau")
acf(d_ipampa, main="Correlogramme sur la sÃ©rie en diffÃ©rence premiÃ¨re")
```

### Periodogramme

```{r}
# Periodogramme
par(mfrow=c(1,2))
periodogram(ipampa, main="Periodogramme sur la sÃ©rie en niveau")
periodogram(d_ipampa, main="Periodogramme sur la sÃ©rie en diffÃ©rence premiÃ¨re")
```

## Test de stationnaritÃ© de la sÃ©rie diffÃ©renciÃ© ipampa

```{r}
adf.test(d_ipampa)
```

Apres la diffÃ©rentiation la sÃ©rie devient bien stationnaire

```{r}
decomp <- decompose(ipampa)
decomp_d <- decompose(d_ipampa)

graph1 <- plot(decomp)
graph2 <- plot(decomp_d)


```

## Statistiques descriptives

```{r}
summary(d_ipampa)

#histogramme
hist(d_ipampa, main= "Histogramme sÃ©rie corrigÃ©", ylab=" FrÃ©quence", xlab="indice")

#skewness 
PerformanceAnalytics::skewness(d_ipampa)

#kurtosis 
PerformanceAnalytics::kurtosis(d_ipampa)
e1071::kurtosis(d_ipampa)

#normalitÃ©
stats::shapiro.test(d_ipampa)

#boxplot
boxplot(d_ipampa, main="Boxplot")
#test outliers
rosnerTest(d_ipampa, k=10)

```

Le test de shapiro, indique que notre sÃ©rie ne suit pas une loi normal

Le box plot nous indique des possibles outliers. La vÃ©rification avec le test de rosner nous indique que finalement il n'y pas

# Estimation des modÃ¨les linÃ©aires

ModÃ¨les AR(1), AR(p) et ARIMA(p,d,q) et de la mÃ©thode LED Holt-Winters, ADAM ETS, ADAM ETS SARIMA, SSARIMA et CES

### ModÃ¨le AR(1)

```{r}
# Parametres modele AR(1)
ar1 <- auto.arima(d_ipampa, max.p=1, max.q=0, d=0, stationary = TRUE, seasonal = FALSE, ic = "aic", stepwise = TRUE,  trace = TRUE)
# Estimation
summary(ar1)


checkresiduals(ar1)

```

Nombre de retards pour le test Ljung-BOx: 24, ce test permet de vÃ©rifier si les rÃ©sidus de notre modÃ¨le sont effectivement du bruit blanc (c'est-Ã -dire non corrÃ©lÃ©s et avec une moyenne constante et une variance constante). Ici la P_value est de 0,354 donc \> 0,05 ; Il n'y a pas suffisamment de preuves pour rejeter l'hypothÃ¨se selon laquelle les rÃ©sidus du modÃ¨le ARIMA(1,0,0) sont indÃ©pendants. Les rÃ©sidus du modÃ¨le ne prÃ©sentent pas d'autocorrÃ©lation significative Ã  aucun des dÃ©calages testÃ©s.

### ModÃ¨le AR(p)

```{r}
# Parametres modele AR(p)
arp <- auto.arima(d_ipampa, max.q=0, d=0, stationary = TRUE, seasonal = FALSE, ic = "aic", stepwise = TRUE,  trace = TRUE)
# Estimation
summary(arp)


checkresiduals(arp)
```

### ModÃ¨le ARIMA(p,d,q)

```{r}
# Parametres modele AR(p,d,q)
arima <- auto.arima(d_ipampa, stationary = TRUE, seasonal = FALSE, ic = "aic", stepwise = TRUE,  trace = TRUE)
# Estimation
summary(arima)


```

### ModÃ¨le Holt-Winter

```{r}
# un lissage exponentiel double (Holt-Winters sans composante saisonniÃ¨re)
# premier modele
holtw_model <- HoltWinters(d_ipampa,gamma=FALSE) 
holtw_model
summary(holtw_model)

 # modÃ¨le Holt-Winters package forecaste - deuxieme modele 
hw_f <- hw(d_ipampa, seasonal = NULL)
summary(hw_f)

hw_ff <- forecast(hw_f, h=12)
plot(hw_f$mean)

checkresiduals(hw_ff)


```

ModÃ¨le Holt - nous testons un troisiÃ¨me modele, avec la fonction Holt de forecast

```{r}
# Ajustement du modÃ¨le de Holt
#holtW <- holt(d_ipampa, h=12)
#summary(holtW)

#  rÃ©sidus
#checkresiduals(holtW)


```

### ModÃ¨le ADAM ETS

```{r}

# 1er ADAM ETS
adam_ets <- auto.adam(d_ipampa, model="ZZN", lags=c(1,12), 
                      select=TRUE, ic = "AIC")

# Message d'avertissement 
"Warning messages:
1: The data is not strictly positive, so not all the distributions make sense. Dropping dlnorm, dinvgauss, dgamma. 
2: Only additive models are allowed for your data. Changing the selection mechanism"

# estimation
summary(adam_ets)

# deuxieme adam_ets pour eviter le message d'avertissement 
adam_ets <- auto.adam(d_ipampa, model="AAN",  select=TRUE, ic = "AIC", distribution = c("dnorm"), bootstrap=TRUE, control=list(maxit=1000, trace=TRUE),orders=list(ar=c(0), i = c(0), ma = c(0)))

summary(adam_ets)

"Warning message:
Observed Fisher Information is not positive semi-definite, which means that the likelihood was not maximised properly. Consider reestimating the model, tuning the optimiser or using bootstrap via bootstrap=TRUE."

# troicieme adam_ets  modÃ¨le ADAM sans saisonnalitÃ©
# adam_ets <-auto.adam(d_ipampa, model="ANN", select=TRUE, ic="AIC", bootstrap=TRUE, distribution = c("dnorm", "dlaplace"), control=list(maxit=1000, trace=TRUE))

#summary(adam_ets)


```

### ModÃ¨le ADAM ETS ARIMA

```{r}
# premier test model ADAM ETS SARIMA
adam_ets_sa <- auto.adam(d_ipampa, model="ZZN", lags=c(1,1,12), orders=list(ar=c(3,3), i=c(0), ma=c(3,3), select=TRUE))
summary(adam_ets_sa)

"Warning messages:
1: The data is not strictly positive, so not all the distributions make sense. Dropping dlnorm, dinvgauss, dgamma. 
2: Only additive models are allowed for your data. Changing the selection mechanism.  "
# apres modification pour Ã©viter les message d'avertisment 
adam_ets_sa <- auto.adam(d_ipampa, model="AAN", lags=c(1,1,12), orders=list(ar=c(3,3), i=c(0), ma=c(3,3), select=TRUE), distribution = c("dnorm", "dlaplace"))
summary(adam_ets_sa)

"Warning message:
Observed Fisher Information is not positive semi-definite, which means that the likelihood was not maximised properly. Consider reestimating the model, tuning the optimiser or using bootstrap via bootstrap=TRUE. "

# Modele choisi
adam_ets_sa <- auto.adam(d_ipampa, model="ANN", lags=c(1,1,12), orders=list(ar=c(3,3), i=c(0), ma=c(3,3), select=TRUE), distribution=c("dnorm", "dlaplace"), bootstrap=TRUE,control=list(maxit=3000))
summary(adam_ets_sa)


summary(adam_ets_sa)
forecast(adam_ets_sa, h=12)

# meme apres avoir reduit la complexitÃ© du modele cela donne l'avertissement 
#adam_ets_sa_Test <- auto.adam(d_ipampa, model="ANN", lags=c(1,12), orders=list(ar=c(1,1), i=c(0), ma=c(1,1),select=TRUE), distribution=c("dnorm", "dlaplace"), bootstrap=TRUE, bootstrap=TRUE, control=list(maxit=3000))

#forecast(adam_ets_sa_Test, h=12)

#?auto.adam()
```

si l'on veut Ã©viter l'avertissement il faut mettre model = 'ANN', mais cela implique que les prÃ©vision sont toutes Ã©gales. sur le graphique cela donne une ligne droite

forecast(adam_ets_sa_Test, h=12) Jan Feb Mar Apr May 2023 -0.588298 -0.588298 -0.588298 -0.588298 -0.588298 Jun Jul Aug Sep Oct 2023 -0.588298 -0.588298 -0.588298 -0.588298 -0.588298 Nov Dec 2023 -0.588298 -0.588298

On continue avec l'avertissement ...

### ModÃ¨le SSARIMA

```{r}
# SSARIMA
ssarima <- auto.ssarima(d_ipampa, lags=c(1,12), orders=list(ar=c(3,3), i=(0), ma=c(3,3), select=TRUE), ic="AICc")
ssarima 
summary(ssarima)
?auto.ssarima()
```

### ModÃ¨le CES

```{r}
# auto 
ces <- auto.ces(d_ipampa, models=c("n", "s", "p", "f"), ic="AICc") #  tester plusieurs types de modÃ¨les 
summary(ces)
ces

checkresiduals(ces)

#?auto.ces()
```

### ModÃ¨le NaÃ¯f

```{r}
naive <- naive(d_ipampa, h=12)
summary(naive)
```

# PrÃ©visions

```{r}

# PrÃ©vision et tracÃ© pour le modÃ¨le AR(1)
ar1_forecast <- forecast(ar1, h=12)
plot(ar1_forecast, main="PrÃ©vision pour le modÃ¨le AR(1)", xlab="Mois", ylab="Valeurs", col="blue")

# PrÃ©vision et tracÃ© pour le modÃ¨le AR(p)
arp_forecast <- forecast(arp, h=12)
plot(arp_forecast, main="PrÃ©vision pour le modÃ¨le AR(p)", xlab="Mois", ylab="Valeurs", col="blue")

# PrÃ©vision et tracÃ© pour le modÃ¨le ARIMA
arima_forecast <- forecast(arima, h=12)
plot(arima_forecast, main="PrÃ©vision pour le modÃ¨le ARIMA", xlab="Mois", ylab="Valeurs", col="blue")

# PrÃ©vision et tracÃ© pour le modÃ¨le Holt (LED Holt sans saisonnalitÃ©)
#holt_forecast <- forecast(holtw_model, h=12, interval="confidence", level = 0.90)
#plot(holt_forecast, main="PrÃ©vision pour le modÃ¨le Holt", xlab="Mois", ylab="Valeurs", col="purple")


hw_forecast <- forecast(hw_f, h=12)
plot(hw_forecast, main="PrÃ©vision pour le modÃ¨le Holt Winter", xlab="Mois", ylab="Valeurs", col="blue")


# PrÃ©vision et tracÃ© pour le modÃ¨le ADAM ETS
adam_ets_forecast <- forecast(adam_ets, h=12, interval="confidence", level = 0.90)
plot(adam_ets_forecast, main="PrÃ©vision pour le modÃ¨le ADAM ETS", xlab="Mois", ylab="Valeurs", col="blue")

# PrÃ©vision et tracÃ© pour le modÃ¨le ADAM ES 
adamES_forecast <- forecast(adam_ets_sa, h=12, level = 0.90)
plot(adamES_forecast, main="PrÃ©vision pour le modÃ¨le ADAM ETS SARIMA", xlab="Mois", ylab="Valeurs", col="blue")


# PrÃ©vision et tracÃ© pour le modÃ¨le SSARIMA - State Space ARIMA
ssarima_forecast <- forecast(ssarima, h=12,  level = 0.90)
plot(ssarima_forecast, main="PrÃ©vision pour le modÃ¨le SSARIMA", xlab="Mois", ylab="Valeurs", col="blue")

# PrÃ©vision et tracÃ© pour le modÃ¨le CES
ces_forecast <- forecast(ces, h=12,  level = 0.90)
plot(ces_forecast, main="PrÃ©vision pour le modÃ¨le CES", xlab="Mois", ylab="Valeurs", col="blue")

# Graphique prÃ©vsion modele naive

plot(naive, main=" MÃ©thode de PrÃ©vision NaÃ¯ve", xlab="Temps", ylab="Valeurs")



```

## RÃ©cupÃ©ration des "points forecastes" dans un seul dataframe

```{r}
start_date <- as.Date("2023-01-01") # La date de dÃ©but des prÃ©visions
forecast_horizon <- 12 # Le nombre de mois Ã  prÃ©voir

# sÃ©quence de dates pour les prÃ©visions
forecast_dates <- seq(start_date, by = "month", length.out = forecast_horizon)

#  data frames avec les dates et les previsions
df <- data.frame(
  Date = forecast_dates,
  AR1 = as.numeric(ar1_forecast$mean),
  ARP = as.numeric(arp_forecast$mean),
  ARIMA =as.numeric(arima_forecast$mean),
  HOLT = as.numeric(hw_forecast$mean),
  ADAM_ETS = as.numeric(adam_ets_forecast$mean),
  ADAM_ETS_SARIMA = as.numeric(adamES_forecast$mean),
  SSARIMA =  as.numeric(ssarima_forecast$mean),
  CES = as.numeric(ces_forecast$mean),
  NAIVE = as.numeric(naive$mean)
)

df
```

## Recuperation des donnÃ©es 2023

Lors du TÃ©lÃ©chargement de notre jeu de donnÃ©es nous nous sommes arrÃªtÃ©s au mois de dÃ©cembre 2022 et mis de cotÃ© les donnÃ©es pour l'annÃ©e 2023, on rÃ©cupÃ¨re les donnÃ©es pour les comparer aux modÃ¨les

```{r}
real <- read_excel(here("data", "serie_ipampa.xlsx"), sheet = 'complete')
real <- real[nrow(real):1,]
real <- real[, 2]
real <- ts(data = real, start = c(2005, 01), frequency=12) 


real_2023 <- window(real, start = c(2023, 1), end = c(2023, 12))
real_2023
real_d <- diff(real, differences = 1)

real_d <- window(real_d, start = c(2023, 1), end = c(2023, 12))
plot(real_d)

real_d <- as.numeric(real_d)
df$Real = real_d
df
names (df) # on verifie que real fait bien partie du data frame 
```

Graphique de comparaison

```{r}

# Transformer les donnÃ©es en format long
df_long <- pivot_longer(df, cols = -Date, names_to = "Model", values_to = "Value")

# graphique plotly
p <- ggplot(df_long, aes(x = Date, y = Value, color = Model)) +
  geom_line() +
  theme_minimal() +
  labs(title = "Comparaison des prÃ©visions des modÃ¨les avec les donnÃ©es rÃ©elles
       Jan 2023 Ã  DÃ©c 2023 - sÃ©rie differenciÃ©",
       x = "Date",
       y = "Valeur",
       color = "ModÃ¨le") +
  theme(legend.position = "bottom") 


ggplotly(p)

```

### RÃ©intÃ©gration

Nous pouvons reintegrer les prÃ©visions aux donnÃ©es pour avoir le graphique au niveau

```{r}
dec_2022 <- 139.6

df_real <- data.frame(
    Date = forecast_dates,
    AR1 = dec_2022 + cumsum(df$AR1),
    ARP = dec_2022 + cumsum(df$ARP),
    ARIMA = dec_2022 + cumsum(df$ARIMA),
    HOLT = dec_2022 + cumsum(df$HOLT),
    ADAM_ETS = dec_2022 + cumsum(df$ADAM_ETS),
    ADAM_ETS_SARIMA = dec_2022 + cumsum(df$ADAM_ETS_SARIMA),
    SSARIMA = dec_2022 + cumsum(df$SSARIMA),
    CES = dec_2022 + cumsum(df$CES)
    )

real_2023 <- as.numeric(real_2023)
df_real$Real = real_2023
df_real



# Transformer les donnÃ©es en format long
df_real_long <- pivot_longer(df_real, cols = -Date, names_to = "Model", values_to = "Value")

# graphique plotly
r <- ggplot(df_real_long, aes(x = Date, y = Value, color = Model)) +
  geom_line() +
  theme_minimal() +
  labs(title = "Comparaison des prÃ©visions des modÃ¨les avec les donnÃ©es rÃ©elles
       Jan 2023 Ã  DÃ©c 2023",
       x = "Date",
       y = "Valeur",
       color = "ModÃ¨le") +
  theme(legend.position = "bottom") 


ggplotly(r)

```

# QualiteÌ de preÌvision

```{r}
# Erreur de prÃ©vision , comparatif entre la valeur predicte de chaque modele et la valeur real 
models <- names(df)[-which(names(df) == "Date" | names(df) == "Real")]
# Calculer l'erreur pour chaque modÃ¨le
errors_df <- data.frame(Date = df$Date)  # nouveau dataframe pour stocker les erreurs
for (model in models) {
  errors_df[[model]] <- df[[model]] - df$Real
}

errors_df
```

### CSPE somme cumulative des erreurs pour chaque modÃ¨le et graphique

```{r}

# errors_df contienne dÃ©jÃ  les erreurs pour chaque modÃ¨le calculÃ©es comme prÃ©cÃ©demment
cspe_df <- data.frame(Date = df$Date)  #  nouveau dataframe pour stocker le CSPE

for (model in models) {
  cspe_df[[model]] <- cumsum(errors_df[[model]])  # Calcul du CSPE 
}

cspe_df

#  on pivot cspe_df pour l'utiliser avec ggplot2
cspe_long <- tidyr::pivot_longer(cspe_df, cols = -Date, names_to = "Model", values_to = "CSPE")


ggplot(cspe_long, aes(x = Date, y = CSPE, color = Model)) +
  geom_line() +
  geom_hline(yintercept = 0, linetype = "dashed", color = "black") +
  labs(title = "Cumulative Sum of Prediction Errors (CSPE) pour chaque modÃ¨le",
       x = "Date",
       y = "CSPE") +
  theme_minimal() +
  theme(legend.position = "bottom")


```

### Calcul du R2OOS pour chaque modÃ¨le

```{r}
calculate_r2oos <- function(actual, predicted, naive_predictions) {
  ss_res <- sum((actual - predicted)^2)  # Somme des carrÃ©s des erreurs de prÃ©diction
  ss_tot <- sum((actual - naive_predictions)^2)  # Somme des carrÃ©s des erreurs du modÃ¨le naÃ¯f
  r2_oos <- 1 - ss_res / ss_tot
  return(r2_oos)
}

# DataFrame pour stocker le R^2 OOS de chaque modÃ¨le
r2oos_df <- data.frame(Model = character(), R2OOS = numeric())

# R^2 OOS pour chaque modÃ¨le, avec modÃ¨le naÃ¯f comme rÃ©fÃ©rence
models <- setdiff(names(df), c("Date", "Real", "NAIVE"))  # Exclure Date, Real, et NAIVE de la liste des modÃ¨les

for (model in models) {
  r2oos_value <- calculate_r2oos(df$Real, df[[model]], df$NAIVE)
  r2oos_df <- rbind(r2oos_df, data.frame(Model = model, R2OOS = r2oos_value))
}

r2oos_df

```

### Calcul du MSE pour chaque modÃ¨le

```{r}
# dataFrame pour stocker le MSE de chaque modÃ¨le
mse_df <- data.frame(Model = character(), MSE = numeric())

for (model in models) {
  mse_value <- mean((errors_df[[model]])^2)  # Calcul du MSE
  mse_df <- rbind(mse_df, data.frame(Model = model, MSE = mse_value))
}

mse_df
```

### DM test

```{r}

# DataFrame pour stocker les rÃ©sultats du 
dm_results <- data.frame(Model = character(), DM_Statistic = numeric(), P_Value = numeric(), stringsAsFactors = FALSE)

# DM test pour chaque modÃ¨le comparÃ© au modÃ¨le naÃ¯f
for (model in setdiff(models, "NAIVE")) {
  dm_test_result <- dm.test(errors_df$NAIVE, errors_df[[model]], alternative = "less")
  
#  rÃ©sultats
dm_results <- rbind(dm_results, data.frame(Model = model, DM_Statistic = dm_test_result$statistic, P_Value = dm_test_result$p.value))}

dm_results

?dm.test()
```

### Accuracy

```{r}
# dataframe pour stocker les rÃ©sultats d'accuracy
accuracy_results <- data.frame(Model = character(), 
                               ME = numeric(), 
                               RMSE = numeric(), 
                               MAE = numeric(), 
                               MPE = numeric(),
                               MAPE = numeric())

models <- setdiff(names(df), c("Real", "Date"))  
# Calcul de l'accuracy pour chaque modÃ¨le
for (model in models) { acc <- accuracy(df[[model]], df$Real)
#  rÃ©sultats au dataframe des rÃ©sultats
accuracy_results <- rbind(accuracy_results, data.frame(Model = model,ME = acc[1, "ME"], RMSE = acc[1, "RMSE"],MAE = acc[1, "MAE"], MPE = acc[1, "MPE"], APE = acc[1, "MAPE"]))
}

accuracy_results

```

## Estimation de modeles sÃ©rie corrigÃ© (non stationnaire)

```{r}

#lissage exponentiel double (Holt-Winters sans composante saisonniÃ¨re)
hw2 <- HoltWinters(ipampa, gamma = FALSE)
forecast_hw2 <- forecast(hw2, h=12)


# ADAM ETS
ae2 <- auto.adam(ipampa, model="ZZN", lags=c(1,12), select=TRUE)
forecast_ae2 <- forecast(ae2, h=12)
forecast_ae2


# ADAM ETS+ARIMA 
aea2 <- auto.adam(ipampa, model="ZZN", lags=c(1,12), orders=list(ar=c(3,3), i=(2), ma=c(3,3), select=TRUE))
forecast_aea2 <- forecast(aea2 , h=12)
forecast_aea2

# SSARIMA
ssarima2 <- auto.ssarima(ipampa, lags=c(1,12), orders=list(ar=c(3,3), i=(2), ma=c(3,3), select=TRUE))
forecast_ssarima2 <- forecast(ssarima2 , h=12)
forecast_ssarima2
#ces
ces2 <- auto.ces(ipampa, models=c("n", "s", "p", "f"), ic="AICc")
forecast_ces2 <- forecast(ces2 , h=12)
forecast_ces2


# Naive model
forecast_naive2 <- naive(ipampa,h=12)
forecast_naive2

ipampa
```

### RÃ©cuperation des previsions

```{r}
## RÃ©cupÃ©ration des "points forecastes" dans un seul dataframe
start_date <- as.Date("2023-01-01") # La date de dÃ©but des prÃ©visions
forecast_horizon <- 12 # Le nombre de mois Ã  prÃ©voir

# sÃ©quence de dates pour les prÃ©visions
forecast_dates <- seq(start_date, by = "month", length.out = forecast_horizon)

#  data frames avec les dates et les previsions
df2 <- data.frame(
  Date = forecast_dates,
  AR1 = dec_2022 + cumsum(df$AR1),
  ARP = dec_2022 + cumsum(df$ARP),
  ARIMA = dec_2022 + cumsum(df$ARIMA),
  HOLT_WINTER = as.numeric(forecast_hw2$mean),
 ADAM_ETS = as.numeric(forecast_ae2$mean),
 ADAM_ETS_SARIMA = as.numeric(forecast_aea2$mean),
 SSARIMA =  as.numeric(forecast_ssarima2$mean),
 CES = as.numeric(forecast_ces2$mean),
 NAIVE = as.numeric(forecast_naive2$mean)
)

df2$Real = real_2023


# Transformer les donnÃ©es en format long
df_long2 <- pivot_longer(df2, cols = -Date, names_to = "Model", values_to = "Value")

# graphique plotly
p <- ggplot(df_long2, aes(x = Date, y = Value, color = Model)) +
  geom_line() +
  theme_minimal() +
  labs(title = "Comparaison des prÃ©visions des modÃ¨les avec les donnÃ©es rÃ©elles
       Jan 2023 Ã  DÃ©c 2023 - sÃ©rie corrigÃ©e",
       x = "Date",
       y = "Valeur",
       color = "ModÃ¨le") +
  theme(legend.position = "bottom") 

ggplotly(p)

```

RÃ©cupÃ©ration des donnÃ©es completes de janvier 2005 Ã  dÃ©cembre 2023

```{r}
ip <- ipampa1[nrow(ipampa1):1,]
ip <- ip[, 2]
ip <- ts(data = ip, start = c(2005, 01), frequency=12) 
ip
```

## SÃ©rie complete corrigÃ©e

```{r}
# Automatic Procedure for Detection of Outliers
tso(ip)
fit_ip <- tso(ip)

# outlier-adjusted series
ip_corrige <- fit_ip$yadj
ip_corrige

ip_20023 <-  window(ip_corrige, start = c(2023, 1), end = c(2023, 12))
ip_20023 # recuperation des donnes pour 2023 de la sÃ©rie corrigÃ© 
```

## Graphique PrÃ©visions de modeles comparÃ©s au donnÃ©es corrigÃ©s

```{r}

dec_2022 <- 128.9857 # derniere valeur observÃ©, pour la reintegration

#  data frames avec les dates et les prÃ©visions
df2 <- data.frame(
  Date = forecast_dates,
  AR1 = dec_2022 + cumsum(df$AR1),
  ARP = dec_2022 + cumsum(df$ARP),
  ARIMA = dec_2022 + cumsum(df$ARIMA),
  HOLT_WINTER = as.numeric(forecast_hw2$mean),
 ADAM_ETS = as.numeric(forecast_ae2$mean),
 ADAM_ETS_SARIMA = as.numeric(forecast_aea2$mean),
 SSARIMA =  as.numeric(forecast_ssarima2$mean),
 CES = as.numeric(forecast_ces2$mean),
 NAIVE = as.numeric(forecast_naive2$mean),
 corrige = as.numeric(ip_20023) # on integre les donnÃ©es corrigÃ©s
)

df2

# Transformer les donnÃ©es en format long
df_long2 <- pivot_longer(df2, cols = -Date, names_to = "Model", values_to = "Value")

# graphique plotly
p <- ggplot(df_long2, aes(x = Date, y = Value, color = Model)) +
  geom_line() +
  theme_minimal() +
  labs(title = "Comparaison des prÃ©visions  avec les donnÃ©es corrigÃ©es
       Jan 2023 Ã  DÃ©c 2023 - sÃ©rie corrigÃ©e",
       x = "Date",
       y = "Valeur",
       color = "ModÃ¨le") +
  theme(legend.position = "bottom") 

ggplotly(p)

```

# QualitÃ© de prÃ©vision 2

```{r}

# Erreur de prÃ©vision , comparatif entre la valeur predicte de chaque modele et la valeur real corrigÃ©
models2 <- names(df2)[-which(names(df2) == "Date" | names(df2) == "corrige")]
# erreur pour chaque modÃ¨le
errors_df2 <- data.frame(Date = df2$Date)  #  dataframe pour stocker les erreurs
for (m in models2) {
  errors_df2[[m]] <- df2[[m]] - df2$corrige
}
errors_df2

df2$corrige

```

### CSPE 2

```{r}

# errors_df contienne dÃ©jÃ  les erreurs pour chaque modÃ¨le calculÃ©es comme prÃ©cÃ©demment
cspe_df2 <- data.frame(Date = df2$Date)  #  nouveau dataframe pour stocker le CSPE

for (m in models2) {
  cspe_df2[[m]] <- cumsum(errors_df2[[m]])  # Calcul du CSPE 
}

cspe_df2

#  on pivot cspe_df2 pour l'utiliser avec ggplot2
cspe_long2 <- tidyr::pivot_longer(cspe_df2, cols = -Date,  names_to = "Model", values_to = "CSPE")


a<- ggplot(cspe_long2, aes(x = Date, y = CSPE, color = Model)) +
  geom_line() +
  geom_hline(yintercept = 0, linetype = "dashed", color = "black") +
  labs(title = "Cumulative Sum of Prediction Errors (CSPE) ",
       x = "Date",
       y = "CSPE") +
  theme_minimal() +
  theme(legend.position = "bottom")

 ggplotly(a)
```

### Calcul du R2OOS 2

```{r}

# DataFrame pour stocker le R^2 OOS de chaque modÃ¨le
r2oos_df2 <- data.frame(Model = character(), R2OOS = numeric())

# R^2 OOS pour chaque modÃ¨le, avec modÃ¨le naÃ¯f comme rÃ©fÃ©rence
models2 <- setdiff(names(df2), c("Date", "corrige", "NAIVE"))  # Exclure Date, corrige, et NAIVE de la liste des modÃ¨les

for (model in models2) {
  r2oos_value2 <- calculate_r2oos(df2$corrige, df2[[model]], df2$NAIVE) #on reutilise la fonction crÃ©e avant
  r2oos_df2 <- rbind(r2oos_df2, data.frame(Model = model, R2OOS = r2oos_value2))
}

r2oos_df2

```

### Calcul du MSE 2

```{r}
# dataFrame pour stocker le MSE de chaque modÃ¨le
mse_df2 <- data.frame(Model = character(), MSE = numeric())

for (model in models2) {
  mse_value2 <- mean((errors_df2[[model]])^2)  # Calcul du MSE
  mse_df2 <- rbind(mse_df2, data.frame(Model = model, MSE = mse_value2))
}

mse_df2
```

### DM test 2

```{r}
# DataFrame pour stocker les rÃ©sultats du 
dm_results2 <- data.frame(Model = character(), DM_Statistic = numeric(), P_Value = numeric(), stringsAsFactors = FALSE)

# DM test pour chaque modÃ¨le comparÃ© au modÃ¨le naÃ¯f
for (model in setdiff(models2, "NAIVE")) {
  dm_test_result2 <- dm.test(errors_df2$NAIVE, errors_df2[[model]], alternative = "less")
  
#  rÃ©sultats
dm_results2 <- rbind(dm_results2, data.frame(Model = model, DM_Statistic = dm_test_result2$statistic, P_Value = dm_test_result2$p.value))}

dm_results2

```

## PrÃ©vision modele Holt Winter

```{r}
checkresiduals(forecast_hw2)

forecast_hw2$mean
df2$corrige

```
