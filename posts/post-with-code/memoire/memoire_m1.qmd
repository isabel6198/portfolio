---
title: "M√©moire"
date: "2024-06-12"
format: 
  html:
    toc: true
    toc_float: 
      collapsed: false
      smooth_scroll: true
      css: styles.css
categories: [S√©ries temporelles, R, MCO, ARMAX]
---

**SensibiliteÃÅ des prix agricoles face aux chocs climatiques**

**SeÃÅries temporelles au BreÃÅsil de janvier 2000 aÃÄ deÃÅcembre 2022**

# **Pr√©sentation**

Cette √©tude analyse les prix des produits agricoles au Br√©sil, un acteur cl√© des enjeux agricoles mondiaux, en utilisant l'indice des prix √† la production agricole (IPA) de janvier 2000 √† d√©cembre 2022. L'√©tude a int√©gr√© des variables climatiques pour √©valuer leur impact, en utilisant des mod√®les de r√©gression tels que les Moindres Carr√©s Ordinaires (MCO) et ARMAX. Dans notre approche par les MCO, nous avons rencontr√© des difficult√©s telles que l'autocorr√©lation des r√©sidus et l'h√©t√©rosc√©dasticit√©. Malgr√© plusieurs tentatives, le mod√®le MCO n'a pas pu √™tre valid√© et nous avons adopt√© le mod√®le ARMAX qui s'est av√©r√© plus efficace. Les r√©sultats montrent que le taux de change, le prix du p√©trole et l'influence des valeurs pass√©es de l'IPA ont eu un impact statistiquement significatif. Nos recherches r√©v√®lent que, bien que les variables climatiques n'aient pas eu un effet notable, la complexit√© du syst√®me agricole sugg√®re qu'une approche globale et uniforme n'est pas ad√©quate. Ainsi, nous pr√©conisons, tant dans les √©tudes que dans l'√©laboration des strat√©gies, l'adoption de mesures localis√©es qui r√©pondent mieux aux besoins sp√©cifiques des communaut√©s agricoles.

**Mots cl√©s¬†*:*** *Prix agricoles, Br√©sil, MCO, ARMAX,¬† R*

### Sujet d‚Äô√©tude

Le Br√©sil, l'un des plus grands producteurs agricoles mondiaux, est √©galement riche en biodiversit√© et ressources environnementales. Toutefois, le pays est marqu√© par d'importantes disparit√©s √©conomiques et sociales, refl√©t√©es dans son secteur agricole qui se divise entre l'agriculture familiale et l'agrobusiness. Depuis 2000, les politiques br√©siliennes ont altern√© entre progr√®s et r√©gression. Sous Lula da Silva, des avanc√©es significatives ont √©t√© r√©alis√©es, tandis que les administrations suivantes ont vu des reculs, notamment avec la suppression de minist√®res cl√©s et la lib√©ralisation de la politique de r√©forme agraire. L'administration de Bolsonaro a augment√© les tensions entre d√©veloppement agricole et conservation environnementale, en particulier avec l'augmentation de la d√©forestation en Amazonie. En tant que membre des BRICS et du MERCOSUR, le Br√©sil joue un r√¥le important dans les discussions internationales. Le trait√© de libre-√©change entre l'UE et le MERCOSUR est un bon exemple de l'importance croissante du pays sur la sc√®ne internationale. L‚Äôobjectif est de comprendre les facteurs qui influencent les prix √† la production agricole du pays que beaucoup surnomment ¬´¬†la ferme du monde¬†¬ª.

### Pr√©sentation des donn√©es

Les donn√©es s'√©tendant de janvier 2000 √† d√©cembre 2022 avec une fr√©quence mensuelle, proviennent de trois sources : l'Institut de Recherche √âconomique Appliqu√©e (IPEA DATA), les Statistiques de l'ONU pour l'alimentation et l'agriculture (FAO STAT), et le Portail de connaissances sur le changement climatique de la Banque mondiale (CCKP). Les variables explicatives incluent les variations de temp√©rature (¬∞C), les pr√©cipitations (mm), le nombre de jours secs cons√©cutifs, le prix du p√©trole, le taux de change (BRL/USD), le salaire minimum nominal (SMIC), et les indices des exportations et importations agricoles.

Des statistiques descriptives ont mis en √©vidence une hausse marqu√©e de l‚ÄôIPA, particuli√®rement apr√®s 2016.

![](memoire_y.png)

Sur le plan climatique, les donn√©es indiquent des p√©riodes de s√©cheresse plus longues et des fluctuations de temp√©rature tendant vers des valeurs maximales. En ce qui concerne les variables √©conomiques, le prix du p√©trole a subi de fortes fluctuations au cours des deux derni√®res d√©cennies, principalement en raison du contexte g√©opolitique mondial. Le taux de change a connu une d√©valuation notable depuis 2019, en r√©ponse √† la crise du COVID-19, ce qui a contribu√© √† une augmentation exponentielle des exportations, accentuant une tendance d√©j√† forte depuis 2010. Un pr√©traitement de nos donn√©es a √©t√© n√©cessaire en raison de la pr√©sence de valeurs atypiques.

### M√©thodologie

Pour analyser les variations de l'IPA, nous avons utilis√© deux m√©thodes¬†: MCO et ARMAX. Afin d‚Äô√©viter les r√©gressions fallacieuses et assurer la validit√© de nos mod√®les, nous avons v√©rifi√© la stationnarit√© avec les tests ADF et KPSS.

Les s√©ries temporelles pr√©sentant une saisonnalit√© ont √©t√© d√©compos√©es afin de corriger les variations saisonni√®res, permettant de mieux isoler les effets des variables explicatives. Nous avons aussi utilis√© les tests de Breusch-Godfrey et Breusch-Pagan pour d√©tecter l'autocorr√©lation et l'h√©t√©rosc√©dasticit√©, le test de Kolmogorov-Smirnov pour la normalit√© des r√©sidus, et le test RESET pour la sp√©cification du mod√®le, confirmant l'ad√©quation des mod√®les et la fiabilit√© des estimations des coefficients.

Nous avons explor√© plusieurs mod√®les en utilisant l'approche MCO. Les probl√®mes d'h√©t√©rosc√©dasticit√© et de sp√©cificit√© ont √©t√© corrig√©s en adoptant une forme semi-logarithmique. Cependant, malgr√© diverses tentatives, telles que l'introduction d'une variable temporelle, la correction de la tendance d√©terministe, et l‚Äôajustement des r√©sidus avec un mod√®le AR(1), les mod√®les ont continu√© de pr√©senter une capacit√© explicative limit√©e et des probl√®mes de conformit√© aux hypoth√®ses. Nous avons alors opt√© pour des mod√®les ARMAX, lesquels int√®grent les effets des variables exog√®nes ainsi que la dynamique interne des s√©ries temporelles.

![](memoire_modeles.png)

Le mod√®le r√©v√®le que les valeurs futures de notre s√©rie temporelle sont significativement influenc√©es par les valeurs imm√©diatement ant√©rieures, avec un niveau de significativit√© de 1%. Par ailleurs, le prix du p√©trole est statistiquement significatif au seuil de risque de 5%. Avec un coefficient positif, lorsque les prix du p√©trole augmentent, l'indice IPA augmente √©galement. Il en est de m√™me pour le taux de change, cela signifie que lorsque le real br√©silien se d√©pr√©cie,¬† les prix √† la production agricole tendent √† augmenter.

Concernant les autres variables du mod√®le, elles ne montrent pas d'impact significatif . Quant √† notre variable climatique, la pr√©cipitation, elle s'est r√©v√©l√©e non significative, indiquant que , dans le cadre de cette √©tude,¬† les variations des pr√©cipitations n'ont pas un impact notable sur l'indice des prix √† la production agricole de mani√®re statistiquement mesurable.

### Conclusion et discussion

Cette √©tude nous a montr√© la complexit√© du syst√®me agricole br√©silien et, bien que nos r√©sultats n'aient pas √©t√© ceux attendus, cela peut s'expliquer par la mani√®re dont l'agriculture s'adapte aux changements climatiques. Alors que certaines r√©gions voient leur production agricole diminuer en raison de conditions d√©favorables, d'autres connaissent une augmentation ou d√©localisent leur production. Lorsque ces variations r√©gionales sont agr√©g√©es au niveau national, les impacts locaux peuvent √™tre masqu√©s, minimisant ainsi les effets perceptibles sur les prix nationaux.

Par ailleurs, les progr√®s technologiques en agriculture, bien qu'ils puissent am√©liorer les rendements et la gestion des cultures, introduisent une complexit√© suppl√©mentaire dans l'√©valuation des impacts directs du climat. Les innovations, comme les vari√©t√©s r√©sistantes √† la s√©cheresse et l'optimisation des intrants, ont renforc√© la r√©silience des cultures face aux al√©as climatiques, permettant de maintenir des niveaux de production √©lev√©s m√™me dans des conditions difficiles. Cependant, cette intensification pose des d√©fis environnementaux significatifs, tels que l'√©puisement des sols et une d√©pendance accrue aux produits chimiques, qui compliquent l'attribution pr√©cise des impacts du changement climatique dans les analyses √©conomiques agricoles.

Il est donc important de mettre en ≈ìuvre les avanc√©es technologiques de mani√®re r√©fl√©chie pour √©viter des cons√©quences ind√©sirables et de revoir les politiques agricoles pour assurer la durabilit√© et la s√©curit√© alimentaire dans un climat changeant, en adaptant les pratiques agricoles aux nouvelles r√©alit√©s climatiques et √©conomiques.

::: {style="text-align: center;"}
<iframe src="/pdf/memoire.pdf" width="80%" height="500px">

</iframe>
:::

Vous avez la possibilit√© de t√©l√©charger le document ici :) [üì• T√©l√©charger le fichier PDF](/pdf/memoire.pdf)

**Pr√©sentation du code**

Je vous pr√©sente ci-dessous, le code utilis√© pour mener √† bien ce projet, avec les √©tapes et explications correspondantes.

### Librairies

```{r}
suppressPackageStartupMessages({
library(readxl)
library(ggplot2)
library(plotly)
library(tidyr)
library(dplyr)
library(ggcorrplot)
library(PerformanceAnalytics)
library(trend)
library(seastests)
library(tseries)
library(forecast)
library(tsoutliers)
library(EnvStats)
library(RJDemetra)
library(TSA)
library(lubridate)
library(tsoutliers)
library(leaps)
library(MASS)
library(car)
library(lmtest)
library(BeSS)
library(nlme)
library(here)
})
```

# Analyse exploratoire

## Chargement de donn√©es

Les donn√©es de la variable du prix du p√©trole ont une fr√©quence journali√®re, nous calculons donc la moyenne pour avoir un prix moyen mensuel

```{r}

petrole <- read_excel(here("data", "donnees_br.xlsx"), sheet = 'prix_petrole')

petrole$date <- as.Date(petrole$date)

#  Colonnes pour l'ann√©e et le mois
petrole <- petrole %>%
  mutate(
    year = year(date),
    month = month(date)
  )

prix_petrole <- petrole %>%
  group_by(year, month) %>%
  summarise(
    prix_moyen = mean(prix, na.rm = TRUE), 
    .groups = 'drop'  # regroupement apr√®s le summarise
  )
rm(petrole) # supprime p√©trole en jours
```

R√©cup√©ration de l'ensemble de nos variables et remplacement de la variable prix du p√©trole en jours, par le prix moyen mensuel

```{r}
# ensemble de variables

data <- read_excel(here("data", "donnees_br.xlsx"))

data$petrole <- prix_petrole$prix_moyen 

```

### Valeurs manquantes et format des donn√©es

```{r}
sum(is.na(data)) # v√©rification des valeurs manquants
data <- drop_na(data)
dim(data)
str(data) # v√©rification format

# On transforme la variable smic en num√©rique
data$SMIC <- as.numeric(data$SMIC)


# Conversion la colonne de date en type  yearmon
data$date <- as.yearmon(data$date, "%Y.%m")

```

Les donn√©es climatiques sont compl√®tes jusqu'au mois de d√©cembre 2022, on conserve donc l'ensemble des donn√©es du mois de janvier 2000 √† d√©cembre 2022. Au total nous avons 276 observations pour 13 variables.

## Statistiques descriptives

```{r}
summary(data)
```

### Boxplot

```{r}
data|>
pivot_longer(
cols = where(is.numeric)
) |>
ggplot() +
aes(y = value) +
facet_wrap(~ name, scales = "free_y") +
geom_boxplot() +
theme_light()
```

### Graphiques des s√©ries

```{r}
data$date <- as.Date(as.yearmon(data$date))

# Boucle sur chaque colonne sauf la date pour cr√©er des graphiques
for (column_name in names(data)[-1]) {
p <- ggplot(data, aes(x = date, y = .data[[column_name]], colour = .data[[column_name]])) + 
        geom_line() +
        scale_color_gradient(low = "blue", high = "red") + 
        labs(title = paste("S√©rie temporelle: ", column_name),
             x = "Date",
             y = column_name,
             colour = "Intensit√©") +  
        theme_minimal()
 print(p)
}
    print(p)


```

### Convertir en time series

```{r}
# Boucle pour convertir chaque colonne en ts et les stocker comme variables s√©par√©es
for(column_name in names(data)[-1]) {  # Exclure la colonne de date
    # Cr√©er une s√©rie temporelle pour la colonne actuelle
    ts_data <- ts(data[[column_name]], start = c(2000, 1), frequency = 12)
  # variable dans l'environnement global avec un nom dynamique
    assign(paste0("ts_", column_name), ts_data)
}

```

## Points atypiques ou Outliers

(attention cela peut prendre quelques minutes, possibilit√© de charger le fichier apr√®s correction data.adj (pour donn√©es ajust√©es))

```{r}
#|warning: false
#|message: false

# on utilise tso() pour chercher les outliers
fit_CDD <- tso(ts_CDD)
fit_IPA <- tso(ts_IPA)
fit_importations <- tso(ts_importations)
fit_exportations <- tso(ts_exportations)
fit_petrole <- tso(ts_petrole)
fit_taux_change <- tso(ts_taux_change)
fit_SMIC <- tso(ts_SMIC)
fit_precipitation <- tso(ts_precipitation)
fit_temperature <- tso(ts_temperature)


# pour regarder les points atypiques de chaque serie 
fit_CDD # sans outliers 
fit_IPA 
fit_importations 
fit_exportations 
fit_petrole  # sans outliers
fit_taux_change 
fit_SMIC 
fit_precipitation 
fit_temperature # sans outliers

# Graphique
plot(fit_IPA)
plot(fit_SMIC)
plot(fit_precipitation)
plot(fit_taux_change)
plot(fit_exportations)
plot(fit_importations)
plot(fit_CDD )




# recuperation des s√©ries ajust√©s 
adj_IPA <- fit_IPA$yadj 
adj_CDD <- fit_CDD$yadj 
adj_importations <- fit_importations$yadj 
adj_exportations <- fit_exportations$yadj 
adj_petrole <- fit_petrole$yadj 
adj_taux_change <- fit_taux_change$yadj 
adj_SMIC <- fit_SMIC$yadj 
adj_precipitation <- fit_precipitation$yadj 
adj_temperature <- fit_temperature$yadj 


```

### Enregistrement donn√©es ajust√©s

```{r}
# cr√©ation d'un dataframe o√π les s√©ries ajust√©s seront stock√©s pour √™tres r√©utilises si n√©cessaire plus tard 
data_adj <- data.frame(
  Date = data$date,  
  IPA = adj_IPA,
  CDD = adj_CDD,
  importations = adj_importations,
  exportations = adj_exportations,
  petrole = adj_petrole,
  taux_change = adj_taux_change,
  SMIC = adj_SMIC,
  precipitation = adj_precipitation,
  temperature = adj_temperature
)

#write.csv(data_adj, "data_adj.csv", row.names = FALSE)


```

## R√©cup√©ration base de donn√©es ajust√©es

```{r}
#data_adj <- read.csv("/Users/Isabel/Desktop/memoire3/data_adj.csv")

data_adj$Date <- as.Date(data_adj$Date)


#  variables
variables <- c("IPA", "CDD", "precipitation", "temperature",  "exportations", "importations", "taux_change", "SMIC", "petrole")
```

### Skewness, kurtosis

```{r}

skew_kurt_df <- data.frame(
  Variable = variables,
  # Calcul de skewness
  Skewness = sapply(data_adj[variables], PerformanceAnalytics::skewness),
  # Calcul de kurtosis
  Kurtosis = sapply(data_adj[variables], PerformanceAnalytics::kurtosis)
)
skew_kurt_df

```

### Test de normalit√©

```{r}
#v√©rification de la normalit√© des variables 
lapply(data_adj[variables], shapiro.test)

```

### Corr√©lation

```{r}
#|warning: false
#|message: false

#  Matrice de corr√©lation
cor_matrix <- cor(data_adj[, variables], use = "complete.obs", method = "spearman")
cor_matrix
# Visualiser la matrice de corr√©lation

ggcorrplot(cor_matrix,
  hc.order = TRUE, type = "lower",
  lab = TRUE,
  ggtheme = ggplot2::theme_gray,
  colors = c("blue", "white", "red"))


# spearman correlation test
#chart.Correlation(data_adj[variables], histogram=TRUE, pch=19,method = c("spearman"))
```

Le calcul de la corr√©lation de Spearman est recommand√© lorsque les variables ne suivent pas une loi normaleÔÉ®ce type de corr√©lation est dit robuste car il ne d√©pend pas de la distribution des donn√©es. (cours M.Travers)

## Composants

Nous commen√ßons cette partie par deux tests : le premier est le test de tendance monotone de Mann-Kendall,et le deuxi√®me est le test de saisonalit√©

## Test de tendance Mann-Kendall

```{r}
# Test de tenance pour chaque variable 
lapply(data_adj[variables], function(x) {
  mk.test(x, alternative = "greater")
})
```

## Test Saisonni√®re

```{r}
# On transforme en format tsv
ts_data <- ts(data_adj[, 2:10], frequency = 12,  start = c(2000, 1))

## Verfication de la saisonnalit√© 
test_saison <- vector("logical", ncol(ts_data))  # vecteur pour stocker les r√©sultats
names(test_saison) <- colnames(ts_data)  # nomme les r√©sultats selon les variables

for (i in 1:ncol(ts_data)) {
  test_saison[i] <- isSeasonal(ts_data[, i], test = "wo")
}
test_saison

# Deuxi√®me test Seasonal dummies
for (i in 1:ncol(ts_data)) {
  nom_var <- colnames(ts_data)[i]
  result <- seasdum(ts_data[, i])
  cat("\nTest Seasonal dummies: ", nom_var, ":\n")
  print(result)
}

```

Les variables pressentant une saisonnalit√© d‚Äôapr√®s les tests sont CDD, importations, Exportations, Pr√©cipitation et temp√©rature

Le code ci-dessous et similaire √† celui que nous avons fait precedement pour transformer les variables en time series, on a besoin si nous t√©l√©chargeons le fichier data.adj

```{r}
# Boucle pour convertir chaque colonne en ts et les stocker comme variables s√©par√©es
for(column_name in names(data_adj)[-1]) {  # Exclure la colonne de date
    # Cr√©er une s√©rie temporelle pour la colonne actuelle
    ts_list <- ts(data_adj[[column_name]], start = c(2000, 1), frequency = 12)
  # variable dans l'environnement global avec un nom dynamique
    assign(paste0("ts_", column_name), ts_list)
}

```

### Correlogramme des variables saisonni√®res

```{r}
par(mfrow=c(2,2))

# ACF pour les variables presentant une saisonalit√© 
# CDD
acf(ts_CDD, main = "ACF CDD sur la s√©rie en niveau")
acf(diff(ts_CDD,differences = 1), main = "ACF CDD sur la s√©rie en diff√©rence premi√©re")
# Pr√©cipitation
acf(ts_precipitation, main = "ACF Precipitations sur la s√©rie en niveau")
acf(diff(ts_precipitation,differences = 1), main = "ACF Precipitations sur la s√©rie en diff√©rence premi√©re")
# T√©mperature
acf(ts_temperature, main = "ACF T√©mperature sur la s√©rie en niveau ")
acf(diff(ts_temperature,differences = 1), main = "ACF T√©mperature sur la s√©rie en diff√©rence premi√©re")
# Importations
acf(ts_importations, main = "ACF Importations sur la s√©rie en niveau")
acf(diff(ts_importations, differences = 1),main = "ACF Importations sur la s√©rie en diff√©rence premi√©re")
# Exportations
acf(ts_exportations, main = "ACF Exportations sur la s√©rie en niveau")
acf(diff(ts_exportations,differences = 1), main = "ACF Exportations sur la s√©rie en diff√©rence premi√©re")
```

### P√©riodogramme

```{r}
# P√©riodogramme ou filtre spectra pour les s√©rires presentant une saisonalit√©
# CDD
periodogram(ts_CDD, main = "P√©riodogramme CDD sur la s√©rie en niveau")
periodogram(diff(ts_CDD,differences = 1), main = "P√©riodogramme CDD sur la s√©rie en diff√©rence premi√©re")

# Precipitations
periodogram(ts_precipitation, main = "P√©riodogramme Precipitations sur la s√©rie en niveau")
periodogram(diff(ts_precipitation,differences = 1), main = "P√©riodogramme Precipitations sur la s√©rie en diff√©rence premi√©re")

# Temperature
periodogram(ts_temperature, main = "P√©riodogramme T√©mperature sur la s√©rie en niveau ")
periodogram(diff(ts_temperature,differences = 1), main = "P√©riodogramme T√©mperature sur la s√©rie en diff√©rence premi√©re")

# Importations
periodogram(ts_importations, main = "P√©riodogramme Importations sur la s√©rie en niveau")
periodogram(diff(ts_importations, differences = 1),main = "P√©riodogramme Importations sur la s√©rie en diff√©rence premi√©re")

# Exportations 
periodogram(ts_exportations, main = "P√©riodogramme Exportations sur la s√©rie en niveau")
periodogram(diff(ts_exportations,differences = 1), main = "P√©riodogramme Exportations sur la s√©rie en diff√©rence premi√©re")

```

```{r}
par(mfrow=c(1,2))

# Boxplots pour les variables climatiques avec les cycles correspondants √† chaque s√©rie
boxplot(ts_CDD ~ cycle(ts_CDD), main = "Bo√Æte √† moustaches des CDD par cycle", xlab = "Cycle", ylab = "CDD en jours")
boxplot(ts_precipitation ~ cycle(ts_precipitation), main = "Bo√Æte √† moustaches des pr√©cipitations par cycle", xlab = "Cycle", ylab = "Pr√©cipitations en mm")
boxplot(ts_temperature ~ cycle(ts_temperature), main = "Bo√Æte √† moustaches de la temp√©rature par cycle", xlab = "Cycle", ylab = "Variations de temp√©rature")

# Variables export - importation
boxplot(ts_importations ~ cycle(ts_importations), main = "Bo√Æte √† moustaches des importations par cycle", xlab = "Cycle", ylab = "Valeurs des importations")
boxplot(ts_exportations ~ cycle(ts_exportations), main = "Bo√Æte √† moustaches des exportations par cycle", xlab = "Cycle", ylab = "Valeurs des exportations")

```

## Test ADF

```{r}
#|warning: false
#|message: false

# test ADF 
lapply(data_adj[variables], function(x) {
  adf.test(x, alternative = "stationary")
})

```

### Graphiques des variables non stationnaires Test ADF

```{r}
# Graphique pour la s√©rie IPA
ggplot(data = data_adj, aes(x = Date, y = IPA)) +
  geom_line(color = "blue", size = 0.5) +
  stat_smooth(color = "red", fill = "red", method = "loess", show.legend = TRUE,  size = 0.2) +
  ggtitle("Analyse de la tendance de l'IPA-DI sur la p√©riode 01/2000 - 12/2022") +
  xlab("Date") +
  ylab("IPA Value") 


# Graphique pour la s√©rie petrole

ggplot(data = data_adj, aes(x = Date, y = petrole)) +
  geom_line(color = "blue", size = 0.5) +
  stat_smooth(color = "red", fill = "red", method = "loess", show.legend = TRUE, size = 0.2) +
  ggtitle("Analyse de la tendance du prix du p√©trole sur la p√©riode 01/2000 - 12/2022") +
  xlab("Date") +
  ylab("Petrole Value") 

# Graphique pour la s√©rie taux de change 

ggplot(data = data_adj, aes(x = Date, y = taux_change)) +
  geom_line(color = "blue", size = 0.5) +
  stat_smooth(color = "red", fill = "red", method = "loess", show.legend = TRUE, size = 0.2) +
  ggtitle("Analyse de la tendance du taux de change sur la p√©riode 01/2000 - 12/2022") +
  xlab("Date") +
  ylab("Taux de change") 


```

La fonction stat_smooth(method = "loess") ajoute une courbe de lissage aux donn√©es, utilisant la m√©thode LOESS (Locally Estimated Scatterplot Smoothing). Cette courbe est utile pour visualiser une tendance centrale plus lisse dans les donn√©es, ce qui peut √™tre particuli√®rement b√©n√©fique dans les cas o√π les donn√©es sont bruyantes ou volatiles

## Test KPSS

```{r}
#|warning: false
#|message: false

## Trend 
for (i in 1:ncol(ts_data)) {
  nom_var <- colnames(ts_data)[i]
  result <- kpss.test(ts_data[, i], null = "Trend")
  cat("\nTest KPSS: ", nom_var, ":\n")
  print(result)
}

## Level 
for (i in 1:ncol(ts_data)) {
  nom_var <- colnames(ts_data)[i]
  result <- kpss.test(ts_data[, i], null = "Level")
  cat("\nTest KPSS: ", nom_var, ":\n")
  print(result)
}


```

## Correction

Nous allons maintenant d√©terminer le type de sch√©ma des s√©ries, multiplicatif ou addif

```{r}
# Approche Graphique 
plot(ts_CDD)
plot(ts_precipitation)
plot(ts_temperature)
plot(ts_importations)
plot(ts_exportations)

#  Test log-level
regx13_CDD <- regarima_x13(ts_CDD, spec ="RG5c") 
s_transform(regx13_CDD)

regx13_precipitation <- regarima_x13(ts_precipitation, spec ="RG5c") 
s_transform(regx13_precipitation)

regx13_temperature <- regarima_x13(ts_temperature, spec ="RG5c") 
s_transform(regx13_temperature)

regx13_importations <- regarima_x13(ts_importations, spec ="RG5c") 
s_transform(regx13_importations)

regx13_exportations <- regarima_x13(ts_exportations, spec ="RG5c") 
s_transform(regx13_exportations)

```

Ce test est sp√©cifiquement con√ßu pour d√©cider si une transformation logarithmique des donn√©es est appropri√©e

### D√©composition

Utilisation de decompose pour une d√©composition additive

```{r}
# D√©composition 
decom_CDD <- decompose(ts_CDD, type="additive")
decom_precipitations<- decompose(ts_precipitation, type="additive")
decom_temperature <- decompose(ts_temperature, type="additive")
decom_importations <- decompose(ts_importations, type="additive")
decom_importations <- decompose(ts_importations, type="additive")
decom_exportations <- decompose(ts_exportations, type = "additive")

# Plot 


plot(decom_CDD)
plot(decom_temperature)
plot(decom_precipitations)
plot(decom_importations)
plot(decom_exportations)

```

Chacune de nos variables saisonni√®res est d√©compos√© en 'trend', 'seasonl', 'random'

### D√©saisonalitation

CDD

```{r}
CDD_deseason <- ts_CDD - decom_CDD$seasonal
cdd <- ts.intersect(ts_CDD, CDD_deseason)
# Graphique 
plot.ts(cdd, 
        plot.type = "single",
        col = c("red", "blue"),
        main = "CDD s√©rie originale (rouge) et d√©saisonnalis√©e (bleu)",
        xlab = "P√©riode",
        ylab= "Nombre de jours")

```

Temp√©rature

```{r}
temperature_deseason <- ts_temperature - decom_temperature$seasonal
temperature <- ts.intersect(ts_temperature, temperature_deseason)
# Graphique 
plot.ts(temperature, 
        plot.type = "single",
        col = c("red", "blue"),
        main = "T√©mperature s√©rie originale (rouge) et d√©saisonnalis√©e (bleu)",
        xlab = "P√©riode",
        ylab= "Variation de la t√©mperature")
```

Pr√©cipitations

```{r}
precipitations_deseason <- ts_precipitation - decom_precipitations$seasonal

precipitations <- ts.intersect(ts_precipitation, precipitations_deseason)
# Graphique 
plot.ts(precipitations, 
        plot.type = "single",
        col = c("red", "blue"),
        main = "Pr√©cipitations s√©rie originale (rouge) et d√©saisonnalis√©e (bleu)",
        xlab = "P√©riode",
        ylab= "Pr√©cipations en mm")
```

Exportation

```{r}
exportations_deseason <- ts_exportations - decom_exportations$seasonal

exportations <- ts.intersect(ts_exportations, exportations_deseason)
# Graphique 
plot.ts(exportations, 
        plot.type = "single",
        col = c("red", "blue"),
        main = "Exportations s√©rie originale (rouge) et d√©saisonnalis√©e (bleu)",
        xlab = "P√©riode",
        ylab= "Indice exportation")
```

Importation

```{r}
importations_deseason <- ts_importations - decom_importations$seasonal

importations <- ts.intersect(ts_importations, importations_deseason)
# Graphique 
plot.ts(importations, 
        plot.type = "single",
        col = c("red", "blue"),
        main = "Importations s√©rie originale (rouge) et d√©saisonnalis√©e (bleu)",
        xlab = "P√©riode",
        ylab= "Indice importations")


```

```{r}
# CDD 
adf.test(CDD_deseason, alternative = "stationary")
kpss.test(CDD_deseason,  null = "Trend")
kpss.test(CDD_deseason,  null = "Level")

```

```{r}
# temperature 
adf.test(temperature_deseason, alternative = "stationary")
kpss.test(temperature_deseason,  null = "Trend")
kpss.test(temperature_deseason,  null = "Level")
```

```{r}
# precipitation
adf.test(precipitations_deseason, alternative = "stationary")
kpss.test(precipitations_deseason,  null = "Trend")
kpss.test(precipitations_deseason,  null = "Level")
```

```{r}
# Importations
adf.test(importations_deseason, alternative = "stationary")
kpss.test(importations_deseason,  null = "Trend")
kpss.test(importations_deseason,  null = "Level")


# Differenciaiton
importation_diff <- diff(importations_deseason, differences = 1)
adf.test(importation_diff, alternative = "stationary")
kpss.test(importation_diff,  null = "Trend")
kpss.test(importation_diff,  null = "Level")


```

```{r}
# Exportations 
adf.test(exportations_deseason, alternative = "stationary")
kpss.test(exportations_deseason,  null = "Trend")
kpss.test(exportations_deseason,  null = "Level")

```

### Diff√©renciation des s√©ries non stationnaires par la tendance stochastique

### Tests apr√®s corrections

```{r}
#|warning: false
#|message: false

# Differenciation 
ipa_diff <- diff(ts_data[, "IPA"])
taux_change_diff <- diff(ts_data[, "taux_change"])
petrole_diff <- diff(ts_data[, "petrole"])

# TESTS FINAL ADF ET KPSS 

#IPA
adf.test(ipa_diff, alternative = "stationary")
kpss.test(ipa_diff,  null = "Trend")
kpss.test(ipa_diff,  null = "Level")


# Taux de change
adf.test(taux_change_diff, alternative = "stationary")
kpss.test(taux_change_diff,  null = "Trend")
kpss.test(taux_change_diff,  null = "Level")

# P√©trole
adf.test(petrole_diff, alternative = "stationary")
kpss.test(petrole_diff,  null = "Trend")
kpss.test(petrole_diff,  null = "Level")

# smic
adf.test(ts_SMIC, alternative = "stationary")
kpss.test(ts_SMIC,  null = "Trend")
kpss.test(ts_SMIC,  null = "Level")

```

### Data frame avec les variables stationnaires

Maintenant que nos s√©ries ont √©t√© rendues stationnaires, nous allons cr√©er un nouveau dataframe avec ces variables. Cependant, du fait que la diff√©renciation entra√Æne la perte de la premi√®re observation, nous devrons √©galement supprimer la premi√®re observation des s√©ries qui √©taient d√©j√† stationnaires. Ainsi, nous ajusterons toutes les s√©ries pour aligner leurs longueurs.

```{r}
#|warning: false
#|message: false
# Suppression de la premi√®re observation des s√©ries non diff√©renci√©es

#  dataframe avec des longueurs align√©es
stationnaire_data <- data.frame(
  Date = data_adj$Date[-1],
  IPA = ipa_diff,  
  CDD = CDD_deseason[-1],  
  importations = importation_diff,
  exportations = exportations_deseason[-1],
  petrole = petrole_diff, 
  taux_change = taux_change_diff,  
  SMIC = ts_SMIC[-1],
  precipitation = precipitations_deseason[-1],
  temperature = temperature_deseason[-1]
)


```

```{r}
#|warning: false
#|message: false


# Re v√©rification du test ADF 
lapply(stationnaire_data[variables], function(x) {
  adf.test(x, alternative = "stationary")
})

# test kpss 
lapply(stationnaire_data[variables], function(x) {
  kpss.test(x, null = "Trend")
})

# test kpss 
lapply(stationnaire_data[variables], function(x) {
  kpss.test(x, null = "Level")
})
```

## S√©lection des variables

1er m√©thode

```{r}

leaps <- regsubsets(IPA ~ CDD +  importations + exportations +  petrole +  taux_change + SMIC + precipitation + temperature, data=stationnaire_data, nbest=1, method=c("exhaustive"))

summary(leaps)


# R√©sum√© des crit√®res pour choisir le mod√®le optimal
res.sum <- summary(leaps)
optimal_model <- data.frame(
  Adj.R2 = which.max(res.sum$adjr2),
  CP = which.min(res.sum$cp),
  BIC = which.min(res.sum$bic)
)

# Affichage des r√©sultats
print(optimal_model)
print(res.sum)
# plot a table of models showing variables in each model.
# models are ordered by the selection statistic
# Other options for plot( ) are bic, Cp, and adjr2
par(mfrow=c(1,1))

plot(leaps, scale="adjr2", main = "Adjusted R^2")
plot(leaps, scale="Cp", main = "Mallow's Cp")
plot(leaps, scale="bic", main = "BIC")

```

## Deuxi√®me approche de s√©lection

```{r}

# Modele avec toutes les variables, ne sera pas utilis√© dans notre analyse - voir m√©thode STEP

modele1 <- lm(IPA ~  CDD +  importations + exportations +  petrole +  taux_change + SMIC + precipitation + temperature, data=stationnaire_data)

summary(modele1)

# Step : SeÃÅlection des variables explicatives significatives (modeÃÄle lineÃÅaire = modele1 )

modele0 <- lm(IPA~1,data=stationnaire_data)
summary(modele0)

### M√©thode ascendante
step1 <- step(modele0, scope=list(lower=modele0, upper=modele1), data=stationnaire_data, direction="forward")

### M√©thode descendante
step2 <- step(modele1,data=stationnaire_data,direction="backward")

### M√©thode double
#m√©thode dans les 2 sens
step3 <- step(modele0,scope=list(upper=modele1),data=stationnaire_data,direction="both")


```

# MODELES

Apr√®s les m√©thodes de s√©lections les variables IPA \~ exportations + CDD + petrole + taux_change + precipitation

## 1. Mod√®le

1 retenue

```{r}
lm_model1 <- lm(IPA ~ exportations + CDD + petrole + taux_change + precipitation, data=stationnaire_data)

summary(lm_model1)

```

### Hypoth√®ses

Test de normalit√© des r√©sidus

```{r}
# R√©sidus
# Test de normalit√© des r√©sidus
residus <- residuals(lm_model1)
# Test de normalit√© des r√©sidus
ks.test(residus, "pnorm", mean = mean(residus), sd = sd(residus))

```

p-value = 0.001723, Refus de l‚Äôhypoth√®se de normalit√© des r√©sidus au seuil de risque de 5%

Test d‚Äôhomosc√©dasticit√© des r√©sidus

```{r}
# Test de Breusch-Pagan pour l'h√©t√©rosc√©dasticit√©
bptest(lm_model1)
```

p-value = 8.844e-05, Refus de l‚Äôhypoth√®se d‚Äôhomosc√©dacticit√© des r√©sidus au seuil de risque de 5%

Forme fonctionnelle

```{r}
# Test RESET
reset(lm_model1)
```

p-value = 0.001495; Forme fonctionnelle lin√©aire du mod√®le sp√©cifi√© accept√©e au seuil de 5%

Analyse des observations influen√ßant l‚Äôestimation

```{r}
# Distance de Cook pour identifier les points influents
plot(cooks.distance(lm_model1), type = "h", main = "Distance de Cook")
```

multicollin√©arit√©

```{r}
vif(lm_model1)
```

Autocorrelation de r√©sidus

```{r}
checkresiduals(lm_model1)
```

p-value \< 2.2e-16. il existe des preuves significatives d‚Äôauto-corr√©lation r√©siduelle dans les donn√©es.

## 2. Mod√®le 2: diff√©renci√© - logarithmique

Dans ce model nous appliquons le logarithme avant la diff√©renciation p

```{r}
d_l_IPA <- diff(log(data_adj$IPA), differences = 1)
plot(ts(d_l_IPA))
adf.test(d_l_IPA) # on verifie stationnarit√© 

# creation df avec la dif du log de ipa
st2_data <- data.frame(
  Date = data_adj$Date[-1],
  IPA = d_l_IPA,  
  CDD = CDD_deseason[-1],  
  importations = importation_diff,
  exportations = exportations_deseason[-1],
  petrole = petrole_diff, 
  taux_change = taux_change_diff,  
  SMIC = ts_SMIC[-1],
  precipitation = precipitations_deseason[-1],
  temperature = temperature_deseason[-1]
)

# estimation modele avec ipa differenci√© et log
modele1_2 <- lm(IPA ~ CDD +  importations + exportations +  petrole +  taux_change + SMIC + precipitation + temperature, data=st2_data)
summary(modele1_2)

# Step : SeÃÅlection des variables explicatives significatives (modeÃÄle lineÃÅaire = modele1 )

modele0_2 <- (lm(IPA~1,data=st2_data))
summary(modele0_2)
### M√©thode ascendante
step(modele0_2, scope=list(lower=modele0_2, upper=modele1_2), data=st2_data, direction="forward")
### M√©thode descendante
step(modele1_2,data=st2_data,direction="backward")
### M√©thode double
#m√©thode dans les 2 sens
step(modele0_2,scope=list(upper=modele1_2),data=st2_data,direction="both")

# MODELO 3 RETENUE
lm_model2 <- lm(IPA ~ taux_change + petrole + precipitation + exportations, 
    data = st2_data)
summary(lm_model2)


## TESTS 
residus2 <- residuals(lm_model2)
# Test de normalit√© des r√©sidus
ks.test(residus2, "pnorm", mean = mean(residus2), sd = sd(residus2))
bptest(lm_model2)
reset(lm_model2)
vif(lm_model2)
checkresiduals(lm_model2)

```

Le mod√®le 3 inclut une variable de temps pour capturer la tendance d√©terministe. Cela permet de mod√©liser explicitement les effets de la tendance dans les donn√©es et peut aider √† r√©duire l'autocorr√©lation dans les r√©sidus.

## 3. Mod√®le 3 index temporel

```{r}
# Ajout d'un index temporel
st3_data <- st2_data
st3_data$time <- 1:nrow(st3_data)

# Mod√®le de r√©gression avec la variable de temps
modele1_3 <- lm(IPA ~ CDD +  importations + exportations +  petrole +  taux_change + SMIC + precipitation + temperature+ time, data = st3_data)
summary(modele1_3)


modele0_3 <- (lm((IPA)~1,data=st3_data))
summary(modele0_3)
### M√©thode ascendante
step(modele0_3, scope=list(lower=modele0_3, upper=modele1_3), data=st3_data, direction="forward")
### M√©thode descendante
step(modele1_3,data=st3_data,direction="backward")
### M√©thode double
#m√©thode dans les 2 sens
step(modele0_3,scope=list(upper=modele1_3),data=st3_data,direction="both")

# modele 3 
lm_model3 <- lm(formula = (IPA) ~ taux_change + petrole + precipitation + 
    exportations + time, data = st3_data)

summary(lm_model3)

## TESTS 
residus3 <- residuals(lm_model3)
# Test de normalit√© des r√©sidus
ks.test(residus3, "pnorm", mean = mean(residus3), sd = sd(residus3))
reset(lm_model3)
bptest(lm_model3)
vif(lm_model3)
checkresiduals(lm_model3)

```

## 4. Mod√®le 4 tendance d√©terministe corrig√©e

```{r}
# Fonction pour corriger la tendance d√©terministe par r√©gression
correct_trend <- function(series) {
  model <- lm(series ~ time(series))
  residuals(model)
}
# Appliquer la correction √† chaque variable explicative
for (var in variables) {
  # Corriger la tendance d√©terministe
  corrected_series <- correct_trend(stationnaire_data[[var]])
  # Ajouter les s√©ries corrig√©es au data frame
  stationnaire_data[[paste(var, "detrended", sep = "_")]] <- corrected_series
}

# Affiche la structure du data frame pour v√©rifier les changements
str(stationnaire_data)

# Modele avec toutes les variables, ne sera pas utilis√© dans notre analyse - voir m√©thode STEP
modele1_4 <- lm(IPA_detrended ~  CDD_detrended +  importations_detrended + exportations_detrended +  petrole_detrended +    taux_change_detrended + SMIC_detrended + precipitation_detrended + temperature_detrended, data=stationnaire_data)

summary(modele1_4)

# Step : SeÃÅlection des variables explicatives significatives (modeÃÄle lineÃÅaire = modele1_4 )

modele0_4 <- (lm(IPA_detrended~1,data=stationnaire_data))
summary(modele0_4)

### M√©thode ascendante
 step(modele0_4, scope=list(lower=modele0_4, upper=modele1_4), data=stationnaire_data, direction="forward")

### M√©thode descendante
step(modele1_4,data=stationnaire_data,direction="backward")

### M√©thode double
#m√©thode dans les 2 sens
step(modele0_4,scope=list(upper=modele1_4),data=stationnaire_data,direction="both")
# 1. MCO modele retenue
lm_model4<-  lm(formula = IPA_detrended ~ CDD_detrended + petrole_detrended + 
    exportations_detrended + taux_change_detrended + precipitation_detrended, 
    data = stationnaire_data)
summary(lm_model4)
## Hypotheses
#### Test de normalit√© des r√©sidus
# R√©sidus
residus4 <- residuals(lm_model4)
# Test de normalit√© des r√©sidus
ks.test(residus4, "pnorm", mean = mean(residus4), sd = sd(residus4))
# Test de Breusch-Pagan pour l'h√©t√©rosc√©dasticit√©
bptest(lm_model4)
# Test RESET
reset(lm_model4)
#### multicollin√©arit√©
vif(lm_model4)
#### Autocorrelation de r√©sidus
checkresiduals(lm_model4)

```

## 5. Mod√®le 5 avec lag

```{r}
# Cr√©ation du lag 
st3_data$IPA_lag1 <- stats::lag(st3_data$IPA, 1) 
st3_data$IPA_lag2 <- stats::lag(st3_data$IPA, 2) 

st3_data <- na.omit(st3_data)


# Mod√®le de r√©gression avec Lag 1 , toutes les variables
modele1_5 <- lm(IPA ~ CDD +  importations + exportations +  petrole +  taux_change + SMIC + precipitation + temperature+ IPA_lag1 + IPA_lag2, data = st3_data)
summary(modele1_5)


modele0_5 <- (lm((IPA)~1,data=st3_data))
summary(modele0_5)
### M√©thode ascendante
step(modele0_5, scope=list(lower=modele0_5, upper=modele1_5), data=st3_data, direction="forward")
### M√©thode descendante
step(modele1_5,data=st3_data,direction="backward")
### M√©thode double
#m√©thode dans les 2 sens
step(modele0_5,scope=list(upper=modele1_5),data=st3_data,direction="both")


# modele 7 
model5 <- lm(formula = (IPA) ~ IPA_lag1 + taux_change + petrole + precipitation,   data = st3_data)
summary(model5)

## TESTS 
residus7 <- residuals(model5)
# Test de normalit√© des r√©sidus
ks.test(residus7, "pnorm", mean = mean(residus7), sd = sd(residus7))
bptest(model5)
reset(model5)
vif(model5)
checkresiduals(model5)


```

-   La pr√©sence d'h√©t√©rosc√©dasticit√© signifie que la variance des r√©sidus n'est pas constante. Cela peut affecter la validit√© des tests de significativit√© des coefficients.

-   Le test RESET sugg√®re que le mod√®le pourrait √™tre mal sp√©cifi√©, indiquant que la relation entre les variables n'est pas correctement captur√©e par le mod√®le lin√©aire.

-   On ne peut donc pas utiliser la m√©thode des MCO pour estimer le mod√®le : les coefficients MCO ne sont pas biais√©s mais la variance de l‚Äôestimateur est non minimale

# Conclusion

Tous les mod√®les estim√©s avec les MCO pr√©sentent de l'autocorrelation de r√©sidus, c'est √† dire une corr√©lation entre les r√©sidus eux-m√™mes √† travers le temps.

Introduire des lags peut r√©gler le probl√®me mais cela a g√©n√©r√© un surajustement et aussi de l'heteroscedasticit√© et la forme lin√©aire n'est pas accepte

# ARMAX

Mod√®le 0 de test avec ARMAX avec toutes les variables et sans stationnaire

```{r}
y0 <- ts_data[,1]
vars0 <- ts_data[,2:9]
# Estimation du mod√®le ARMAX
armax_model0 <- auto.arima(y0, xreg = vars0, stationary=FALSE, seasonal = TRUE)
# R√©sum√© du mod√®le ARMAX
summary(armax_model0)
coeftest(armax_model0)

# Test hypotheses 
# R√©sidus du mod√®le ARMAX
residuals_armax0 <- residuals(armax_model0)
# Test de normalit√© des r√©sidus
ks.test(residuals_armax0, "pnorm", mean = mean(residuals_armax0), sd = sd(residuals_armax0))
# Test de Ljung-Box pour l'autocorr√©lation des r√©sidus
checkresiduals(armax_model0)
# Test de Breusch-Pagan pour l'h√©t√©rosc√©dasticit√©
bptest(residuals_armax0 ~ vars0)

```

Probl√®me d‚Äôautocorrelation Ljung-Box test p-value \< 2.2e-16

Probl√®me d‚Äôhomoscedasticit√© Breusch-Pagan p-value test 2.703e-06

Probl√®me normalit√© Kolmogorov-Smirnov test p-value = 0.01913

## 1. Test Mod√®le ARMAX avec toutes les variables stationnaires

Inclut toutes les variables (stationnaires)

```{r}
# Pr√©paration des s√©ries temporelles pour ARMAX
y1 <- ts(stationnaire_data[,2], start = c(2000, 2), frequency = 12)
vars1 <- as.matrix(stationnaire_data[, 3:10]) 
# Estimation du mod√®le ARMAX avec toutes les variables
armax_model1 <- auto.arima(y1, xreg = vars1, stationary=TRUE)
# R√©sum√© du mod√®le ARMAX
summary(armax_model1)
coeftest(armax_model1)

# Test hypotheses 
# R√©sidus du mod√®le ARMAX
# Test de Ljung-Box pour l'autocorr√©lation des r√©sidus
checkresiduals(armax_model1)
residuals_armax1 <- residuals(armax_model1)
# Test de normalit√© des r√©sidus
ks.test(residuals_armax1, "pnorm", mean = mean(residuals_armax1), sd = sd(residuals_armax1))
# Test de Breusch-Pagan pour l'h√©t√©rosc√©dasticit√©
bptest(residuals_armax1 ~ vars1)


```

## 2. ARMAX Avec variables s√©lectionnes par stepwise et best sub

```{r}

y2 <- ts(stationnaire_data[,2], start = c(2000, 2), frequency = 12)
vars2 <- as.matrix(stationnaire_data[, c("exportations", "petrole", "precipitation", "taux_change", "CDD")])
# Estimation du mod√®le ARMAX
armax_model2 <- auto.arima(y2, xreg = vars2, stationary=TRUE)
# R√©sum√© du mod√®le ARMAX
summary(armax_model2)

coeftest(armax_model2)


# Test hypoth√®ses 
# R√©sidus du mod√®le ARMAX
residuals_armax2 <- residuals(armax_model2)
# Test de Ljung-Box pour l'autocorr√©lation des r√©sidus
checkresiduals(armax_model2)
# Test de normalit√© des r√©sidus
ks.test(residuals_armax2, "pnorm", mean = mean(residuals_armax2), sd = sd(residuals_armax2))

# Test de Breusch-Pagan pour l'h√©t√©rosc√©dasticit√©
bptest(residuals_armax2 ~ vars2)
```

## 3. Mod√®le ARMAX (st2_data utilise le diff_log_IPA)

```{r}
y3 <- ts(st2_data[,2], start = c(2000, 2), frequency = 12)
vars3 <- as.matrix(stationnaire_data[, 3:10]) 
# Estimation du mod√®le ARMAX
armax_model3 <- auto.arima(y3, xreg = vars3, stationary=TRUE)
# R√©sum√© du mod√®le ARMAX
summary(armax_model3)

coeftest(armax_model3)

# Test hypotheses 
# R√©sidus du mod√®le ARMAX
residuals_armax3 <- residuals(armax_model3)
# Test de Ljung-Box pour l'autocorr√©lation des r√©sidus
checkresiduals(residuals_armax3)
# Test de normalit√© des r√©sidus
ks.test(residuals_armax3, "pnorm", mean = mean(residuals_armax3), sd = sd(residuals_armax3))
# Test de Breusch-Pagan pour l'h√©t√©rosc√©dasticit√©
bptest(residuals_armax3 ~ vars3)

```

## 4. Mod√®le ARMAX2 - Variables s√©lectionn√©s (st2_data utilise le diff_log_IPA)

```{r}
y4 <- ts(st2_data[,2], start = c(2000, 2), frequency = 12)
vars4 <- as.matrix(stationnaire_data[, c("exportations", "petrole", "precipitation", "taux_change")])

# Estimation du mod√®le ARMAX
armax_model4 <- auto.arima(y4, xreg = vars4, stationary=TRUE, seasonal = FALSE, stepwise=FALSE, approximation=FALSE)
# R√©sum√© du mod√®le ARMAX
summary(armax_model4)
coeftest(armax_model4)

# Test hypotheses 
# R√©sidus du mod√®le ARMAX
residuals_armax <- residuals(armax_model4)
# Test de normalit√© des r√©sidus
ks.test(residuals_armax, "pnorm", mean = mean(residuals_armax), sd = sd(residuals_armax))
# Test de Ljung-Box pour l'autocorr√©lation des r√©sidus

checkresiduals(armax_model4)
# Test de Breusch-Pagan pour l'h√©t√©rosc√©dasticit√©
bptest(residuals_armax ~ vars4)

```

-   Test de Kolmogorov-Smirnov Une p-value de 0.4388 indique qu'il n'y a pas de preuve statistique pour rejeter l'hypoth√®se nulle selon laquelle les r√©sidus suivent une distribution normale. Cela signifie que les r√©sidus peuvent √™tre consid√©r√©s comme normalement distribu√©s

-   Test de Ljung-Box (Box-Ljung Test) Une p-value de 0.593 indique que on ne rejete pas l'hypoth√®se nulle d'ind√©pendance des r√©sidus et donc pas d'autocorr√©lation significative dans les r√©sidus du mod√®le

-   Test de Breusch-Pagan Hypoth√®se nulle: les variances des r√©sidus sont homog√®nes, c'est-√†-dire qu'il n'y a pas d'h√©t√©rosc√©dasticit√© dans les r√©sidus de votre mod√®le. Avec une p-value de 0.3751, on ne rejet pas l'hypoth√®se nulle car il n'y a pas de preuves statistiquement significatives d'h√©t√©rosc√©dasticit√© dans les r√©sidus du mod√®le ARMAX

```{r}
# √©cart pour la bande de pr√©diction √† 80%
ec80 <- sqrt(armax_model4$sigma2) * qnorm(0.90)

# Valeurs ajust√©es (pr√©dictions)
vajust <- fitted(armax_model4)

# Matrice avec les valeurs observ√©es, les valeurs ajust√©es, et les bandes de pr√©diction
matri <- as.ts(cbind(y4, vajust - ec80, vajust + ec80), start = start(y4), frequency = frequency(y4))

# Graphique
plot(matri, plot.type = 'single', lty = c(1, 2, 2), xlab = "Temps", ylab = 'Valeur', main = "", cex.main = 0.8)
legend("topright", legend = c("Valeur observ√©e", "Bande de pr√©diction 80%"), lwd = 1, lty = c(1, 2), cex = 0.8)


# Proportion 
indi <- (y4-(vajust-ec80))>0&(vajust+ec80-y4)>0
prop <- 100*sum(indi)/length(indi)

prop

```

Montre les valeurs observ√©es de notre s√©rie temporelle, ainsi que les valeurs ajust√©es par le mod√®le ARMAX avec une bande de pr√©diction √† 80%.

La proportion observ√©e vaut 81%, elle est un peu sup√©rieure √† la valeur th√©orique de 80%. On consid√©rera que l'ajustement est satisfaisant.

# Comparaison lm et armax

```{r}
a <-arima(y4, order = c(0,0,0), xreg = vars4)
coeftest(a)


lm_model2
summary(lm_model2)
```

On trouve effectivement les m√™mes estimations que par lm() dans lm_model2; cependant on note des diff√©rences dans les √©carts types des estimateurs. Ceci peut s‚Äôexpliquer par le fait que Arima() fournit une estimation de la matrice des covariances des estimateurs √† partir du Hessien de la log-vraisemblance, estimation peu pr√©cise.

## ACF - PACF

On reprend le mod√®le avec diff log, les variables s√©lectionn√©s et

```{r}
acf(residuals(lm_model2),lag.max=30,numer=FALSE)
pacf(residuals(lm_model2),lag.max=30,numer=FALSE)
```

# Mod√®le mix - MCG - AR

on rajoute un terme AR 1

```{r}

gls_model1 <- gls(IPA ~ taux_change + petrole + precipitation + exportations, 
                 data = st2_data,  corAR1(form = ~ 1))
summary(gls_model1)

# V√©rification des r√©sidus
residuals_gls_model <- residuals(gls_model1)
par(mfrow = c(1, 2))
acf(residuals_gls_model, main = "ACF des r√©sidus du mod√®le AR(1)")
pacf(residuals_gls_model, main = "PACF des r√©sidus du mod√®le AR(1)")

checkresiduals(gls_model1)

```

gls : La fonction gls permet de sp√©cifier des mod√®les de r√©gression avec des structures de corr√©lation sp√©cifiques pour les erreurs. corARMA(p = 1, form = \~ 1) : Cet argument sp√©cifie que les r√©sidus du mod√®le doivent suivre un processus AR(1).

## Mod√®le MCO avec les r√©sidus ajust√©s avec un mod√®le AR(1)

```{r}
# On ajuste le mod√®le avec base st2 (qui utilise diff_log_IPA) pour obtenir les r√©sidus
lm_base <- lm(IPA ~ taux_change + petrole + precipitation + exportations, data = st2_data)
residuals_base <- residuals(lm_base)

#  mod√®le AR(1) sur les r√©sidus
ar1_residuals <- arima(residuals_base, order = c(1, 0, 0))
ar1_fitted <- fitted(ar1_residuals)

#  les valeurs ajust√©es de l'AR(1) comme une nouvelle variable
st2_data$ar1_fitted <- ar1_fitted

# On reajuste le mod√®le lin√©aire en incluant la nouvelle variable
lm_corrected <- lm(IPA ~ taux_change + petrole + precipitation + exportations + ar1_fitted, data = st2_data)

# R√©sum√© du nouveau mod√®le
summary(lm_corrected)

# V√©rification des r√©sidus du mod√®le corrig√©
residuals_corrected <- residuals(lm_corrected)
par(mfrow = c(1, 2))
acf(residuals_corrected, main = "ACF des r√©sidus du mod√®le corrig√©")
pacf(residuals_corrected, main = "PACF des r√©sidus du mod√®le corrig√©")

checkresiduals(residuals_corrected)


# Tests
ks.test(residuals_corrected, "pnorm", mean = mean(residuals_corrected), sd = sd(residuals_corrected))
bptest(lm_corrected)
reset(lm_corrected)
vif(lm_corrected)


```
